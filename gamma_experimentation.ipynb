{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veVyQdYk_N5g",
        "outputId": "24418f86-bb4f-4e81-9b6a-30cf53667263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbK5k0KgNMoC"
      },
      "source": [
        "## Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KudB-pTs_qb6",
        "outputId": "f82a1fa2-ec5c-49cb-e342-646ec80e468e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive/\n",
            "MyDrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive/')\n",
        "!ls /gdrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j-DtVrxNdST"
      },
      "source": [
        "## Extracting The Dataset From a Zip File\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "a_B4Zm_zA7Jp",
        "outputId": "f0cb7ad5-0fd6-406e-bf84-35a4fbc5f949"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6a6b7030c733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'extracted_birds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m# create an object to manipulate the zip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mzip_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'birds.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0;31m# to extract all files inside\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1248\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1249\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/gdrive/My Drive/colab_files/birds.zip'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "BASE_PATH = '/gdrive/My Drive/colab_files/'\n",
        "CK_PATH = '/gdrive/My Drive/colab_files/cks'\n",
        "\n",
        "if not os.path.exists(BASE_PATH):\n",
        "  os.makedirs(BASE_PATH)\n",
        "\n",
        "# add checkpoints to store the history of training\n",
        "if not os.path.exists(CK_PATH):\n",
        "  os.makedirs(CK_PATH)\n",
        "\n",
        "if not os.path.exists('extracted_birds'):\n",
        "  !mkdir extracted_birds\n",
        "  os.chdir('extracted_birds')\n",
        "  # create an object to manipulate the zip\n",
        "  zip_file = zipfile.ZipFile(os.path.join(BASE_PATH, 'birds.zip'))\n",
        "  # to extract all files inside\n",
        "  zip_file.extractall()\n",
        "  \n",
        "  # switch back to the parent directory\n",
        "  os.chdir('..')\n",
        "\n",
        "# verify that the extracted_birds directory is there\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfsAC_SW_BeL"
      },
      "source": [
        "## Getting Image Size\n",
        "**This cell should not be ran for training a model**, and is only for testing purpose. Checking the size of sample images in the given dataset.\n",
        "\n",
        "### Results\n",
        "See output below. This can roughly tell us what size to choose for `transforms.RandomCrop()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GlG4TWGk8B-A",
        "outputId": "1e63a024-042d-406c-e94e-b6acba1ac9b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image file name is : 81d5cdbb709e4ffd8b1c29e0f616780a.jpg\n",
            "image width: 1024, image height: 725\n",
            "image file name is : 626e0b90838a41d9b71df171d23157cf.jpg\n",
            "image width: 800, image height: 800\n",
            "image file name is : ee217e5a95f54e97995eb2e334405154.jpg\n",
            "image width: 800, image height: 548\n",
            "image file name is : 0133dc8543f44c1fbb5a7941a286b1db.jpg\n",
            "image width: 1024, image height: 680\n",
            "image file name is : 76f84b5eb6334474a2d323a3ba7efc24.jpg\n",
            "image width: 1024, image height: 606\n",
            "image file name is : 1131a4c5f40f4636a4be4fed9e83b4c8.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 9d7268bdebc24d8cbe09d2734961ba14.jpg\n",
            "image width: 573, image height: 860\n",
            "image file name is : dcbdbf9fd8a14e3bbc36b4ff1327461e.jpg\n",
            "image width: 1008, image height: 820\n",
            "image file name is : 69034a46663b4e0eb8db02cf696ebe8d.jpg\n",
            "image width: 1024, image height: 831\n",
            "image file name is : 7bed42d90d8843bfb6f96083fc50ea23.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : d7ffcb4b168444e7a2fd15eb1f7d4a23.jpg\n",
            "image width: 1024, image height: 730\n",
            "image file name is : 5212d43fc0994aef9531bce86e321907.jpg\n",
            "image width: 1024, image height: 678\n",
            "image file name is : 7990cb577f0942c884f380ea2abf9b44.jpg\n",
            "image width: 675, image height: 514\n",
            "image file name is : ca8c4bcd21e24572a74fc0b17743f1ed.jpg\n",
            "image width: 800, image height: 600\n",
            "image file name is : a7af4b7522e94c3ba47931040535b5ce.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 3031c8ed71dd41b494fae6715ad311a3.jpg\n",
            "image width: 600, image height: 400\n",
            "image file name is : 9ed39a0e495f4542a5991c2aa9f45e25.jpg\n",
            "image width: 800, image height: 565\n",
            "image file name is : 690305e1c59045a2bbeb4b2f13748313.jpg\n",
            "image width: 1024, image height: 727\n",
            "image file name is : 64f1d81f923242edbd234f7abc14f969.jpg\n",
            "image width: 1024, image height: 827\n",
            "image file name is : 80b4131bd1ca4039acacd4ce545c95aa.jpg\n",
            "image width: 684, image height: 1024\n",
            "image file name is : fc1e7958b1eb43aab96f33a777799c00.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : c65d32e8885f4f858cf96651533a61af.jpg\n",
            "image width: 1024, image height: 725\n",
            "image file name is : ddf5f6bb803b404381b25dbf0c42689e.jpg\n",
            "image width: 640, image height: 480\n",
            "image file name is : b3b4589e50ad4b8eb060128d2c95baf0.jpg\n",
            "image width: 1024, image height: 856\n",
            "image file name is : 0e69df288ff744d5ad52a922de2da12f.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 05d002e6b49f4d8e96a8e24d0ba1be72.jpg\n",
            "image width: 1024, image height: 678\n",
            "image file name is : ecfb530d75e9463ca90a148728b534de.jpg\n",
            "image width: 1024, image height: 819\n",
            "image file name is : 1cd3ea627d714d518601ba262d039258.jpg\n",
            "image width: 680, image height: 1024\n",
            "image file name is : 01a647ba0ca64db59404b055345bdf23.jpg\n",
            "image width: 1024, image height: 685\n",
            "image file name is : 6ddccc2286f046978285efdcf0d431da.jpg\n",
            "image width: 860, image height: 645\n",
            "image file name is : 02adfd220e8740988be1ac79e0d3880b.jpg\n",
            "image width: 640, image height: 425\n",
            "image file name is : 25d8135bed8945abbf2c2ae2c2104d8b.jpg\n",
            "image width: 1024, image height: 679\n",
            "image file name is : 6cc85a2515a84091a71627192d2de987.jpg\n",
            "image width: 735, image height: 600\n",
            "image file name is : 0b4cf8d44c8f4312a794f99e01679176.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : dcf39cce7f13498580181823ca7d8f09.jpg\n",
            "image width: 878, image height: 1024\n",
            "image file name is : cfd2c85cd996481f93bcb3c710b9fd0c.jpg\n",
            "image width: 800, image height: 618\n",
            "image file name is : 029c08cb793c421f9e1d311189d1325e.jpg\n",
            "image width: 457, image height: 685\n",
            "image file name is : f3e3be1e961746339400fbe46e77e7f5.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : fb7afc17aeef47e18bccef96e1e0e836.jpg\n",
            "image width: 1024, image height: 771\n",
            "image file name is : c72fcc055b6b44fabe4afc9db55a166f.jpg\n",
            "image width: 1024, image height: 680\n",
            "image file name is : 3664a9ce77e14e4b95abc1556485783f.jpg\n",
            "image width: 640, image height: 480\n",
            "image file name is : 68142b20b6ba4d85953d01179c2c5511.jpg\n",
            "image width: 477, image height: 550\n",
            "image file name is : a1a1c0a3be8a48eaab84b81fb86a34a4.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 5751349dac7944ed9365285b76b77a76.jpg\n",
            "image width: 817, image height: 1024\n",
            "image file name is : 763632afced74d4d900535e86dbd59de.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 5fe25cadd9254fe78a5ade5d54b0af9b.jpg\n",
            "image width: 740, image height: 1024\n",
            "image file name is : 96958dd3810740f09c7961e509676f41.jpg\n",
            "image width: 512, image height: 640\n",
            "image file name is : 20d9318e4ec14b46be9d6aa58b077f9e.jpg\n",
            "image width: 1024, image height: 917\n",
            "image file name is : ef8035e92cf8404ab0c0bf68064208ef.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 89ce89c395ca483b9b1fb67d3ef24056.jpg\n",
            "image width: 975, image height: 663\n",
            "image file name is : 729e457ba48043ce9e4c869664c877ba.jpg\n",
            "image width: 800, image height: 640\n",
            "image file name is : cb04dd1acd014628a0b43392a19e6af2.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 5c5eb7430b104fd1a6fe9dfc29f42ea3.jpg\n",
            "image width: 771, image height: 551\n",
            "image file name is : 878bf7a7498141ad8c4dfcff9edd7a74.jpg\n",
            "image width: 800, image height: 565\n",
            "image file name is : 4e51c58d33ac473f9e7dfdd98343ce80.jpg\n",
            "image width: 700, image height: 555\n",
            "image file name is : bf6b2fa2b80a4dc7a7e5feab3742b73a.jpg\n",
            "image width: 1024, image height: 728\n",
            "image file name is : e6307c2fb88147bd9237a6cfa98b208e.jpg\n",
            "image width: 926, image height: 1024\n",
            "image file name is : 523411e04b8d4613bcdbc6a577ced8bb.jpg\n",
            "image width: 640, image height: 427\n",
            "image file name is : 003d00f987624b62a47646737e24b5b3.jpg\n",
            "image width: 817, image height: 1024\n",
            "image file name is : a3aecb4653a840bf8b675e4acff0423f.jpg\n",
            "image width: 1024, image height: 819\n",
            "image file name is : e1ba306fbc5246ad9c9c730221906438.jpg\n",
            "image width: 1024, image height: 681\n",
            "image file name is : b3c880d355ed4675871e34e87dc71b39.jpg\n",
            "image width: 1024, image height: 691\n",
            "image file name is : 194ec673fce8436c8bf3aa5bd3a4c78e.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : f19f916ebd7b4b9389aa141f9b8d2a5d.jpg\n",
            "image width: 1024, image height: 707\n",
            "image file name is : 24fa12fdf7864bd5be450a068150ff15.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 53e15f1ae83b4ae2ad1fe4944c2092c6.jpg\n",
            "image width: 1024, image height: 792\n",
            "image file name is : 9644ade5ca6d4357a531fcabfcbcddf2.jpg\n",
            "image width: 1024, image height: 681\n",
            "image file name is : e8f20dff1ab04999b39b1742e8af0e4e.jpg\n",
            "image width: 1024, image height: 688\n",
            "image file name is : a741731798714b12ab97acfb2a78e206.jpg\n",
            "image width: 800, image height: 640\n",
            "image file name is : 13950458ca9949ccbf6c40d57ddfb0d9.jpg\n",
            "image width: 1024, image height: 819\n",
            "image file name is : 878f92850b994953835caf9ff5da64e7.jpg\n",
            "image width: 700, image height: 520\n",
            "image file name is : 9919d32404cd4e62a95b95b51a87e201.jpg\n",
            "image width: 860, image height: 573\n",
            "image file name is : 75ee674988934fddb1e42c4460ac6bb2.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : eb3a963b2b0c4008ab47e06b9873f79b.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : b4e09d99bce24153a4d5825402f8f81b.jpg\n",
            "image width: 550, image height: 600\n",
            "image file name is : afd30bd6f5b646728dc53f3fba5e42ca.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : ce49c888e4704c7e8e32a9c2dbd46909.jpg\n",
            "image width: 1017, image height: 800\n",
            "image file name is : 7be7da6bdd5341d1813ca60bf59a6893.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 0197a7a671d242bf8dd5b6b567f36eb1.jpg\n",
            "image width: 650, image height: 850\n",
            "image file name is : 0749ba1547fd481fae6263ee9215d8ac.jpg\n",
            "image width: 700, image height: 800\n",
            "image file name is : 8ab57e3a7ea6487cb20b7441c74a2ac2.jpg\n",
            "image width: 1024, image height: 747\n",
            "image file name is : 3ceedbc578ae4f71a43219503925600f.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : ec3d8ce7fb974966972f51ec1c9020c8.jpg\n",
            "image width: 1024, image height: 679\n",
            "image file name is : 3f3b073959cc4d74a5197bc1cec55a8b.jpg\n",
            "image width: 852, image height: 1024\n",
            "image file name is : a234130a29674be1b53496f84f4e23e0.jpg\n",
            "image width: 682, image height: 1024\n",
            "image file name is : 270d8b8916684cb6b3546511ffd4288e.jpg\n",
            "image width: 800, image height: 800\n",
            "image file name is : ff85a2f114b14b7e9c87887151d97e01.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 450d5c1f0ee84dcfa707529c935d6612.jpg\n",
            "image width: 1024, image height: 733\n",
            "image file name is : 5e52564f9842498eb590870793646232.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 30d26c2704834b739bb03c6e60293593.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : e0a963c534764b44b892669aad9947a0.jpg\n",
            "image width: 900, image height: 700\n",
            "image file name is : 9bfb0ec2b60a43b7a72c96068cbac9ca.jpg\n",
            "image width: 1024, image height: 685\n",
            "image file name is : 9de432fdb74e4f57ab327356f0a6cc8c.jpg\n",
            "image width: 680, image height: 850\n",
            "image file name is : c6d9f958c36648c1a2b43b911ad0c2d1.jpg\n",
            "image width: 500, image height: 321\n",
            "image file name is : b6cb496abc0e4e3cbd0594885ebc1653.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 52729b1a63454bce9b1753b8e1db6d63.jpg\n",
            "image width: 1000, image height: 666\n",
            "image file name is : c22e86ec2f884a21b83fa27ea517b477.jpg\n",
            "image width: 576, image height: 433\n",
            "image file name is : bbaaeff4087b4d12a5f37cab0f16a5c0.jpg\n",
            "image width: 1024, image height: 732\n",
            "image file name is : 252e52977a1b49e2a2a8bb970215aafa.jpg\n",
            "image width: 800, image height: 600\n",
            "image file name is : 4d2b747e546f416c8b30e419e0b75b3c.jpg\n",
            "image width: 835, image height: 1024\n",
            "image file name is : fc32707d54954c0b855413c046efa729.jpg\n",
            "image width: 1024, image height: 725\n",
            "image file name is : 49f0d463baf54bc685e6009fa6eb0c54.jpg\n",
            "image width: 800, image height: 600\n",
            "image file name is : 0e91a80f37ef43638ec1a3a2c003fd57.jpg\n",
            "image width: 860, image height: 573\n",
            "image file name is : 233a694848eb4b678259222b916b2322.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 4c0abd85f2de4e34a169aca417ed5c38.jpg\n",
            "image width: 600, image height: 450\n",
            "image file name is : 6c3360695a5241c9a890d7968bf60b7a.jpg\n",
            "image width: 873, image height: 1024\n",
            "image file name is : 705569ab962b4a95a7bba8e348e35e83.jpg\n",
            "image width: 571, image height: 800\n",
            "image file name is : d6afe78a90ed45ceabe28c0351223c6d.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 5334fd543a4c4bafb52f4b5a24a95387.jpg\n",
            "image width: 860, image height: 545\n",
            "image file name is : 869491ff14d848c7a377e870583b6535.jpg\n",
            "image width: 1024, image height: 804\n",
            "image file name is : fb6725c6e1f64a299edf1ab0d5faadc7.jpg\n",
            "image width: 1024, image height: 662\n",
            "image file name is : 8e0e433461564e8f9e17c0b04a021464.jpg\n",
            "image width: 683, image height: 1024\n",
            "image file name is : 243646f21f0345888732b3bf8c3994b0.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 52072eac004a41ed83fbbba139e75315.jpg\n",
            "image width: 900, image height: 477\n",
            "image file name is : f727fa60c14949ea97fa932b4d1a88cd.jpg\n",
            "image width: 800, image height: 647\n",
            "image file name is : ac52ccec2f7944ed8c41348793f62aeb.jpg\n",
            "image width: 500, image height: 448\n",
            "image file name is : 699a7ba1042b446e80265d06d81af2e2.jpg\n",
            "image width: 450, image height: 375\n",
            "image file name is : 54b3e46416a2453c976f0a0bbafc272b.jpg\n",
            "image width: 1024, image height: 640\n",
            "image file name is : 9013d28cf28849c6b537af1feb4114cc.jpg\n",
            "image width: 683, image height: 1024\n",
            "image file name is : c3b88d0f47b544728aaf1f8de22b8cdb.jpg\n",
            "image width: 932, image height: 1024\n",
            "image file name is : f7e92f2915494618b55bd847913642f0.jpg\n",
            "image width: 800, image height: 539\n",
            "image file name is : c1b6d85150064b3096688aeb46a81668.jpg\n",
            "image width: 683, image height: 1024\n",
            "image file name is : 49481d25964843418abeba28a2832252.jpg\n",
            "image width: 800, image height: 562\n",
            "image file name is : d659f6f2a72c47ec9de5037a3297b0e2.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : f144384914ba4b1998d0602009985b34.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : 5b864621e4e8499abe646cba0c7f1c62.jpg\n",
            "image width: 641, image height: 840\n",
            "image file name is : dd4be7c03bab45fbb7911fa1127a225f.jpg\n",
            "image width: 681, image height: 1024\n",
            "image file name is : 3aadb4abcccf442cb27627b1424710d1.jpg\n",
            "image width: 1008, image height: 792\n",
            "image file name is : 0cedc49762e441cdb6b5bb85f981e9c8.jpg\n",
            "image width: 900, image height: 781\n",
            "image file name is : 2a2de099f4e544a3bd5aeb19648aa375.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : b795bdd77e4a482b9a9f02e95c6265a9.jpg\n",
            "image width: 1022, image height: 767\n",
            "image file name is : 54b6db77f5af4725905fa9a484b47eb6.jpg\n",
            "image width: 1024, image height: 688\n",
            "image file name is : 0cf6f70839744b368628e76565b4f929.jpg\n",
            "image width: 1024, image height: 680\n",
            "image file name is : e7ba899824474560b5138439a4369042.jpg\n",
            "image width: 1024, image height: 681\n",
            "image file name is : d6356669cbe24fce8d332236440d1cb1.jpg\n",
            "image width: 1024, image height: 645\n",
            "image file name is : 84e61db9138e476fb27f2747b0410a46.jpg\n",
            "image width: 800, image height: 600\n",
            "image file name is : b51a7c73dc684153926cfebef56601dd.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : fce9385d27b34a1292d5ab53267477a1.jpg\n",
            "image width: 1024, image height: 648\n",
            "image file name is : e4a1ba9194de486f9bf55ce6bb071928.jpg\n",
            "image width: 1024, image height: 735\n",
            "image file name is : 41723d4addea49328ad1ff07c2e655c4.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : cc284ba9f4c24723bb8d67b443137287.jpg\n",
            "image width: 1024, image height: 776\n",
            "image file name is : 81835f98485b42128a85538678deddbf.jpg\n",
            "image width: 615, image height: 960\n",
            "image file name is : 0526dd93510847b68176e0c9b2b7ff7b.jpg\n",
            "image width: 1024, image height: 680\n",
            "image file name is : 2f57999a8ea3429bb2e4b15e44f7cff2.jpg\n",
            "image width: 640, image height: 427\n",
            "image file name is : ed6cb4c825034cffae6326c334aada51.jpg\n",
            "image width: 1024, image height: 819\n",
            "image file name is : cf8035b710a949f38404f78d1d3dd892.jpg\n",
            "image width: 1024, image height: 725\n",
            "image file name is : 5dba41513cf542f58dd97c6128318b01.jpg\n",
            "image width: 1024, image height: 680\n",
            "image file name is : 47e39de86959469f8be96999a6db207c.jpg\n",
            "image width: 1024, image height: 681\n",
            "image file name is : fed88097b1924ea98c688d526d7afeb9.jpg\n",
            "image width: 576, image height: 720\n",
            "image file name is : 6613717a2040400ca84c66ecc8ef1984.jpg\n",
            "image width: 821, image height: 1024\n",
            "image file name is : cf4611eb0fad4d5aa117485b2f7b2a15.jpg\n",
            "image width: 1024, image height: 957\n",
            "image file name is : d42e70fdd2064442952c742f09d2bbe4.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 8cf5acb035344c3fb72318f4dad11341.jpg\n",
            "image width: 1024, image height: 680\n",
            "image file name is : bbc3c89ddd244ae2bfb70ceef8c76dd1.jpg\n",
            "image width: 800, image height: 600\n",
            "image file name is : 262d8c7a0b1348409ee1be03a73ceeb7.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 7c4eebac023942baa5bbe24842b56aaf.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : b4470e470c9d48668aa12426b61b2b54.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : 8ae0d6704421420e982b3ef838c76b51.jpg\n",
            "image width: 1024, image height: 685\n",
            "image file name is : 890fdd7bd74c46e5bb3499f0fae1340c.jpg\n",
            "image width: 1024, image height: 725\n",
            "image file name is : 70676c8da6e847449f5bacb94f35a381.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 1e87aa5ff3254029b7f830ec8f0807ee.jpg\n",
            "image width: 1024, image height: 548\n",
            "image file name is : 4028fd77e54a433b91b38579a29aeb85.jpg\n",
            "image width: 683, image height: 1024\n",
            "image file name is : 4955933ab87a427180fc5ac852c6caca.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : 135d72e702164a5aa4cba9de9b406ca3.jpg\n",
            "image width: 1024, image height: 806\n",
            "image file name is : 0027700e49154516b358a14296e16355.jpg\n",
            "image width: 1024, image height: 788\n",
            "image file name is : 62e901e1fcd64531b4ac977b21f1ae1e.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : dab79133d81445b4a3a9f25904f6c19e.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : 93974cd7b7b84bacb0f6bfd95b0fca17.jpg\n",
            "image width: 800, image height: 547\n",
            "image file name is : 745921d60df144c9949f3c2d05aa62d2.jpg\n",
            "image width: 1024, image height: 815\n",
            "image file name is : 0926902b8385414ba4cceb1350461ff2.jpg\n",
            "image width: 1024, image height: 831\n",
            "image file name is : 9fa0c76e9a7841119df04f9f51126b3f.jpg\n",
            "image width: 1024, image height: 733\n",
            "image file name is : 7ecf3808ee514f8781e5b591689aff86.jpg\n",
            "image width: 800, image height: 600\n",
            "image file name is : 0864f159c076457383e1ea134f239717.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 6d783f2e23c94beab4fe401911c969c8.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 8527054ce3944953a5b0546e1dd2cee7.jpg\n",
            "image width: 884, image height: 983\n",
            "image file name is : 8cfd768f8ac547d9940de88d6a0fc6eb.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 7105f79ffdc044b3a3e226d63ac0d6d2.jpg\n",
            "image width: 1024, image height: 630\n",
            "image file name is : 44cff8e353a84813805fe0a1468a7430.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 449eb4df1d5541ac8cd0dd3dd5fae22c.jpg\n",
            "image width: 600, image height: 480\n",
            "image file name is : 7572405849294ee48838d2c9a57bf770.jpg\n",
            "image width: 706, image height: 1024\n",
            "image file name is : 621fc342a9ca4c6abd8c29900f017c7f.jpg\n",
            "image width: 1024, image height: 700\n",
            "image file name is : b9c3c7f5a0e44ee68ddb0ba3e5177da6.jpg\n",
            "image width: 1024, image height: 681\n",
            "image file name is : 2cd8829376254ba992a4551e4df88304.jpg\n",
            "image width: 683, image height: 1024\n",
            "image file name is : d6764188e83e44e78a01d7d3a95836b6.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 9068bc4da3c1481db2535ed4fd92dff8.jpg\n",
            "image width: 606, image height: 700\n",
            "image file name is : f37f51cd4e4f4432b964ff3bfb0fcb5d.jpg\n",
            "image width: 800, image height: 641\n",
            "image file name is : 908ce447be6045d6907c0af14b66107e.jpg\n",
            "image width: 1024, image height: 725\n",
            "image file name is : 26a214278e754639bf59860221f84a96.jpg\n",
            "image width: 700, image height: 491\n",
            "image file name is : 483613a977b94b19855aa5ec9b8a5aca.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 68bb2badee6143ca8d8de920b2c4039f.jpg\n",
            "image width: 745, image height: 1024\n",
            "image file name is : 318ac82b6343478aa82ce607113d2be5.jpg\n",
            "image width: 1024, image height: 821\n",
            "image file name is : c33c5bf9ea05421d84e0f0fba8f42d83.jpg\n",
            "image width: 851, image height: 1024\n",
            "image file name is : b91f0179ae6f4ac0a7aad46d05340ef6.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 8baa3950f7bd490386b57ea26c093604.jpg\n",
            "image width: 1024, image height: 766\n",
            "image file name is : 491509007f254ce88d109b47a71d1997.jpg\n",
            "image width: 700, image height: 514\n",
            "image file name is : d7e1b97c27e245eab45873ccdeae9b38.jpg\n",
            "image width: 640, image height: 427\n",
            "image file name is : 08ddc93924674259b7a318693369bd86.jpg\n",
            "image width: 800, image height: 533\n",
            "image file name is : 3616ee8021fc4d5a8cdc7b92ab7e20e5.jpg\n",
            "image width: 1024, image height: 725\n",
            "image file name is : 3ae9e544eb9e4d30af997287b60488ab.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 0ed561adda8b43e98a9c9af8436c8ae2.jpg\n",
            "image width: 1024, image height: 805\n",
            "image file name is : bca3f034635c4146b5e68e2176add853.jpg\n",
            "image width: 800, image height: 602\n",
            "image file name is : 59e51c37bc0b4eb093e3e584f65a9dea.jpg\n",
            "image width: 1024, image height: 819\n",
            "image file name is : 419793cf2adb47ec83a1f027c222fc3c.jpg\n",
            "image width: 750, image height: 511\n",
            "image file name is : 6a853e35adc84eeaa0783a99f57273e2.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : f10d13ea211949bd8b3d9d484d8e4779.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : e339953d4a494d54a246be9df492a09c.jpg\n",
            "image width: 1024, image height: 728\n",
            "image file name is : 0384ba8f86f8472682bfb9773401eed3.jpg\n",
            "image width: 750, image height: 900\n",
            "image file name is : 85fc2e73a4294e9e848abe7d7826cca0.jpg\n",
            "image width: 1000, image height: 667\n",
            "image file name is : 93ada3d3054e4e19b9f13d3a9bfd9c18.jpg\n",
            "image width: 800, image height: 600\n",
            "image file name is : 45ca2c3e45224f99bb7ae52b0b19e976.jpg\n",
            "image width: 1024, image height: 687\n",
            "image file name is : f8e968c4a3d04e2080b694ace6292af1.jpg\n",
            "image width: 634, image height: 946\n",
            "image file name is : 4ce35a8b5ac6410db5e8ad34200369a3.jpg\n",
            "image width: 800, image height: 533\n",
            "image file name is : 7c126216d7554595b59e25772c39d7b3.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : e2a88f4c1ef34956bf5a0e6f08b62e2c.jpg\n",
            "image width: 1024, image height: 681\n",
            "image file name is : 2dc0bed6020b4100bad224cdb2d0dec4.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 711271dc101e47dab07e88e0d3d9b6c4.jpg\n",
            "image width: 1024, image height: 741\n",
            "image file name is : 1e3def6c076244c5b08df55ec3c356f2.jpg\n",
            "image width: 640, image height: 800\n",
            "image file name is : feaa4f5cc56740c6a00172872de0f635.jpg\n",
            "image width: 1024, image height: 652\n",
            "image file name is : abd8dd83d8ee4003b4d2b4045220a578.jpg\n",
            "image width: 1024, image height: 640\n",
            "image file name is : 1223b9d16550444d9a9144c696179c4a.jpg\n",
            "image width: 819, image height: 1024\n",
            "image file name is : 869604ec9d2746fb83ca7e5f92f35f50.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 2543330e6b28401695cf6a2021bba2e5.jpg\n",
            "image width: 1024, image height: 816\n",
            "image file name is : 6c7c2a89fb4e476f8db22c5c27ccf5e2.jpg\n",
            "image width: 848, image height: 535\n",
            "image file name is : 105d53e5ca394f9d99ca889ad941850d.jpg\n",
            "image width: 1024, image height: 681\n",
            "image file name is : 46b85fa20123488ea341a447cb562de4.jpg\n",
            "image width: 1024, image height: 769\n",
            "image file name is : d71db0642999458eaf77cadb63767d6a.jpg\n",
            "image width: 1024, image height: 805\n",
            "image file name is : 322d90ca6b304c8eac681f4f52dcb418.jpg\n",
            "image width: 640, image height: 441\n",
            "image file name is : c549d9cb8ddf4206a2c2da1e796520bb.jpg\n",
            "image width: 1024, image height: 666\n",
            "image file name is : f327559dfa8647a09a8a32b13a7613ac.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 91a6e1025cdf42f2b1d16fd64e8884ad.jpg\n",
            "image width: 1024, image height: 747\n",
            "image file name is : 5b740f649b1b46008280dd93c4c5f9c6.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 48159490f82a4803984555f9f8de1875.jpg\n",
            "image width: 392, image height: 585\n",
            "image file name is : 225df33dfd1b43a38a5eebe88f798b51.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 7c3d36a72d674a23baa3405fa5a49b70.jpg\n",
            "image width: 1024, image height: 819\n",
            "image file name is : fbcb8b2614b74db583fee02a9d4002f0.jpg\n",
            "image width: 500, image height: 333\n",
            "image file name is : b3a50cea9d14401297f23ad64eee19dd.jpg\n",
            "image width: 1024, image height: 680\n",
            "image file name is : 4fabd89742d440e8867c8e44834052d0.jpg\n",
            "image width: 484, image height: 600\n",
            "image file name is : ba203e68fa764d5bb65aa96219594033.jpg\n",
            "image width: 583, image height: 700\n",
            "image file name is : 1663954cb2544e0094a81d7aa40d479b.jpg\n",
            "image width: 1024, image height: 838\n",
            "image file name is : e39b6caebc1249fca2b28d5d8f19f3d5.jpg\n",
            "image width: 750, image height: 518\n",
            "image file name is : 350f50024caf4e1caa078e82e66a6041.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : cc709ec5a8db4501a673528629ed7deb.jpg\n",
            "image width: 800, image height: 533\n",
            "image file name is : d09200d7b60d415bac8f4ca6f0983c05.jpg\n",
            "image width: 1024, image height: 839\n",
            "image file name is : ba6bc4a1bdad441b8e0da1a3e2394a06.jpg\n",
            "image width: 1024, image height: 680\n",
            "image file name is : 18eb3ccff3444a69a8078f2cafb9a13b.jpg\n",
            "image width: 360, image height: 720\n",
            "image file name is : 1eece2f64a7f420099dfc1cd1b650cd6.jpg\n",
            "image width: 800, image height: 600\n",
            "image file name is : 7829bbad8c98488d8853eb23864b840a.jpg\n",
            "image width: 682, image height: 1024\n",
            "image file name is : 0a2f2765c8c74208b0a41d69fcccef2f.jpg\n",
            "image width: 1000, image height: 666\n",
            "image file name is : 3b4cbb9c9359490a9e6e303aea7c272c.jpg\n",
            "image width: 728, image height: 1024\n",
            "image file name is : 1dcee3e9fca344a38cfe76d1a67ca1d9.jpg\n",
            "image width: 1024, image height: 632\n",
            "image file name is : cf6658ffba8847eca8f663f0a8188acf.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 275714d73dc34546b8c61b604b1deecc.jpg\n",
            "image width: 1024, image height: 695\n",
            "image file name is : 309d646a66884feb8e6faf40d74a41ff.jpg\n",
            "image width: 1024, image height: 819\n",
            "image file name is : 0797b187cb7448ec8ab7ac4a02802994.jpg\n",
            "image width: 1024, image height: 771\n",
            "image file name is : c5544b1882b74cf7ac74093b45f384b0.jpg\n",
            "image width: 1024, image height: 693\n",
            "image file name is : 77e6831dbf1649e89689d3086a9e6cde.jpg\n",
            "image width: 800, image height: 800\n",
            "image file name is : ffc41f53725841d5804d8423a29c10ee.jpg\n",
            "image width: 1024, image height: 621\n",
            "image file name is : 08a9e16a69854acc8b9f47c2a4f317e9.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 862a631cc77a40ab8ea8b459bab78205.jpg\n",
            "image width: 1024, image height: 680\n",
            "image file name is : ffde854c059145489d3170f6c2ebf95a.jpg\n",
            "image width: 1024, image height: 764\n",
            "image file name is : c3362dca4a3c489cbd621076be3c8a8d.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : f3c927980f7648e3a43779c1fe981566.jpg\n",
            "image width: 667, image height: 525\n",
            "image file name is : 0ff0ed72350b44a7b7749c0a0828421c.jpg\n",
            "image width: 480, image height: 720\n",
            "image file name is : f769e177197949c3b935fe76721b2d69.jpg\n",
            "image width: 1024, image height: 681\n",
            "image file name is : d2917f3a686440a6b8996737ef949317.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : be3c4ffc1d7f4127a387245bbb761878.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : 593599d3cacd4ad6a609865648b90659.jpg\n",
            "image width: 1024, image height: 967\n",
            "image file name is : 74f37a2450b14929916257c1d66e4d5a.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : ddee1ceb49194b91ab3eeec758c54bdd.jpg\n",
            "image width: 1008, image height: 649\n",
            "image file name is : 83f471f4c51946098a47c866b74ac982.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 09dac84f3d1c4445a68ed0389fdbf1e9.jpg\n",
            "image width: 1024, image height: 727\n",
            "image file name is : b45fcdf5adf943ea851cd31d38c83eef.jpg\n",
            "image width: 1024, image height: 771\n",
            "image file name is : 91e170a114e3448cbf50dd806d928cf5.jpg\n",
            "image width: 1024, image height: 819\n",
            "image file name is : 98d32d1eb0684c25b241220034c81562.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : f3c419e43e3b49ed83f092e28c5491af.jpg\n",
            "image width: 1024, image height: 734\n",
            "image file name is : 5c906cbc08884beaaa30b35346f95dc9.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 4dabfdc0a63f4c038a2ffb512edf1c24.jpg\n",
            "image width: 1024, image height: 680\n",
            "image file name is : b0d7b604fd524a2da203978951025169.jpg\n",
            "image width: 864, image height: 613\n",
            "image file name is : 8e310ec8eed64e7d83d7ea19539c04a9.jpg\n",
            "image width: 1024, image height: 886\n",
            "image file name is : defd79400db64f95ae66ea030a423507.jpg\n",
            "image width: 800, image height: 533\n",
            "image file name is : 75a7b394da14459fab9a6fbcfa11ff8f.jpg\n",
            "image width: 750, image height: 518\n",
            "image file name is : bafe17d779474157bd74d0447363a492.jpg\n",
            "image width: 1024, image height: 799\n",
            "image file name is : 63dd8abce14949f3aa95e7e73f471880.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : ee81c322262b436a9feaf92fd83cd5d0.jpg\n",
            "image width: 522, image height: 640\n",
            "image file name is : 01ea8cf40e3e43c6a980f6874e034129.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 51e6f84c79724c9f87f04c53da264bb0.jpg\n",
            "image width: 564, image height: 860\n",
            "image file name is : 7aba974ad293482599525ba8864be70e.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : f193991df76d44b6b00b91edd6ea89d7.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : b352edb73095438f975c7e181089950e.jpg\n",
            "image width: 640, image height: 427\n",
            "image file name is : 2f499ba49c2042e892b13de46cf3a126.jpg\n",
            "image width: 1024, image height: 853\n",
            "image file name is : a355d35eba74461ebda09010a72b291f.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 846f7dc2ca454a199866d878c829543c.jpg\n",
            "image width: 1024, image height: 815\n",
            "image file name is : b1686f7cb1d7425388ff8631af9d5d40.jpg\n",
            "image width: 800, image height: 533\n",
            "image file name is : e8b9dc0649cb49b6ba7729d9196491ff.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 992e51b471d9413ea563c0ca9e712466.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : 83f6c3d77ada4977976853cb2e966597.jpg\n",
            "image width: 895, image height: 1024\n",
            "image file name is : 6564986cf917483c80d9bd64fb686988.jpg\n",
            "image width: 1024, image height: 819\n",
            "image file name is : 52d9369f83984be98c0b8f3a8f9c611d.jpg\n",
            "image width: 1024, image height: 745\n",
            "image file name is : f116336bdfac47eeaccc73b8e70ea98d.jpg\n",
            "image width: 800, image height: 706\n",
            "image file name is : ac8250a0d8c4482c9d64fdcfbf03e0d1.jpg\n",
            "image width: 800, image height: 600\n",
            "image file name is : ec50c93684094e2aa7cf25131c27ca12.jpg\n",
            "image width: 1024, image height: 706\n",
            "image file name is : 5ce79ee46c064514a065144e4d00c64f.jpg\n",
            "image width: 599, image height: 450\n",
            "image file name is : 627f2ddf224f440cb3e632c3295745da.jpg\n",
            "image width: 1024, image height: 689\n",
            "image file name is : 9d67962b6ed2447c8e92400760941b3e.jpg\n",
            "image width: 968, image height: 645\n",
            "image file name is : d34790e2b63549bcbd46d6b8bb0e9611.jpg\n",
            "image width: 838, image height: 1024\n",
            "image file name is : ea159911ba804d8f80551b4406bb4942.jpg\n",
            "image width: 768, image height: 1024\n",
            "image file name is : 585d8e44d7c64047ba77241683ff53de.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 7e6be09edcd347cba1783fe98631c4e5.jpg\n",
            "image width: 1024, image height: 638\n",
            "image file name is : 263eb341babe4f41b774a2c5f2d30386.jpg\n",
            "image width: 682, image height: 1023\n",
            "image file name is : eddb904833df4a10912ef9e38af46532.jpg\n",
            "image width: 682, image height: 1024\n",
            "image file name is : 9b5ac36e21234c0fadd0ac30d39bd432.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 25ff5e481e0e4d5295a3007537321c0b.jpg\n",
            "image width: 588, image height: 459\n",
            "image file name is : 5c8ce06e4355428284d389231be3b14c.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : fe5bf96644af46848695aac70eb7b454.jpg\n",
            "image width: 600, image height: 423\n",
            "image file name is : 49961892b17044cbb40fd2da916e8c9a.jpg\n",
            "image width: 1024, image height: 743\n",
            "image file name is : e1228fb848bb483388f051768ac58464.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : ca2fdeeec88b4ea6a4d0e0d9464ed98e.jpg\n",
            "image width: 576, image height: 456\n",
            "image file name is : fe9187230cb247debdede7f7387c725d.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 66340edb98ce48bdb5fb5c233bb8db07.jpg\n",
            "image width: 800, image height: 574\n",
            "image file name is : 18d19482b0044ffa8eaef00ad6449374.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 06acfd482b74473ab13836e9efaf107b.jpg\n",
            "image width: 700, image height: 478\n",
            "image file name is : aee853cc06ac45b2b1d4583aa284bcbd.jpg\n",
            "image width: 1024, image height: 699\n",
            "image file name is : b79b7ee9fb334214ba5e06c52a8ccbfb.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : c3249d6f538c4590aa016a1b91a37f61.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 65855728d6074178bc43108822833152.jpg\n",
            "image width: 800, image height: 558\n",
            "image file name is : de48491f2f21410b895c56335b8572ec.jpg\n",
            "image width: 600, image height: 800\n",
            "image file name is : ac8496101b8149e4ad98eaaf48d0d2bf.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 01bd8df237da43c681989c47a6dda962.jpg\n",
            "image width: 1024, image height: 819\n",
            "image file name is : d96cfb2cb9034dc888181088c122425a.jpg\n",
            "image width: 1024, image height: 648\n",
            "image file name is : 2c98dc5688d14fb5a999b6a7861f65f0.jpg\n",
            "image width: 1024, image height: 610\n",
            "image file name is : 90c0d55d70f9400f8a665951ac975ebc.jpg\n",
            "image width: 800, image height: 1024\n",
            "image file name is : 4445262f8a964833b076c6f1643b4e93.jpg\n",
            "image width: 600, image height: 493\n",
            "image file name is : c83a0f9586f4410684e23bba5636a0c0.jpg\n",
            "image width: 1024, image height: 664\n",
            "image file name is : 771e451e74434870953a22885c88ecc5.jpg\n",
            "image width: 220, image height: 160\n",
            "image file name is : af7a9c0f99dd4d958f866e49546edc17.jpg\n",
            "image width: 1024, image height: 692\n",
            "image file name is : 28b2f2da8d2640c692c83f7fbb1b377a.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : cffe82bfd0b84c4bae29052622bf929b.jpg\n",
            "image width: 1024, image height: 819\n",
            "image file name is : 9deb7762e02e43e4ba764bebd839f147.jpg\n",
            "image width: 900, image height: 611\n",
            "image file name is : adabeaca2e434d7a9062e9a9bfbcffb4.jpg\n",
            "image width: 1024, image height: 787\n",
            "image file name is : 242821042a8440038c8cf1505fad0720.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 4b642951166f4656adfcb4a0b7159277.jpg\n",
            "image width: 791, image height: 1024\n",
            "image file name is : 5da1f6307f8846c09fa206626eaf73f8.jpg\n",
            "image width: 768, image height: 1024\n",
            "image file name is : dba5d02774ee44c482a59c382885d949.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 2271dc0129ae4d2eabae9bbdc5d8a9ad.jpg\n",
            "image width: 500, image height: 375\n",
            "image file name is : 80d0eae8e35c4ba8bfdf35f536eb7c08.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 71426fdb71c24bd0949693f0dfc7a239.jpg\n",
            "image width: 1024, image height: 731\n",
            "image file name is : f271ab6e480c4c218a8ccc9f5815a7e1.jpg\n",
            "image width: 882, image height: 1024\n",
            "image file name is : 74140099bd674f16b99c1ef194e840e4.jpg\n",
            "image width: 1024, image height: 614\n",
            "image file name is : 6406472d8d80426b9a087c8ef621e4e3.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 012b3aa0eb4145f88fa4efdb228576bf.jpg\n",
            "image width: 1024, image height: 727\n",
            "image file name is : 53b8e7c0e7284de09b8e3e6a0ec1831a.jpg\n",
            "image width: 640, image height: 439\n",
            "image file name is : 58978a6da3e24c598d62f60693ecc0f6.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 4b721297e1614c77b430534949b9a0a8.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 8378f7010974447a812645b5a1d66d55.jpg\n",
            "image width: 1024, image height: 868\n",
            "image file name is : 5e067a0bc9624d91ac7d64c01056c42a.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : 16068d33247848149ed90516ca08bc90.jpg\n",
            "image width: 416, image height: 292\n",
            "image file name is : ced7fa00ab3e4c6a80b1e1cae09b2acc.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 81fe24da6e7d4415a8f0b11a9d9586fb.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 7b14682667934ba8a2f43e3e8984caa6.jpg\n",
            "image width: 1024, image height: 731\n",
            "image file name is : 19e53e6addf849478066dd9f182a710a.jpg\n",
            "image width: 900, image height: 596\n",
            "image file name is : 17ba3bb76298473088c8249fd11d1ace.jpg\n",
            "image width: 1024, image height: 767\n",
            "image file name is : 3ce64725218a42278382cf2e53265d8f.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 3790404a05b844a4b7e52c28d5fe99a0.jpg\n",
            "image width: 800, image height: 586\n",
            "image file name is : c206b76d0b784ec496601f27b5fde75c.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : 3db88337ca274cabaf3ce08773ebd285.jpg\n",
            "image width: 1024, image height: 638\n",
            "image file name is : 615053ae9a814b9398f67b838536a364.jpg\n",
            "image width: 800, image height: 480\n",
            "image file name is : 35fc93c3ca2f4ee9ab6463ea6b07d0e4.jpg\n",
            "image width: 1024, image height: 771\n",
            "image file name is : c3ad2f057a1140cfab26bcf5b0550027.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 4afdc3702eaf4e3caedb5e694e85257b.jpg\n",
            "image width: 900, image height: 589\n",
            "image file name is : 73a15d82ae5b4e2f86cb323bd245eff8.jpg\n",
            "image width: 800, image height: 800\n",
            "image file name is : 5997c424c35b4b79af1abe148551fb12.jpg\n",
            "image width: 1008, image height: 684\n",
            "image file name is : e0c4505a76624f489adf7726662aec15.jpg\n",
            "image width: 1024, image height: 699\n",
            "image file name is : b4f132da954e4132877aa4c74598e579.jpg\n",
            "image width: 700, image height: 519\n",
            "image file name is : 34fc566ca5a5481698157eaf8e8b9277.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 10214ac3a8194494b317a73fd68b7316.jpg\n",
            "image width: 1024, image height: 704\n",
            "image file name is : fde008edcd8741dfa28a424301c804c9.jpg\n",
            "image width: 641, image height: 1024\n",
            "image file name is : d2c19b8197ee465d9213bdc08dd4841d.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 8595405b95f54d3aafb4a537484b6686.jpg\n",
            "image width: 1024, image height: 679\n",
            "image file name is : 86f94a8d44e8491ab36b651f1bd649cb.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : dec042d46f27490d8a90404cc6257a70.jpg\n",
            "image width: 1024, image height: 731\n",
            "image file name is : e26420b10eb04e08a789916df0bc52ff.jpg\n",
            "image width: 1024, image height: 805\n",
            "image file name is : 7cbd19207ed543bcaccf0d9a314910be.jpg\n",
            "image width: 642, image height: 860\n",
            "image file name is : e5d969dd33844eef8a8c4f54874b7b07.jpg\n",
            "image width: 700, image height: 556\n",
            "image file name is : 8211920a6dea4195b97cca4c053c05e4.jpg\n",
            "image width: 1024, image height: 689\n",
            "image file name is : 572c410ff726400e8a254c4a38915c54.jpg\n",
            "image width: 731, image height: 1024\n",
            "image file name is : 5f8553b5702c42a69aa9cc6686b02255.jpg\n",
            "image width: 640, image height: 449\n",
            "image file name is : d6de2982196f47a58e2be061e1fed8ba.jpg\n",
            "image width: 864, image height: 576\n",
            "image file name is : 388edebf8ba34e2395253efabb41d5b2.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : ee15688958d249ce925d7eb948992fe8.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : fcbf766ac09b4957bc625fa60dd991cf.jpg\n",
            "image width: 1024, image height: 680\n",
            "image file name is : da9b244bbbcd409fbfb99ba471174075.jpg\n",
            "image width: 1024, image height: 650\n",
            "image file name is : 1cc123cd72a041af82a3465013e974fb.jpg\n",
            "image width: 1024, image height: 819\n",
            "image file name is : 4294a4ade1bb4a94964c28f58537876a.jpg\n",
            "image width: 1024, image height: 715\n",
            "image file name is : 73ea9cd2849649a9b26f8554ac34a793.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 20f2ddb2b92b4383bb4d90bcbbe43df3.jpg\n",
            "image width: 1024, image height: 613\n",
            "image file name is : 839fde902a9243ddbbb30bdc36fb267b.jpg\n",
            "image width: 1024, image height: 650\n",
            "image file name is : 48b491d36bd545d5baacb34c2574c184.jpg\n",
            "image width: 1024, image height: 689\n",
            "image file name is : 08a0b4d047e14e469276ba0790743354.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : e44aa4de24224ca78e51380329e6391b.jpg\n",
            "image width: 1024, image height: 703\n",
            "image file name is : 02570e089e3a4f4e8f8b9263b6fc978b.jpg\n",
            "image width: 1024, image height: 723\n",
            "image file name is : 32d47b0481d74450826ee26a69d01293.jpg\n",
            "image width: 684, image height: 648\n",
            "image file name is : d67663cd711e43208bac00c1f6934d17.jpg\n",
            "image width: 820, image height: 1024\n",
            "image file name is : 24d924efc791489c8aedb9b95493e7f2.jpg\n",
            "image width: 800, image height: 600\n",
            "image file name is : 5c94546c9c7b4ae09356924beeff022a.jpg\n",
            "image width: 1024, image height: 600\n",
            "image file name is : d9649181dcac46b9b4a4638fb33a8265.jpg\n",
            "image width: 1024, image height: 677\n",
            "image file name is : 01ee9f8f606240788779eb7acebf1716.jpg\n",
            "image width: 1024, image height: 731\n",
            "image file name is : fd9efb43701f4cd6baaa4c38315f4bdc.jpg\n",
            "image width: 1024, image height: 725\n",
            "image file name is : 4b7315a06bb84845b090d8f69219edd2.jpg\n",
            "image width: 1024, image height: 600\n",
            "image file name is : f245c7a3ed4c488497c4d2980de64e8c.jpg\n",
            "image width: 1024, image height: 764\n",
            "image file name is : e45b4d9d7f2f48bfb57a5199992811fc.jpg\n",
            "image width: 1024, image height: 1024\n",
            "image file name is : 3de0c50d572f41e0b7187e2d8b81ca13.jpg\n",
            "image width: 678, image height: 1024\n",
            "image file name is : cf982a4c52f741a4849ada53eb72a9c6.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : ffb950c5060f4e5b845c5e620f98bd2d.jpg\n",
            "image width: 1024, image height: 800\n",
            "image file name is : 3b4acf92646b425eb17d8a59b5344629.jpg\n",
            "image width: 683, image height: 1024\n",
            "image file name is : 70a2fbc6583948498ccd67ddb6e4d2a1.jpg\n",
            "image width: 1024, image height: 877\n",
            "image file name is : c8541b1e182c4e09992a1cb386bb3449.jpg\n",
            "image width: 450, image height: 600\n",
            "image file name is : 874ea89ddd0d4446928becb81ab46324.jpg\n",
            "image width: 817, image height: 1024\n",
            "image file name is : ce54fb8a23a34798a6fbd4ca25c3aad6.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : c4900a2d04a542b08496cda4cc52e810.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 022749ee2613437e8e95ffb4c683f597.jpg\n",
            "image width: 905, image height: 603\n",
            "image file name is : 1a0481f4ed9c471aa43d5caf87d06bf9.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 444397eb4b4b4983a0624c646cf73af5.jpg\n",
            "image width: 800, image height: 480\n",
            "image file name is : 1bf171231c8643a4ac96b7923d868beb.jpg\n",
            "image width: 600, image height: 550\n",
            "image file name is : 4901ea6a2e7b4c9091ff633068b53031.jpg\n",
            "image width: 655, image height: 825\n",
            "image file name is : cade52ce08534705b237eb30339ab95c.jpg\n",
            "image width: 844, image height: 675\n",
            "image file name is : 524aa3c82b0b4d6e822e099073414ed3.jpg\n",
            "image width: 384, image height: 480\n",
            "image file name is : 97dfe110aa2b4410be9a4fb4405e1729.jpg\n",
            "image width: 808, image height: 1024\n",
            "image file name is : 16deaf23882346a0be88c7144465e21a.jpg\n",
            "image width: 600, image height: 435\n",
            "image file name is : d76040e71b3c4e9f8cd8a31a94d5b575.jpg\n",
            "image width: 800, image height: 600\n",
            "image file name is : dc6dedc471ab4c76b4912716c66710bc.jpg\n",
            "image width: 1024, image height: 732\n",
            "image file name is : ce2bc5b765c54e07975656f7b3d188be.jpg\n",
            "image width: 700, image height: 514\n",
            "image file name is : dd1e76761d0d4839b82a988cfa73d41a.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 6eef28eea8f841be8601278e4ff23482.jpg\n",
            "image width: 1024, image height: 822\n",
            "image file name is : 255dc3aec0084ecc8420c15ca404c3e6.jpg\n",
            "image width: 800, image height: 637\n",
            "image file name is : d8fa9233852845f6875d81d5dd8586fc.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 81d7aa9d02744f49916929e4dd7c4963.jpg\n",
            "image width: 845, image height: 643\n",
            "image file name is : 2e51edb21d4b44d9b648278fb663e1be.jpg\n",
            "image width: 1024, image height: 819\n",
            "image file name is : 6abfcca3422b492f95db7a646ec9a374.jpg\n",
            "image width: 900, image height: 700\n",
            "image file name is : c3450b2454b94cf8a9f04972ff4f33fd.jpg\n",
            "image width: 732, image height: 1024\n",
            "image file name is : d3c6eb5df8a54f648fe845ebe6be9f6e.jpg\n",
            "image width: 682, image height: 1024\n",
            "image file name is : eb275612032f4cf69f5ca28435e8cd71.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : a038a9086e99459cbba1c1126b39b869.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : 7083feeb4b154f038ddf47df2b874361.jpg\n",
            "image width: 1024, image height: 820\n",
            "image file name is : 8bbb37199a5840b794e1f0eab5da56c2.jpg\n",
            "image width: 1024, image height: 659\n",
            "image file name is : 3bd2eb0c1cc34cf3ae0dce11e02a9683.jpg\n",
            "image width: 682, image height: 476\n",
            "image file name is : 09b726f56fd54bcf9386db1f98e625e8.jpg\n",
            "image width: 600, image height: 800\n",
            "image file name is : 9c6575912fbe409bbdffb966672b484c.jpg\n",
            "image width: 1024, image height: 732\n",
            "image file name is : 61b0564eb2be428a9c2a7508169269a0.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 5b3539a30eb24a5d9ed6b8ae93dcc56d.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 07d7c60e4fb1401eafd43433cfd442b3.jpg\n",
            "image width: 515, image height: 550\n",
            "image file name is : 766e5f75c8534c4882ae9f46d435353a.jpg\n",
            "image width: 600, image height: 400\n",
            "image file name is : 94628fbdda114d9992929b98c9ab0f67.jpg\n",
            "image width: 1024, image height: 717\n",
            "image file name is : 20a3ab3e9ae14cfd996e1e01aa1a8361.jpg\n",
            "image width: 1000, image height: 800\n",
            "image file name is : 7d5c4cbad99f417a8980e21552c810e6.jpg\n",
            "image width: 1024, image height: 681\n",
            "image file name is : ed48c0412507482795344446c8d74c4f.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 883b279310b247f1bbf3937c7427c70c.jpg\n",
            "image width: 800, image height: 600\n",
            "image file name is : 361c4907d1d145389f562069762a87b1.jpg\n",
            "image width: 960, image height: 597\n",
            "image file name is : 988da4d17d974a01848dfe4d26828f97.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 82c8cb379c604b89bc269f01ab7598cb.jpg\n",
            "image width: 800, image height: 600\n",
            "image file name is : e4b5a0d690e54e52bac8f8bcfef45945.jpg\n",
            "image width: 732, image height: 1024\n",
            "image file name is : 177c1d8e19804a86b47df6b05c6c77ab.jpg\n",
            "image width: 822, image height: 1024\n",
            "image file name is : bcf354cd7f5a45daa89625a7b50a9913.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : aaaf9ff50c724a3193b12b6e021ed575.jpg\n",
            "image width: 556, image height: 720\n",
            "image file name is : 4f822f3607a24013b1c7c6bc57d957aa.jpg\n",
            "image width: 626, image height: 466\n",
            "image file name is : 6afedf0d907f4fb18f446e5d78717d2e.jpg\n",
            "image width: 1024, image height: 731\n",
            "image file name is : e824ad28bd424cbabd1f6b5c5affbec6.jpg\n",
            "image width: 864, image height: 612\n",
            "image file name is : 629d0f0b2c1a4e10bc5f11cba0ab0495.jpg\n",
            "image width: 640, image height: 427\n",
            "image file name is : a4b55de4d0634681a2d1d5514ccdb6da.jpg\n",
            "image width: 1000, image height: 667\n",
            "image file name is : fcb7d19ac75146c3a7ec35f8a4720065.jpg\n",
            "image width: 630, image height: 420\n",
            "image file name is : feaa0ac44a4443ed90701d199b40fad4.jpg\n",
            "image width: 800, image height: 800\n",
            "image file name is : 655c9960b30649d8a669f19d0bff62e1.jpg\n",
            "image width: 1024, image height: 997\n",
            "image file name is : 6c93e39c82e846aaa499541dd2b403ae.jpg\n",
            "image width: 500, image height: 318\n",
            "image file name is : ead83d393a61413b9be46ce281e96754.jpg\n",
            "image width: 1024, image height: 700\n",
            "image file name is : adc234fc72874647acca1f7b5808d10f.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 74cbdc2d6c6546f6a42d7bc199e938a9.jpg\n",
            "image width: 1024, image height: 681\n",
            "image file name is : 78e9a615e3ba4f5cba2aabea70d0a927.jpg\n",
            "image width: 1024, image height: 681\n",
            "image file name is : 3edf964a0ae746239a4d2440ba0ba5ad.jpg\n",
            "image width: 422, image height: 318\n",
            "image file name is : 3bd651d0f2e6494b922b3c869e62b172.jpg\n",
            "image width: 1024, image height: 650\n",
            "image file name is : ee8a127744914cd19f0195e5e6869668.jpg\n",
            "image width: 1024, image height: 770\n",
            "image file name is : 5102f26520a44207abbf2e0c915c3e83.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 5ff1d8de0bfd4532a30c7ce408bf55ec.jpg\n",
            "image width: 860, image height: 573\n",
            "image file name is : 166f4b9fe3af4a948173389bcafa5a53.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : d6e14739e7914f7489d8b26ffa6961bf.jpg\n",
            "image width: 900, image height: 600\n",
            "image file name is : 0a94d110865d46ea8111e4c58e1538fd.jpg\n",
            "image width: 702, image height: 606\n",
            "image file name is : fedd806586b4420c9c808b62484bd52e.jpg\n",
            "image width: 1024, image height: 685\n",
            "image file name is : 8e786b02731e4cf98a0bc6b3e0e15bbd.jpg\n",
            "image width: 900, image height: 645\n",
            "image file name is : 5798ea8e525c444eb65d8bd80c9c54a7.jpg\n",
            "image width: 900, image height: 600\n",
            "image file name is : 619020090cc949139e99f7fbba7944d7.jpg\n",
            "image width: 768, image height: 1024\n",
            "image file name is : b442cdcf470845a58624fa6b748b51d6.jpg\n",
            "image width: 1024, image height: 680\n",
            "image file name is : 0fb8f692c05c4eb0aa642aacbddf2a41.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : 0127b94b24f04db3ba40cd2aea811b6c.jpg\n",
            "image width: 640, image height: 450\n",
            "image file name is : 42d2d36d597048379fe0dc3483b980a8.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 46d913e4591a456b8424bcabcdda97cf.jpg\n",
            "image width: 800, image height: 533\n",
            "image file name is : 0fa84c05bdb349d59d4193f16261cb1b.jpg\n",
            "image width: 1024, image height: 816\n",
            "image file name is : c8f178925ed147c5967b07276cb613e0.jpg\n",
            "image width: 1024, image height: 666\n",
            "image file name is : 2487041e963a4c95a4773b81136dcf68.jpg\n",
            "image width: 1024, image height: 819\n",
            "image file name is : 1fa10ad4a657406fa95d85a3266ec509.jpg\n",
            "image width: 800, image height: 600\n",
            "image file name is : d3db10a6ebc1440b85132c2e653290d6.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : b6f0393e32394907aae8670fcef5a1c9.jpg\n",
            "image width: 1024, image height: 775\n",
            "image file name is : 3689f83bbd234d84ba57d94dc448a975.jpg\n",
            "image width: 792, image height: 612\n",
            "image file name is : e89159a1738d47248465d34e99bff03e.jpg\n",
            "image width: 1024, image height: 680\n",
            "image file name is : d2888d4de413429498c22ba3f2600c13.jpg\n",
            "image width: 1024, image height: 532\n",
            "image file name is : 147dfd2459b4428ea248e3b004c486f2.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : b87d99289e7d4d1484ae3d9376ead7b1.jpg\n",
            "image width: 1024, image height: 747\n",
            "image file name is : a28f1ccdb9e24374805fa9fc2c480bab.jpg\n",
            "image width: 800, image height: 800\n",
            "image file name is : 1248515d2db842239e3e92be23ed4bd7.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : cdffdbdfef2c49d6afc9bf9249cdea21.jpg\n",
            "image width: 1024, image height: 665\n",
            "image file name is : 15dd28f803e74e0ab340e15d48a5a5c9.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : dc8ad32c58434c7fb41785899ab3e4cc.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 8b9bc07e554d427fabc4a5048da6fb3f.jpg\n",
            "image width: 700, image height: 554\n",
            "image file name is : b7970912400241c3b16f94609d1e9afc.jpg\n",
            "image width: 618, image height: 800\n",
            "image file name is : 4499aa4b88584a61ae72a06b2b4f9cd3.jpg\n",
            "image width: 800, image height: 800\n",
            "image file name is : 24fc18b33cd24c3ab138652faf602d75.jpg\n",
            "image width: 1024, image height: 819\n",
            "image file name is : 3a0cb68b64774231a0d375317f8dc474.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 42afd7ed51a244ee9e210db2e52cf65c.jpg\n",
            "image width: 1024, image height: 818\n",
            "image file name is : 1cd69a76c5c3495fa50208a58e8dcebd.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : 82d4195b742e4552a371c889614e023a.jpg\n",
            "image width: 1024, image height: 617\n",
            "image file name is : 587e95b35cbc4cd083d97ffe8b8e669c.jpg\n",
            "image width: 1024, image height: 967\n",
            "image file name is : cb61bbe3d4f4495db0fa59fd049f505b.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : d493a2c866eb44b4be022f327b700b7c.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 21fc055d0bc64f4b968b9cf983514c56.jpg\n",
            "image width: 1024, image height: 725\n",
            "image file name is : 0d6de1bb480148b19dc0b0a74d1faf8a.jpg\n",
            "image width: 1024, image height: 785\n",
            "image file name is : 1263aae36689451b8efe601df0ebdec3.jpg\n",
            "image width: 569, image height: 640\n",
            "image file name is : 2beeb5f7a3664a5098514e4f0aba3649.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : a18170cf6a784d5b8bf868f00a1d5cb6.jpg\n",
            "image width: 1024, image height: 681\n",
            "image file name is : 0b0079f8621240049ccd31247a174392.jpg\n",
            "image width: 750, image height: 503\n",
            "image file name is : 341eb7dcf05349eaba315e8fdcc0bc89.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : ae0f35add10f4d9d80bbb8a553358e38.jpg\n",
            "image width: 1024, image height: 974\n",
            "image file name is : efbf83c87acd4063bf6487b2f2372efa.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : d2878288eeea4b5dbcfb6ada0617bc66.jpg\n",
            "image width: 800, image height: 641\n",
            "image file name is : b3c6be2764784dcb846ea3a0dc29707c.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 9f105d2b860d4887a2da09caa6fa3614.jpg\n",
            "image width: 819, image height: 1024\n",
            "image file name is : 2c865a6bc89947d080a7dd6379a60ac2.jpg\n",
            "image width: 938, image height: 1024\n",
            "image file name is : bdc16535d48a457496f3ce518da70b4b.jpg\n",
            "image width: 1024, image height: 680\n",
            "image file name is : a1b2d46c4ab94bed9e6fed298b101bf4.jpg\n",
            "image width: 1024, image height: 824\n",
            "image file name is : 9dc097ae0f0341debe7170211925e83f.jpg\n",
            "image width: 800, image height: 533\n",
            "image file name is : b1b019e949fb4180a09464cc9f35a49e.jpg\n",
            "image width: 700, image height: 509\n",
            "image file name is : 1c5ec83cff3a4acea6d2cb12ddded2cd.jpg\n",
            "image width: 1024, image height: 684\n",
            "image file name is : 535224dc0a094bdeb44c3cc75a588c9c.jpg\n",
            "image width: 1024, image height: 819\n",
            "image file name is : 20125777de5c44c1b72dae93d09ffbb8.jpg\n",
            "image width: 800, image height: 613\n",
            "image file name is : 0bed55025bc14b60bf9e4caf1716e8c8.jpg\n",
            "image width: 1024, image height: 1024\n",
            "image file name is : a13ee2a2010c472a90b1bb245c35958e.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 835e79ce947e42be9b33b02ec0679c0c.jpg\n",
            "image width: 968, image height: 726\n",
            "image file name is : 5995f4a8fa8246f88760fd7800a5ca34.jpg\n",
            "image width: 1024, image height: 685\n",
            "image file name is : 5f7994eefce1481ba5b256c23f8c6c40.jpg\n",
            "image width: 681, image height: 1024\n",
            "image file name is : d7a8265cdc64428899a63214f1ce4e84.jpg\n",
            "image width: 1024, image height: 812\n",
            "image file name is : b5d5d07b552f4c5b991453528cb55f31.jpg\n",
            "image width: 1024, image height: 757\n",
            "image file name is : ab37a3ba64ad4e51969ec509c04bae52.jpg\n",
            "image width: 687, image height: 860\n",
            "image file name is : 1407b85ba1c645b198843b24203efadb.jpg\n",
            "image width: 650, image height: 850\n",
            "image file name is : ca459a17ed7646dea3ee8a0174e0ca7c.jpg\n",
            "image width: 1024, image height: 680\n",
            "image file name is : 1af301e808be435390ca13f35e3d737b.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 048beb361a6745adacb56152aeb3cf9b.jpg\n",
            "image width: 489, image height: 326\n",
            "image file name is : 12efca5c3118474885948eefcaa81f65.jpg\n",
            "image width: 1024, image height: 681\n",
            "image file name is : 9cd6ab0917da485aa24becc169aab777.jpg\n",
            "image width: 1024, image height: 662\n",
            "image file name is : 9935d6cbec8c412a93fdb95ce192d17a.jpg\n",
            "image width: 1024, image height: 870\n",
            "image file name is : 6cc58642a952402399d979b81d8b22b0.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : e8273cdb866c4e438de7d44a29fc29e8.jpg\n",
            "image width: 672, image height: 825\n",
            "image file name is : e90a815fc463477f9c6694b3321d4f8f.jpg\n",
            "image width: 800, image height: 533\n",
            "image file name is : 704d44a8667843c2b9127cb429d04c9c.jpg\n",
            "image width: 654, image height: 800\n",
            "image file name is : b652afdeaea7463a934b76d4d09b196e.jpg\n",
            "image width: 864, image height: 560\n",
            "image file name is : 798216148961403aa77761e386eb8843.jpg\n",
            "image width: 1024, image height: 796\n",
            "image file name is : bf0e8a49e07f4a4f9f6ed1954aa00653.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 076a4d8e57a949c2a8014a53112de525.jpg\n",
            "image width: 600, image height: 860\n",
            "image file name is : 6ea706877eff4afabe293fcbb480463f.jpg\n",
            "image width: 736, image height: 800\n",
            "image file name is : 276a685e560b42afbf395bb3d99f2249.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : d16303d6fef743eea5525c4fd00355aa.jpg\n",
            "image width: 640, image height: 512\n",
            "image file name is : 26662830b1f9452c902c921f0716bde3.jpg\n",
            "image width: 504, image height: 360\n",
            "image file name is : 600f583eb67f4483b4a51352cf9f5eb1.jpg\n",
            "image width: 1024, image height: 820\n",
            "image file name is : 2892fb8f81d44838a5a7d1acee9c2832.jpg\n",
            "image width: 800, image height: 607\n",
            "image file name is : 26b96f11bc2e45669c48c0525b21a2c5.jpg\n",
            "image width: 1024, image height: 656\n",
            "image file name is : 02c62e0fa18d4ce0ab8f79803b1becab.jpg\n",
            "image width: 500, image height: 330\n",
            "image file name is : 56571a3fd6484116be2df05037f94f6a.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : c2f9a662dd244083b59d9735a528d0ef.jpg\n",
            "image width: 600, image height: 800\n",
            "image file name is : d44da646f4d44b53b58e80631276f4a2.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 6de9e8d10a684fa5aef381afa5154ac2.jpg\n",
            "image width: 643, image height: 494\n",
            "image file name is : 6e9c5ffa654447bd90d7e161ddccc78f.jpg\n",
            "image width: 1024, image height: 760\n",
            "image file name is : 775b10373a9e484992c91d7511a90069.jpg\n",
            "image width: 794, image height: 1024\n",
            "image file name is : a22906f5eb6042779ed424281d1e68db.jpg\n",
            "image width: 1024, image height: 699\n",
            "image file name is : 6dc6faef45fc450ea66bafea328d0dba.jpg\n",
            "image width: 1024, image height: 706\n",
            "image file name is : ca14bfa3d65745cf9792d1c8834e2973.jpg\n",
            "image width: 1024, image height: 769\n",
            "image file name is : 88dcffaaa4674abd946de94d87a5be53.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : a95696d5c43e44ff936535822820d838.jpg\n",
            "image width: 1024, image height: 830\n",
            "image file name is : fe00d177f34d442a88cacfec0f10a679.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : dfc5ce8832f24b3cbbf7907777646283.jpg\n",
            "image width: 1024, image height: 821\n",
            "image file name is : 69a55b9395f444679543ef01d9aecdaf.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 8329e0476035420292922447b7ad1f00.jpg\n",
            "image width: 1024, image height: 820\n",
            "image file name is : a296cc6b38ba40c5ae744531362b1179.jpg\n",
            "image width: 640, image height: 513\n",
            "image file name is : a2fed7c4deca4463835c8ef01ada5e74.jpg\n",
            "image width: 750, image height: 500\n",
            "image file name is : ba33ad4190ca43a18ad2990bc9a464fa.jpg\n",
            "image width: 1024, image height: 770\n",
            "image file name is : 774f15586dcf4729ad2f148d34bea254.jpg\n",
            "image width: 1024, image height: 680\n",
            "image file name is : 1ffce85b446644dabbd168cf15a8ba31.jpg\n",
            "image width: 681, image height: 1024\n",
            "image file name is : c815756b7caa4d34a5e7ce4ef70fe978.jpg\n",
            "image width: 1024, image height: 843\n",
            "image file name is : c46f8a36b7b142fcbba1238e779b0386.jpg\n",
            "image width: 1024, image height: 731\n",
            "image file name is : 7b2f221c42e345aa8c66c7e83f3e585e.jpg\n",
            "image width: 859, image height: 687\n",
            "image file name is : e2390aaaeaf64908b3829db1957a93af.jpg\n",
            "image width: 1024, image height: 823\n",
            "image file name is : 9497ab6d863049b9bb746939f881e2ca.jpg\n",
            "image width: 640, image height: 800\n",
            "image file name is : dc5126af9deb44659d92b0f1a03868ae.jpg\n",
            "image width: 686, image height: 860\n",
            "image file name is : 4f348140baf54b559d5c65875cf777b1.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : e75089a0867c409882821bda9946a0de.jpg\n",
            "image width: 600, image height: 452\n",
            "image file name is : e14799585e46430c97ca8fe7ed030f3a.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 9d3ce71cfbcb42309f47450ee9502511.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : c3cc479f39d74c2e978976c82f76e884.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : 09805fd31da843f6a3921d93f2403023.jpg\n",
            "image width: 1024, image height: 685\n",
            "image file name is : 3a49c7131785471f8844997693d42cad.jpg\n",
            "image width: 679, image height: 1024\n",
            "image file name is : 9e1c156b272e4270806dc2195fd9d719.jpg\n",
            "image width: 800, image height: 587\n",
            "image file name is : 8621afe2c12942ef83cefe0285caee10.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 3429cb86c2694005908fc7c0ea81da93.jpg\n",
            "image width: 720, image height: 576\n",
            "image file name is : b29c4bf38eee4ee49bd31601049ed2ad.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 6c08f768d5bd4b41941c1053da996396.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : bb92984e5d4d458d96bada8f42ee4987.jpg\n",
            "image width: 1024, image height: 747\n",
            "image file name is : 373ea70579a240e7a8ab885b80bcd1a1.jpg\n",
            "image width: 1024, image height: 680\n",
            "image file name is : f927ff4aed814793a5856c5e8a23e513.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 1ee3eef3d8b54ba499154b43b51ff77a.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 56187cd8d1244c1d8c6cb41d9b7ff0c7.jpg\n",
            "image width: 800, image height: 600\n",
            "image file name is : 6620b5aa23964668b1fae6abc6757e38.jpg\n",
            "image width: 810, image height: 528\n",
            "image file name is : 2f89a3e232fa40d99ee2aa5d7d23dca5.jpg\n",
            "image width: 1024, image height: 732\n",
            "image file name is : 1a67c0a1150545898ea866a214810950.jpg\n",
            "image width: 683, image height: 1024\n",
            "image file name is : 35cb14d18c294e289eecf83809372010.jpg\n",
            "image width: 1024, image height: 677\n",
            "image file name is : efe53dc36a384bb9a3271e15d6a5f9ad.jpg\n",
            "image width: 1024, image height: 819\n",
            "image file name is : 127bc0a86d114c77983ae40efc4a9261.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : f9d24be2ed504909b672142576759325.jpg\n",
            "image width: 1024, image height: 680\n",
            "image file name is : c413d8e098b242f3bb85e4d7fc313552.jpg\n",
            "image width: 834, image height: 1024\n",
            "image file name is : 9a681a1fe42f4f95a67c03464b221d41.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : caa7a5f1654e4e9e9d689f79f81ebe1d.jpg\n",
            "image width: 1024, image height: 680\n",
            "image file name is : 9657986bff8649b2a22f24a206a808e6.jpg\n",
            "image width: 732, image height: 1024\n",
            "image file name is : 55b82354f05543759cac37689757c99c.jpg\n",
            "image width: 1024, image height: 794\n",
            "image file name is : b1e6f496973043768d6a1a12d54cca99.jpg\n",
            "image width: 916, image height: 1024\n",
            "image file name is : a5c160132a9941b096f888e2882eafd6.jpg\n",
            "image width: 640, image height: 491\n",
            "image file name is : 5d70dccb2305451b942bd5352fc87f2d.jpg\n",
            "image width: 800, image height: 533\n",
            "image file name is : 22dd855501c54ca784e16b4188ab1be9.jpg\n",
            "image width: 640, image height: 524\n",
            "image file name is : fcaf5ac2232949be8ef4a4934cfeee22.jpg\n",
            "image width: 1024, image height: 818\n",
            "image file name is : 4f4bd5dcf97e459eb8543c9c7c9ec190.jpg\n",
            "image width: 1024, image height: 689\n",
            "image file name is : 2b815316102d4d2dac05d5ab8bca7414.jpg\n",
            "image width: 825, image height: 711\n",
            "image file name is : 4bfd009dd64d4bdcbe4633d9022d908f.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 0b7fb2abe93742b29c15214db822dff1.jpg\n",
            "image width: 1024, image height: 680\n",
            "image file name is : 865ab5213ca04bb98c31b7b0f3b07a72.jpg\n",
            "image width: 683, image height: 1024\n",
            "image file name is : bdd0955fea4e400aa79766e3c6db86b1.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 6d8a0df2dcab4df78958aa7dc5e71183.jpg\n",
            "image width: 1024, image height: 864\n",
            "image file name is : c4d2ef6843b94bf6b6a313a36cb9a912.jpg\n",
            "image width: 1024, image height: 690\n",
            "image file name is : a1ea4f5a70874d3ead0ce5acd008b06f.jpg\n",
            "image width: 771, image height: 621\n",
            "image file name is : f2956bc417a84983bbd03df981ff5727.jpg\n",
            "image width: 1024, image height: 684\n",
            "image file name is : f332e14e132a4571808586fee57d4f6e.jpg\n",
            "image width: 1024, image height: 817\n",
            "image file name is : 1b23f74cd653414fbfc0ee41295cc7ef.jpg\n",
            "image width: 1024, image height: 685\n",
            "image file name is : d051cd44707e4d6c9979360c6864c981.jpg\n",
            "image width: 1024, image height: 732\n",
            "image file name is : 5e71ec1da0584588bf162559cf58a864.jpg\n",
            "image width: 640, image height: 427\n",
            "image file name is : 27cb34f7f1264865952aa34777c27b22.jpg\n",
            "image width: 383, image height: 480\n",
            "image file name is : 6c0328792f8a4510ad800db63612eb90.jpg\n",
            "image width: 1024, image height: 727\n",
            "image file name is : c2fca360401042958a0ff166f4a924f0.jpg\n",
            "image width: 533, image height: 640\n",
            "image file name is : c9d7531d311f42eebf6671eb0d814a22.jpg\n",
            "image width: 700, image height: 536\n",
            "image file name is : 347f619d21a14eaa957f7a5e16378b4c.jpg\n",
            "image width: 1024, image height: 686\n",
            "image file name is : 9a8b77257ad74a17953cb369b8a8646e.jpg\n",
            "image width: 601, image height: 860\n",
            "image file name is : 832cb68ee8c84eb9b342364005e32c8d.jpg\n",
            "image width: 694, image height: 1024\n",
            "image file name is : 22ea76d349e34a30b6064c371eb62745.jpg\n",
            "image width: 816, image height: 612\n",
            "image file name is : 8608293786d44939861ebe5ea8a6b96e.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : 8f7a1516871046898cb6e5c0692b6fdc.jpg\n",
            "image width: 800, image height: 533\n",
            "image file name is : ab4bcda3f8f7427d822729b5273e3581.jpg\n",
            "image width: 960, image height: 721\n",
            "image file name is : aa15a8bacdea4b0a9451759f496673a3.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : f5281d2105f74266b7d18713f5b010c0.jpg\n",
            "image width: 1024, image height: 612\n",
            "image file name is : b2ce00394c7b4cc2833bd1aff24c03b6.jpg\n",
            "image width: 600, image height: 448\n",
            "image file name is : df6bd42cb24c47749eea1424ebbee4e8.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 2369928b958848bc931744cd92dac6aa.jpg\n",
            "image width: 1024, image height: 819\n",
            "image file name is : 131df260d4334fd09dfb343fec47b4bd.jpg\n",
            "image width: 1024, image height: 681\n",
            "image file name is : 2b594bb568e447279dd8de7272769626.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : a229251a30a141b29b7b19ba81c03efd.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 887decbfab7c44929ed4b1971808fcfb.jpg\n",
            "image width: 816, image height: 703\n",
            "image file name is : ca983c46b24a47af82d51338f9efba27.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : 75484f2767724cac8cc80d2df75c585c.jpg\n",
            "image width: 1024, image height: 791\n",
            "image file name is : 2a7d030b008d4adc99acac15ecbe7bfd.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 5ef00e4f5a934c0fa80cd41bc5f390bc.jpg\n",
            "image width: 1024, image height: 666\n",
            "image file name is : af4213923d234c12954c858ce2aa353c.jpg\n",
            "image width: 1024, image height: 680\n",
            "image file name is : d76e7430b97a47b9b51d2c0b5b30726b.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 0ae84fa3403b49b9b62cfb8685c8a3b8.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : 66259a763d0d4936b1981b336324f8c7.jpg\n",
            "image width: 842, image height: 578\n",
            "image file name is : faafd301066c441c833d5c469c8a29c0.jpg\n",
            "image width: 1015, image height: 675\n",
            "image file name is : b82e518f6ddc46d9a990fce646a09a3b.jpg\n",
            "image width: 640, image height: 480\n",
            "image file name is : 164a5a45d46e45d8a17815880dbff559.jpg\n",
            "image width: 819, image height: 1024\n",
            "image file name is : 9abe48f7c8c24bd5b89eef4fb4b41fb6.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 8e46263d21b04b7c8d29142445a95d8e.jpg\n",
            "image width: 717, image height: 1024\n",
            "image file name is : ab24e63487b64bcca29ef5046f6d2563.jpg\n",
            "image width: 1024, image height: 781\n",
            "image file name is : 0c893472ced74923b3ecf643942a4e49.jpg\n",
            "image width: 800, image height: 618\n",
            "image file name is : 1173fd0526db411ca3dc4eb44c7470ba.jpg\n",
            "image width: 1024, image height: 682\n",
            "image file name is : e78ad3f11c814254bca4f316f678f2ad.jpg\n",
            "image width: 600, image height: 426\n",
            "image file name is : 3a91ee2c708146a3a6ee061c6ef46eca.jpg\n",
            "image width: 974, image height: 1024\n",
            "image file name is : c0bcca8b7c8d4637991044505c1c812c.jpg\n",
            "image width: 900, image height: 537\n",
            "image file name is : cd1a2c0fad2c4684a37a3bc33d40aef4.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 70a5ca0a68674731820040b12c563a7b.jpg\n",
            "image width: 640, image height: 427\n",
            "image file name is : 7da6b778fade435f9bb9790c2e2ec553.jpg\n",
            "image width: 512, image height: 640\n",
            "image file name is : 66e0646f435d4f9488cba6425bfc761c.jpg\n",
            "image width: 1024, image height: 661\n",
            "image file name is : 86080648b89749738e117dfee4e11c7a.jpg\n",
            "image width: 681, image height: 1024\n",
            "image file name is : cea988a50d07439dbe52daa8e57658cb.jpg\n",
            "image width: 800, image height: 593\n",
            "image file name is : 879fbcb722a744aeb4eb87fb8d5e23b3.jpg\n",
            "image width: 1024, image height: 802\n",
            "image file name is : baa420c6cfb84321b4cbc3c14b5d6625.jpg\n",
            "image width: 1024, image height: 701\n",
            "image file name is : e935ab803f914639b45a9db2cfdeae04.jpg\n",
            "image width: 748, image height: 979\n",
            "image file name is : bad9fbbae6a24c26896969bbec3d6f77.jpg\n",
            "image width: 731, image height: 1024\n",
            "image file name is : 332924bdd8f04733873447ddd99bc889.jpg\n",
            "image width: 800, image height: 800\n",
            "image file name is : 139d13a8f60540f8b2d35752ffb01ed8.jpg\n",
            "image width: 1024, image height: 712\n",
            "image file name is : 1c0ce75847884ec6bc1d8fa4d8f7b17e.jpg\n",
            "image width: 800, image height: 600\n",
            "image file name is : 94e0d01ff43b4a8986df692d4bff2f55.jpg\n",
            "image width: 579, image height: 450\n",
            "image file name is : 2af3dabeecb1488e990ca7dfea537ece.jpg\n",
            "image width: 1024, image height: 673\n",
            "image file name is : 47e03282fadf4e45aa934e11b4de052c.jpg\n",
            "image width: 640, image height: 513\n",
            "image file name is : bcdfd4256ea349e897a56b01c815b907.jpg\n",
            "image width: 640, image height: 465\n",
            "image file name is : 6d601c8cc2df4b079ead479e14807fd3.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 6dda2af907b1402c91f35b5b9c5f8f2c.jpg\n",
            "image width: 800, image height: 600\n",
            "image file name is : 948d20ad504742528797afdf988a0aa7.jpg\n",
            "image width: 537, image height: 700\n",
            "image file name is : f4fcebe43e314bcea1eb4a1b55274bc5.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 1a4f110ab8da4d38b472dad5358388b7.jpg\n",
            "image width: 1024, image height: 725\n",
            "image file name is : 9d81a1681e4743c1aafaf2c8736bae40.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 94924a6f2a764b44b8f6146b08d87ef6.jpg\n",
            "image width: 800, image height: 600\n",
            "image file name is : 145491d9b2ea40ca90728b798e5922ab.jpg\n",
            "image width: 800, image height: 533\n",
            "image file name is : b1f807d048bf47c194c1c1f94e47c89f.jpg\n",
            "image width: 1024, image height: 1022\n",
            "image file name is : fa0069d11d0449f5b8f24dc9e517f5c8.jpg\n",
            "image width: 600, image height: 526\n",
            "image file name is : bf08cf7890f149e48e3818afbdd76638.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 2747385f89524bee9c2199cb56114770.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 217e236622d34ce1a924bc17a7a90c99.jpg\n",
            "image width: 1024, image height: 768\n",
            "image file name is : 876e00f01664471ea67a004fcedb6e32.jpg\n",
            "image width: 1024, image height: 636\n",
            "image file name is : f3b28401ad4446849d01ff9ffea9e95c.jpg\n",
            "image width: 800, image height: 509\n",
            "image file name is : 2368d5d193c24d5f91f1068c57d19daf.jpg\n",
            "image width: 773, image height: 552\n",
            "image file name is : 06bf7fac4f504367a9380e17f31fcf59.jpg\n",
            "image width: 1024, image height: 780\n",
            "image file name is : 4bb462bd1e96425b9db0752ce540dce8.jpg\n",
            "image width: 683, image height: 1024\n",
            "image file name is : 0cd6b0ce32b94f30b6238e2b85344aeb.jpg\n",
            "image width: 852, image height: 721\n",
            "image file name is : 10b6e7c21e7a41f9a3864cbe487f1a3e.jpg\n",
            "image width: 1024, image height: 683\n",
            "image file name is : 07b09c938da74389a5cd052480ff523f.jpg\n",
            "image width: 900, image height: 600\n",
            "image file name is : 888d35ddf17944a899d239cf79bd374f.jpg\n",
            "image width: 315, image height: 420\n",
            "image file name is : 8e0e2631203d42099c4645a9ee2f7a78.jpg\n",
            "image width: 600, image height: 450\n",
            "image file name is : 8e8ab5fe0cfc49cd96432c02c6fee395.jpg\n",
            "image width: 522, image height: 315\n",
            "image file name is : b54b3351e5f944e6a2a45f0de92e585b.jpg\n",
            "image width: 800, image height: 533\n",
            "image file name is : 628803a86ac342e6b1ab0a1757d1d53f.jpg\n",
            "image width: 1024, image height: 725\n",
            "image file name is : b1a5ff4385264be299b7f0b4654269ca.jpg\n",
            "image width: 1024, image height: 904\n",
            "image file name is : 8f5b113a4d024ae0aacd24065cb13e33.jpg\n",
            "image width: 1024, image height: 750\n",
            "image file name is : 5ff36e82c5b14a179566f38e20f52946.jpg\n",
            "image width: 1024, image height: 594\n",
            "image file name is : a21945949ff44f428577f109f5cdf922.jpg\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-faf5157a06de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;31m# Convert the PIL image to Torch tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mimg_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'image width: {img_size[0]}, image height: {img_size[1]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \"\"\"\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpil_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mpil_to_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;31m# handle PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;31m# put it from HWC to CHW format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m             \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mclass\u001b[0m \u001b[0mArrayData\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;31m# unpack data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "\n",
        "TEST_PATH = 'extracted_birds/birds/test/0'\n",
        "# Read a PIL image\n",
        "for img_file in os.listdir(TEST_PATH):\n",
        "  print(f'image file name is : {img_file}')\n",
        "  # Read a PIL image\n",
        "  image = Image.open(os.path.join(TEST_PATH, img_file))\n",
        "\n",
        "  # Define a transform to convert PIL \n",
        "  # image to a Torch tensor\n",
        "  transform = transforms.Compose([\n",
        "      transforms.PILToTensor()\n",
        "  ])\n",
        "\n",
        "  # Convert the PIL image to Torch tensor\n",
        "  img_tensor = transform(image)\n",
        "  img_size = transforms.functional.get_image_size(img_tensor)\n",
        "  print(f'image width: {img_size[0]}, image height: {img_size[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bq0UqOxAJWVi"
      },
      "source": [
        "## Process Dataset and Data Augmentation\n",
        "\n",
        "### Potential parameters to experiment:\n",
        "\n",
        "* img_size\n",
        "* batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_LALIHOMt1O"
      },
      "outputs": [],
      "source": [
        "def get_birds_data(augmentation=0, img_size=128, batch_size=64):\n",
        "  transform_train = transforms.Compose([\n",
        "    transforms.Resize(img_size),\n",
        "    transforms.RandomCrop(img_size, padding=8, padding_mode='edge'),\n",
        "    transforms.RandomHorizontalFlip(),    # 50% of time flip image along y-axis\n",
        "    transforms.ToTensor(),\n",
        "    # using imagenet mean and std \n",
        "    # https://pytorch.org/hub/pytorch_vision_resnet/ mentions these values\n",
        "    # https://stackoverflow.com/questions/58151507/why-pytorch-officially-use-mean-0-485-0-456-0-406-and-std-0-229-0-224-0-2\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "  ])\n",
        "\n",
        "  transform_test = transforms.Compose([\n",
        "    transforms.Resize(img_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "  ])\n",
        "\n",
        "  # using imageFolder \n",
        "  # https://pytorch.org/vision/main/generated/torchvision.datasets.DatasetFolder.html#torchvision.datasets.DatasetFolder\n",
        "  train_ds = datasets.ImageFolder(root='extracted_birds/birds/train', transform=transform_train)\n",
        "  # Random split, 90% train set and 10% validation set\n",
        "  train_set_size = int(len(train_ds) * 0.9)\n",
        "  valid_set_size = len(train_ds) - train_set_size\n",
        "  # fix the random seed to find patterns with hyperparameters and train better\n",
        "  train_set, valid_set = random_split(train_ds, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(47))\n",
        "  trainloader = DataLoader(train_set, batch_size=batch_size, shuffle=True,\n",
        "                                            num_workers=2)\n",
        "  validloader = DataLoader(valid_set, batch_size=1, shuffle=True,\n",
        "                                            num_workers=2)\n",
        "\n",
        "  test_ds = datasets.ImageFolder(root='extracted_birds/birds/test', transform=transform_test)\n",
        "  # batch size might not need to be as big as the one for trainloader/validloader\n",
        "  testloader = DataLoader(test_ds, batch_size=1, shuffle=False,\n",
        "                                          num_workers=2)\n",
        "  \n",
        "  # get all classes, since each line represents a name for each class\n",
        "  classes = open('extracted_birds/birds/names.txt').read().strip().split('\\n')\n",
        "  # train_ds.class_to_idx: dictionary mapping class name to class index \n",
        "  # idx is a label (int) of each class (folder name), in our case folder names are also numbers\n",
        "  # https://github.com/pytorch/vision/blob/caf12f840037193fb3d1e6c60168c37dfa218f43/torchvision/datasets/folder.py#L35\n",
        "  idx_to_class = {int(idx) : int(class_name) for class_name, idx in train_ds.class_to_idx.items()}\n",
        "  idx_to_name = {k: classes[v] for k,v in idx_to_class.items()}\n",
        "  \n",
        "  return {'train': trainloader, 'valid': validloader, 'test': testloader, 'to_class': idx_to_class, 'to_name':idx_to_name}\n",
        "\n",
        "# data = get_birds_data()\n",
        "# print(data['train'].__dict__)\n",
        "# print(data['test'].__dict__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfdlsFdcCk5o"
      },
      "source": [
        "### Define Functions Used For Fine-tuning Pre-Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Pf9ysofh0ZY"
      },
      "outputs": [],
      "source": [
        "# add step size and gamma values for scheduler\n",
        "# add logic for loading checkpoints\n",
        "# add checkpoint path, checkpoint state parameters\n",
        "# add start epoch, initialize to 0, only update when there is a checkpoint state\n",
        "\n",
        "def train(net, dataloader, checkpoint=None, ck_path=None, epochs=1, lr=0.01, \n",
        "          momentum=0.9, decay=0.0, verbose=1, step_size=3, gamma=0.1):\n",
        "  net.to(device)\n",
        "  net.train()\n",
        "  start_epoch = 0\n",
        "  # keep track of used learning rates for plotting\n",
        "  lrs = []\n",
        "  losses = []\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=decay)\n",
        "  # use a step scheduler for learning rate schedules\n",
        "  # https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR\n",
        "  # https://neptune.ai/blog/how-to-choose-a-learning-rate-scheduler\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "  # https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html\n",
        "  if checkpoint:\n",
        "    net.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    losses = checkpoint['losses']\n",
        "\n",
        "  for epoch in range(start_epoch, epochs):\n",
        "    sum_loss = 0.0\n",
        "    for i, batch in enumerate(dataloader, 0):\n",
        "      # get the inputs; data is a list of [inputs, labels]\n",
        "      inputs, labels = batch[0].to(device), batch[1].to(device)\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # forward + backward + optimize \n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()  # autograd magic, computes all the partial derivatives\n",
        "      optimizer.step() # takes a step in gradient direction\n",
        "      \n",
        "\n",
        "      # print statistics\n",
        "      losses.append(loss.item())\n",
        "      sum_loss += loss.item()\n",
        "      if i % 10 == 9:    # print every 10 mini-batches\n",
        "        if verbose:\n",
        "          print('[%d, %5d] loss: %.3f' % (epoch, i + 1, sum_loss / 10))\n",
        "        sum_loss = 0.0\n",
        "\n",
        "    if ck_path:\n",
        "      # save current checkpoint into a pickle file\n",
        "      torch.save({\n",
        "                  'epoch': epoch + 1,\n",
        "                  'model_state_dict': net.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'losses': losses,\n",
        "                 }, os.path.join(CK_PATH, 'ck-%d.pkl' % (epoch + 1)))\n",
        "      \n",
        "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
        "    scheduler.step()\n",
        "  return losses\n",
        "\n",
        "def accuracy(net, dataloader):\n",
        "  net.to(device)\n",
        "  # turn off specific parts of the model (i.e., dropouts, batchnorm layers)\n",
        "  # for evaluation so gradients are not used\n",
        "  net.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for batch in dataloader:\n",
        "      images, labels = batch[0].to(device), batch[1].to(device)\n",
        "      outputs = net(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "  return correct/total\n",
        "\n",
        "def predict(net, dataloader, ofname):\n",
        "  out = open(ofname, 'w')\n",
        "  out.write(\"path,class\\n\")\n",
        "  net.to(device)\n",
        "  net.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for i, (images, labels) in enumerate(dataloader, 0):\n",
        "      if i%100 == 0:\n",
        "        print(i)\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = net(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      fname, _ = dataloader.dataset.samples[i]\n",
        "      out.write(\"test/{},{}\\n\".format(fname.split('/')[-1], data['to_class'][predicted.item()]))\n",
        "  out.close()\n",
        "\n",
        "def smooth(x, size):\n",
        "  return np.convolve(x, np.ones(size)/size, mode='valid')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPgnaRU4C4na"
      },
      "source": [
        "## Define Pre-Trained Model For Image Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e319e2f21d8f4c788ef5cfc224c3e066",
            "9733453223654c14a5d294286888a0b9",
            "db35611c78bc43b4956e573e4fc4a67c",
            "806ff75186ab418384219c4b0d12458f",
            "b53969318c674eeaa7e0475b56c0e30f",
            "8e59caa21973457fa00ec2a47fd5f24d",
            "4a6218a816f5490ab4fa963e67e30a8e",
            "3c1591dbe9d344de8b589a28c72335bb",
            "919d85ab996d418990010667416af1d2",
            "e85d3686e1a94c57aa256481d56003fb",
            "804ec67a8d6d4ad5af8774e55f8abe2b"
          ]
        },
        "id": "N-aDGyECCjiS",
        "outputId": "2c625dea-595c-49e3-d70a-783b17c25692"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e319e2f21d8f4c788ef5cfc224c3e066",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,    10] loss: 6.371\n",
            "[1,    20] loss: 6.267\n",
            "[1,    30] loss: 6.174\n",
            "[1,    40] loss: 5.957\n",
            "[1,    50] loss: 5.671\n",
            "[1,    60] loss: 5.370\n",
            "[1,    70] loss: 5.215\n",
            "[1,    80] loss: 4.932\n",
            "[1,    90] loss: 4.740\n",
            "[1,   100] loss: 4.673\n",
            "[1,   110] loss: 4.291\n",
            "[1,   120] loss: 4.355\n",
            "[1,   130] loss: 4.109\n",
            "[1,   140] loss: 4.068\n",
            "[1,   150] loss: 4.027\n",
            "[1,   160] loss: 3.911\n",
            "[1,   170] loss: 3.799\n",
            "[1,   180] loss: 3.671\n",
            "[1,   190] loss: 3.673\n",
            "[1,   200] loss: 3.675\n",
            "[1,   210] loss: 3.607\n",
            "[1,   220] loss: 3.575\n",
            "[1,   230] loss: 3.531\n",
            "[1,   240] loss: 3.441\n",
            "[1,   250] loss: 3.271\n",
            "[1,   260] loss: 3.361\n",
            "[1,   270] loss: 3.262\n",
            "[1,   280] loss: 3.367\n",
            "[1,   290] loss: 3.126\n",
            "[1,   300] loss: 3.185\n",
            "[1,   310] loss: 3.137\n",
            "[1,   320] loss: 3.164\n",
            "[1,   330] loss: 3.013\n",
            "[1,   340] loss: 3.030\n",
            "[1,   350] loss: 2.803\n",
            "[1,   360] loss: 2.995\n",
            "[1,   370] loss: 2.949\n",
            "[1,   380] loss: 3.017\n",
            "[1,   390] loss: 2.952\n",
            "[1,   400] loss: 2.935\n",
            "[1,   410] loss: 2.832\n",
            "[1,   420] loss: 2.875\n",
            "[1,   430] loss: 2.868\n",
            "[1,   440] loss: 2.996\n",
            "[1,   450] loss: 2.929\n",
            "[1,   460] loss: 2.898\n",
            "[1,   470] loss: 2.781\n",
            "[1,   480] loss: 2.828\n",
            "[1,   490] loss: 2.887\n",
            "[1,   500] loss: 2.676\n",
            "[1,   510] loss: 2.826\n",
            "[1,   520] loss: 2.746\n",
            "[1,   530] loss: 2.770\n",
            "[1,   540] loss: 2.569\n",
            "[2,    10] loss: 2.432\n",
            "[2,    20] loss: 2.299\n",
            "[2,    30] loss: 2.457\n",
            "[2,    40] loss: 2.401\n",
            "[2,    50] loss: 2.384\n",
            "[2,    60] loss: 2.344\n",
            "[2,    70] loss: 2.406\n",
            "[2,    80] loss: 2.289\n",
            "[2,    90] loss: 2.478\n",
            "[2,   100] loss: 2.392\n",
            "[2,   110] loss: 2.471\n",
            "[2,   120] loss: 2.438\n",
            "[2,   130] loss: 2.355\n",
            "[2,   140] loss: 2.368\n",
            "[2,   150] loss: 2.382\n",
            "[2,   160] loss: 2.417\n",
            "[2,   170] loss: 2.248\n",
            "[2,   180] loss: 2.300\n",
            "[2,   190] loss: 2.361\n",
            "[2,   200] loss: 2.309\n",
            "[2,   210] loss: 2.279\n",
            "[2,   220] loss: 2.293\n",
            "[2,   230] loss: 2.341\n",
            "[2,   240] loss: 2.305\n",
            "[2,   250] loss: 2.247\n",
            "[2,   260] loss: 2.258\n",
            "[2,   270] loss: 2.041\n",
            "[2,   280] loss: 2.248\n",
            "[2,   290] loss: 2.253\n",
            "[2,   300] loss: 2.332\n",
            "[2,   310] loss: 2.321\n",
            "[2,   320] loss: 2.261\n",
            "[2,   330] loss: 2.137\n",
            "[2,   340] loss: 2.311\n",
            "[2,   350] loss: 2.098\n",
            "[2,   360] loss: 2.149\n",
            "[2,   370] loss: 2.271\n",
            "[2,   380] loss: 2.203\n",
            "[2,   390] loss: 2.175\n",
            "[2,   400] loss: 2.274\n",
            "[2,   410] loss: 2.162\n",
            "[2,   420] loss: 2.139\n",
            "[2,   430] loss: 2.212\n",
            "[2,   440] loss: 2.185\n",
            "[2,   450] loss: 2.097\n",
            "[2,   460] loss: 2.240\n",
            "[2,   470] loss: 2.089\n",
            "[2,   480] loss: 2.147\n",
            "[2,   490] loss: 2.242\n",
            "[2,   500] loss: 2.161\n",
            "[2,   510] loss: 2.277\n",
            "[2,   520] loss: 2.207\n",
            "[2,   530] loss: 2.108\n",
            "[2,   540] loss: 2.101\n",
            "[3,    10] loss: 1.933\n",
            "[3,    20] loss: 1.987\n",
            "[3,    30] loss: 2.032\n",
            "[3,    40] loss: 1.929\n",
            "[3,    50] loss: 1.838\n",
            "[3,    60] loss: 1.797\n",
            "[3,    70] loss: 1.788\n",
            "[3,    80] loss: 1.881\n",
            "[3,    90] loss: 1.866\n",
            "[3,   100] loss: 1.844\n",
            "[3,   110] loss: 1.925\n",
            "[3,   120] loss: 1.864\n",
            "[3,   130] loss: 1.817\n",
            "[3,   140] loss: 1.841\n",
            "[3,   150] loss: 1.875\n",
            "[3,   160] loss: 1.762\n",
            "[3,   170] loss: 1.737\n",
            "[3,   180] loss: 1.802\n",
            "[3,   190] loss: 1.852\n",
            "[3,   200] loss: 1.848\n",
            "[3,   210] loss: 1.756\n",
            "[3,   220] loss: 1.904\n",
            "[3,   230] loss: 1.860\n",
            "[3,   240] loss: 1.796\n",
            "[3,   250] loss: 1.794\n",
            "[3,   260] loss: 1.738\n",
            "[3,   270] loss: 1.804\n",
            "[3,   280] loss: 1.862\n",
            "[3,   290] loss: 1.999\n",
            "[3,   300] loss: 1.826\n",
            "[3,   310] loss: 1.979\n",
            "[3,   320] loss: 1.747\n",
            "[3,   330] loss: 1.840\n",
            "[3,   340] loss: 1.798\n",
            "[3,   350] loss: 1.843\n",
            "[3,   360] loss: 1.745\n",
            "[3,   370] loss: 1.719\n",
            "[3,   380] loss: 1.766\n",
            "[3,   390] loss: 1.930\n",
            "[3,   400] loss: 1.734\n",
            "[3,   410] loss: 1.891\n",
            "[3,   420] loss: 1.924\n",
            "[3,   430] loss: 1.817\n",
            "[3,   440] loss: 1.903\n",
            "[3,   450] loss: 1.792\n",
            "[3,   460] loss: 1.891\n",
            "[3,   470] loss: 1.732\n",
            "[3,   480] loss: 1.730\n",
            "[3,   490] loss: 1.798\n",
            "[3,   500] loss: 1.895\n",
            "[3,   510] loss: 1.885\n",
            "[3,   520] loss: 1.832\n",
            "[3,   530] loss: 1.799\n",
            "[3,   540] loss: 1.942\n",
            "[4,    10] loss: 1.566\n",
            "[4,    20] loss: 1.587\n",
            "[4,    30] loss: 1.562\n",
            "[4,    40] loss: 1.605\n",
            "[4,    50] loss: 1.478\n",
            "[4,    60] loss: 1.589\n",
            "[4,    70] loss: 1.666\n",
            "[4,    80] loss: 1.531\n",
            "[4,    90] loss: 1.648\n",
            "[4,   100] loss: 1.439\n",
            "[4,   110] loss: 1.483\n",
            "[4,   120] loss: 1.509\n",
            "[4,   130] loss: 1.583\n",
            "[4,   140] loss: 1.589\n",
            "[4,   150] loss: 1.551\n",
            "[4,   160] loss: 1.478\n",
            "[4,   170] loss: 1.501\n",
            "[4,   180] loss: 1.618\n",
            "[4,   190] loss: 1.532\n",
            "[4,   200] loss: 1.595\n",
            "[4,   210] loss: 1.655\n",
            "[4,   220] loss: 1.582\n",
            "[4,   230] loss: 1.538\n",
            "[4,   240] loss: 1.624\n",
            "[4,   250] loss: 1.509\n",
            "[4,   260] loss: 1.605\n",
            "[4,   270] loss: 1.545\n",
            "[4,   280] loss: 1.655\n",
            "[4,   290] loss: 1.484\n",
            "[4,   300] loss: 1.526\n",
            "[4,   310] loss: 1.582\n",
            "[4,   320] loss: 1.545\n",
            "[4,   330] loss: 1.690\n",
            "[4,   340] loss: 1.602\n",
            "[4,   350] loss: 1.578\n",
            "[4,   360] loss: 1.688\n",
            "[4,   370] loss: 1.541\n",
            "[4,   380] loss: 1.459\n",
            "[4,   390] loss: 1.532\n",
            "[4,   400] loss: 1.557\n",
            "[4,   410] loss: 1.582\n",
            "[4,   420] loss: 1.725\n",
            "[4,   430] loss: 1.595\n",
            "[4,   440] loss: 1.465\n",
            "[4,   450] loss: 1.566\n",
            "[4,   460] loss: 1.568\n",
            "[4,   470] loss: 1.628\n",
            "[4,   480] loss: 1.413\n",
            "[4,   490] loss: 1.673\n",
            "[4,   500] loss: 1.701\n",
            "[4,   510] loss: 1.573\n",
            "[4,   520] loss: 1.655\n",
            "[4,   530] loss: 1.590\n",
            "[4,   540] loss: 1.620\n",
            "[5,    10] loss: 1.427\n",
            "[5,    20] loss: 1.377\n",
            "[5,    30] loss: 1.418\n",
            "[5,    40] loss: 1.251\n",
            "[5,    50] loss: 1.251\n",
            "[5,    60] loss: 1.382\n",
            "[5,    70] loss: 1.343\n",
            "[5,    80] loss: 1.259\n",
            "[5,    90] loss: 1.378\n",
            "[5,   100] loss: 1.314\n",
            "[5,   110] loss: 1.372\n",
            "[5,   120] loss: 1.378\n",
            "[5,   130] loss: 1.348\n",
            "[5,   140] loss: 1.346\n",
            "[5,   150] loss: 1.429\n",
            "[5,   160] loss: 1.327\n",
            "[5,   170] loss: 1.463\n",
            "[5,   180] loss: 1.425\n",
            "[5,   190] loss: 1.463\n",
            "[5,   200] loss: 1.415\n",
            "[5,   210] loss: 1.402\n",
            "[5,   220] loss: 1.310\n",
            "[5,   230] loss: 1.314\n",
            "[5,   240] loss: 1.416\n",
            "[5,   250] loss: 1.401\n",
            "[5,   260] loss: 1.440\n",
            "[5,   270] loss: 1.613\n",
            "[5,   280] loss: 1.448\n",
            "[5,   290] loss: 1.351\n",
            "[5,   300] loss: 1.453\n",
            "[5,   310] loss: 1.531\n",
            "[5,   320] loss: 1.454\n",
            "[5,   330] loss: 1.437\n",
            "[5,   340] loss: 1.295\n",
            "[5,   350] loss: 1.478\n",
            "[5,   360] loss: 1.418\n",
            "[5,   370] loss: 1.321\n",
            "[5,   380] loss: 1.496\n",
            "[5,   390] loss: 1.435\n",
            "[5,   400] loss: 1.410\n",
            "[5,   410] loss: 1.427\n",
            "[5,   420] loss: 1.606\n",
            "[5,   430] loss: 1.213\n",
            "[5,   440] loss: 1.513\n",
            "[5,   450] loss: 1.346\n",
            "[5,   460] loss: 1.445\n",
            "[5,   470] loss: 1.485\n",
            "[5,   480] loss: 1.463\n",
            "[5,   490] loss: 1.436\n",
            "[5,   500] loss: 1.471\n",
            "[5,   510] loss: 1.400\n",
            "[5,   520] loss: 1.420\n",
            "[5,   530] loss: 1.369\n",
            "[5,   540] loss: 1.388\n",
            "[6,    10] loss: 1.385\n",
            "[6,    20] loss: 1.174\n",
            "[6,    30] loss: 1.132\n",
            "[6,    40] loss: 1.062\n",
            "[6,    50] loss: 0.962\n",
            "[6,    60] loss: 1.004\n",
            "[6,    70] loss: 0.944\n",
            "[6,    80] loss: 0.974\n",
            "[6,    90] loss: 0.939\n",
            "[6,   100] loss: 0.951\n",
            "[6,   110] loss: 0.900\n",
            "[6,   120] loss: 0.888\n",
            "[6,   130] loss: 0.979\n",
            "[6,   140] loss: 0.814\n",
            "[6,   150] loss: 0.914\n",
            "[6,   160] loss: 0.892\n",
            "[6,   170] loss: 0.749\n",
            "[6,   180] loss: 0.843\n",
            "[6,   190] loss: 0.909\n",
            "[6,   200] loss: 0.878\n",
            "[6,   210] loss: 0.845\n",
            "[6,   220] loss: 0.803\n",
            "[6,   230] loss: 0.846\n",
            "[6,   240] loss: 0.796\n",
            "[6,   250] loss: 0.772\n",
            "[6,   260] loss: 0.867\n",
            "[6,   270] loss: 0.801\n",
            "[6,   280] loss: 0.831\n",
            "[6,   290] loss: 0.906\n",
            "[6,   300] loss: 0.777\n",
            "[6,   310] loss: 0.843\n",
            "[6,   320] loss: 0.826\n",
            "[6,   330] loss: 0.780\n",
            "[6,   340] loss: 0.789\n",
            "[6,   350] loss: 0.797\n",
            "[6,   360] loss: 0.770\n",
            "[6,   370] loss: 0.741\n",
            "[6,   380] loss: 0.763\n",
            "[6,   390] loss: 0.788\n",
            "[6,   400] loss: 0.762\n",
            "[6,   410] loss: 0.747\n",
            "[6,   420] loss: 0.774\n",
            "[6,   430] loss: 0.811\n",
            "[6,   440] loss: 0.736\n",
            "[6,   450] loss: 0.767\n",
            "[6,   460] loss: 0.729\n",
            "[6,   470] loss: 0.704\n",
            "[6,   480] loss: 0.769\n",
            "[6,   490] loss: 0.734\n",
            "[6,   500] loss: 0.816\n",
            "[6,   510] loss: 0.711\n",
            "[6,   520] loss: 0.743\n",
            "[6,   530] loss: 0.745\n",
            "[6,   540] loss: 0.722\n",
            "[7,    10] loss: 0.698\n",
            "[7,    20] loss: 0.649\n",
            "[7,    30] loss: 0.704\n",
            "[7,    40] loss: 0.645\n",
            "[7,    50] loss: 0.739\n",
            "[7,    60] loss: 0.615\n",
            "[7,    70] loss: 0.635\n",
            "[7,    80] loss: 0.692\n",
            "[7,    90] loss: 0.705\n",
            "[7,   100] loss: 0.719\n",
            "[7,   110] loss: 0.690\n",
            "[7,   120] loss: 0.693\n",
            "[7,   130] loss: 0.653\n",
            "[7,   140] loss: 0.700\n",
            "[7,   150] loss: 0.667\n",
            "[7,   160] loss: 0.724\n",
            "[7,   170] loss: 0.585\n",
            "[7,   180] loss: 0.654\n",
            "[7,   190] loss: 0.657\n",
            "[7,   200] loss: 0.697\n",
            "[7,   210] loss: 0.752\n",
            "[7,   220] loss: 0.654\n",
            "[7,   230] loss: 0.730\n",
            "[7,   240] loss: 0.721\n",
            "[7,   250] loss: 0.651\n",
            "[7,   260] loss: 0.703\n",
            "[7,   270] loss: 0.661\n",
            "[7,   280] loss: 0.631\n",
            "[7,   290] loss: 0.602\n",
            "[7,   300] loss: 0.683\n",
            "[7,   310] loss: 0.619\n",
            "[7,   320] loss: 0.651\n",
            "[7,   330] loss: 0.669\n",
            "[7,   340] loss: 0.644\n",
            "[7,   350] loss: 0.684\n",
            "[7,   360] loss: 0.651\n",
            "[7,   370] loss: 0.642\n",
            "[7,   380] loss: 0.711\n",
            "[7,   390] loss: 0.626\n",
            "[7,   400] loss: 0.702\n",
            "[7,   410] loss: 0.662\n",
            "[7,   420] loss: 0.665\n",
            "[7,   430] loss: 0.588\n",
            "[7,   440] loss: 0.736\n",
            "[7,   450] loss: 0.622\n",
            "[7,   460] loss: 0.665\n",
            "[7,   470] loss: 0.622\n",
            "[7,   480] loss: 0.678\n",
            "[7,   490] loss: 0.659\n",
            "[7,   500] loss: 0.697\n",
            "[7,   510] loss: 0.665\n",
            "[7,   520] loss: 0.709\n",
            "[7,   530] loss: 0.681\n",
            "[7,   540] loss: 0.725\n",
            "[8,    10] loss: 0.614\n",
            "[8,    20] loss: 0.652\n",
            "[8,    30] loss: 0.644\n",
            "[8,    40] loss: 0.654\n",
            "[8,    50] loss: 0.601\n",
            "[8,    60] loss: 0.603\n",
            "[8,    70] loss: 0.545\n",
            "[8,    80] loss: 0.677\n",
            "[8,    90] loss: 0.622\n",
            "[8,   100] loss: 0.578\n",
            "[8,   110] loss: 0.597\n",
            "[8,   120] loss: 0.666\n",
            "[8,   130] loss: 0.615\n",
            "[8,   140] loss: 0.664\n",
            "[8,   150] loss: 0.608\n",
            "[8,   160] loss: 0.612\n",
            "[8,   170] loss: 0.595\n",
            "[8,   180] loss: 0.593\n",
            "[8,   190] loss: 0.592\n",
            "[8,   200] loss: 0.630\n",
            "[8,   210] loss: 0.630\n",
            "[8,   220] loss: 0.570\n",
            "[8,   230] loss: 0.658\n",
            "[8,   240] loss: 0.602\n",
            "[8,   250] loss: 0.518\n",
            "[8,   260] loss: 0.624\n",
            "[8,   270] loss: 0.558\n",
            "[8,   280] loss: 0.580\n",
            "[8,   290] loss: 0.615\n",
            "[8,   300] loss: 0.576\n",
            "[8,   310] loss: 0.635\n",
            "[8,   320] loss: 0.607\n",
            "[8,   330] loss: 0.636\n",
            "[8,   340] loss: 0.614\n",
            "[8,   350] loss: 0.618\n",
            "[8,   360] loss: 0.648\n",
            "[8,   370] loss: 0.605\n",
            "[8,   380] loss: 0.567\n",
            "[8,   390] loss: 0.632\n",
            "[8,   400] loss: 0.633\n",
            "[8,   410] loss: 0.529\n",
            "[8,   420] loss: 0.561\n",
            "[8,   430] loss: 0.622\n",
            "[8,   440] loss: 0.623\n",
            "[8,   450] loss: 0.622\n",
            "[8,   460] loss: 0.623\n",
            "[8,   470] loss: 0.674\n",
            "[8,   480] loss: 0.577\n",
            "[8,   490] loss: 0.604\n",
            "[8,   500] loss: 0.608\n",
            "[8,   510] loss: 0.614\n",
            "[8,   520] loss: 0.601\n",
            "[8,   530] loss: 0.641\n",
            "[8,   540] loss: 0.610\n",
            "[9,    10] loss: 0.559\n",
            "[9,    20] loss: 0.525\n",
            "[9,    30] loss: 0.566\n",
            "[9,    40] loss: 0.568\n",
            "[9,    50] loss: 0.540\n",
            "[9,    60] loss: 0.572\n",
            "[9,    70] loss: 0.561\n",
            "[9,    80] loss: 0.472\n",
            "[9,    90] loss: 0.630\n",
            "[9,   100] loss: 0.540\n",
            "[9,   110] loss: 0.558\n",
            "[9,   120] loss: 0.515\n",
            "[9,   130] loss: 0.615\n",
            "[9,   140] loss: 0.571\n",
            "[9,   150] loss: 0.564\n",
            "[9,   160] loss: 0.544\n",
            "[9,   170] loss: 0.629\n",
            "[9,   180] loss: 0.582\n",
            "[9,   190] loss: 0.479\n",
            "[9,   200] loss: 0.583\n",
            "[9,   210] loss: 0.588\n",
            "[9,   220] loss: 0.492\n",
            "[9,   230] loss: 0.570\n",
            "[9,   240] loss: 0.570\n",
            "[9,   250] loss: 0.609\n",
            "[9,   260] loss: 0.546\n",
            "[9,   270] loss: 0.537\n",
            "[9,   280] loss: 0.556\n",
            "[9,   290] loss: 0.597\n",
            "[9,   300] loss: 0.587\n",
            "[9,   310] loss: 0.594\n",
            "[9,   320] loss: 0.584\n",
            "[9,   330] loss: 0.553\n",
            "[9,   340] loss: 0.585\n",
            "[9,   350] loss: 0.533\n",
            "[9,   360] loss: 0.598\n",
            "[9,   370] loss: 0.568\n",
            "[9,   380] loss: 0.604\n",
            "[9,   390] loss: 0.529\n",
            "[9,   400] loss: 0.549\n",
            "[9,   410] loss: 0.465\n",
            "[9,   420] loss: 0.542\n",
            "[9,   430] loss: 0.589\n",
            "[9,   440] loss: 0.555\n",
            "[9,   450] loss: 0.593\n",
            "[9,   460] loss: 0.585\n",
            "[9,   470] loss: 0.543\n",
            "[9,   480] loss: 0.590\n",
            "[9,   490] loss: 0.626\n",
            "[9,   500] loss: 0.592\n",
            "[9,   510] loss: 0.558\n",
            "[9,   520] loss: 0.510\n",
            "[9,   530] loss: 0.582\n",
            "[9,   540] loss: 0.585\n",
            "[10,    10] loss: 0.477\n",
            "[10,    20] loss: 0.483\n",
            "[10,    30] loss: 0.516\n",
            "[10,    40] loss: 0.558\n",
            "[10,    50] loss: 0.513\n",
            "[10,    60] loss: 0.473\n",
            "[10,    70] loss: 0.513\n",
            "[10,    80] loss: 0.518\n",
            "[10,    90] loss: 0.543\n",
            "[10,   100] loss: 0.519\n",
            "[10,   110] loss: 0.568\n",
            "[10,   120] loss: 0.548\n",
            "[10,   130] loss: 0.530\n",
            "[10,   140] loss: 0.524\n",
            "[10,   150] loss: 0.503\n",
            "[10,   160] loss: 0.528\n",
            "[10,   170] loss: 0.546\n",
            "[10,   180] loss: 0.470\n",
            "[10,   190] loss: 0.552\n",
            "[10,   200] loss: 0.513\n",
            "[10,   210] loss: 0.552\n",
            "[10,   220] loss: 0.571\n",
            "[10,   230] loss: 0.548\n",
            "[10,   240] loss: 0.536\n",
            "[10,   250] loss: 0.532\n",
            "[10,   260] loss: 0.522\n",
            "[10,   270] loss: 0.575\n",
            "[10,   280] loss: 0.534\n",
            "[10,   290] loss: 0.503\n",
            "[10,   300] loss: 0.543\n",
            "[10,   310] loss: 0.534\n",
            "[10,   320] loss: 0.512\n",
            "[10,   330] loss: 0.542\n",
            "[10,   340] loss: 0.524\n",
            "[10,   350] loss: 0.480\n",
            "[10,   360] loss: 0.533\n",
            "[10,   370] loss: 0.591\n",
            "[10,   380] loss: 0.558\n",
            "[10,   390] loss: 0.547\n",
            "[10,   400] loss: 0.491\n",
            "[10,   410] loss: 0.489\n",
            "[10,   420] loss: 0.523\n",
            "[10,   430] loss: 0.510\n",
            "[10,   440] loss: 0.535\n",
            "[10,   450] loss: 0.603\n",
            "[10,   460] loss: 0.464\n",
            "[10,   470] loss: 0.509\n",
            "[10,   480] loss: 0.488\n",
            "[10,   490] loss: 0.513\n",
            "[10,   500] loss: 0.573\n",
            "[10,   510] loss: 0.496\n",
            "[10,   520] loss: 0.530\n",
            "[10,   530] loss: 0.494\n",
            "[10,   540] loss: 0.515\n",
            "[11,    10] loss: 0.519\n",
            "[11,    20] loss: 0.440\n",
            "[11,    30] loss: 0.439\n",
            "[11,    40] loss: 0.500\n",
            "[11,    50] loss: 0.444\n",
            "[11,    60] loss: 0.489\n",
            "[11,    70] loss: 0.397\n",
            "[11,    80] loss: 0.489\n",
            "[11,    90] loss: 0.465\n",
            "[11,   100] loss: 0.507\n",
            "[11,   110] loss: 0.474\n",
            "[11,   120] loss: 0.456\n",
            "[11,   130] loss: 0.490\n",
            "[11,   140] loss: 0.520\n",
            "[11,   150] loss: 0.500\n",
            "[11,   160] loss: 0.492\n",
            "[11,   170] loss: 0.535\n",
            "[11,   180] loss: 0.503\n",
            "[11,   190] loss: 0.601\n",
            "[11,   200] loss: 0.459\n",
            "[11,   210] loss: 0.509\n",
            "[11,   220] loss: 0.490\n",
            "[11,   230] loss: 0.455\n",
            "[11,   240] loss: 0.490\n",
            "[11,   250] loss: 0.524\n",
            "[11,   260] loss: 0.454\n",
            "[11,   270] loss: 0.418\n",
            "[11,   280] loss: 0.495\n",
            "[11,   290] loss: 0.464\n",
            "[11,   300] loss: 0.521\n",
            "[11,   310] loss: 0.391\n",
            "[11,   320] loss: 0.447\n",
            "[11,   330] loss: 0.508\n",
            "[11,   340] loss: 0.429\n",
            "[11,   350] loss: 0.441\n",
            "[11,   360] loss: 0.479\n",
            "[11,   370] loss: 0.429\n",
            "[11,   380] loss: 0.496\n",
            "[11,   390] loss: 0.473\n",
            "[11,   400] loss: 0.515\n",
            "[11,   410] loss: 0.491\n",
            "[11,   420] loss: 0.471\n",
            "[11,   430] loss: 0.450\n",
            "[11,   440] loss: 0.469\n",
            "[11,   450] loss: 0.455\n",
            "[11,   460] loss: 0.427\n",
            "[11,   470] loss: 0.483\n",
            "[11,   480] loss: 0.525\n",
            "[11,   490] loss: 0.438\n",
            "[11,   500] loss: 0.437\n",
            "[11,   510] loss: 0.484\n",
            "[11,   520] loss: 0.457\n",
            "[11,   530] loss: 0.449\n",
            "[11,   540] loss: 0.517\n",
            "[12,    10] loss: 0.447\n",
            "[12,    20] loss: 0.407\n",
            "[12,    30] loss: 0.439\n",
            "[12,    40] loss: 0.414\n",
            "[12,    50] loss: 0.472\n",
            "[12,    60] loss: 0.462\n",
            "[12,    70] loss: 0.550\n",
            "[12,    80] loss: 0.371\n",
            "[12,    90] loss: 0.462\n",
            "[12,   100] loss: 0.470\n",
            "[12,   110] loss: 0.494\n",
            "[12,   120] loss: 0.408\n",
            "[12,   130] loss: 0.519\n",
            "[12,   140] loss: 0.503\n",
            "[12,   150] loss: 0.433\n",
            "[12,   160] loss: 0.484\n",
            "[12,   170] loss: 0.553\n",
            "[12,   180] loss: 0.449\n",
            "[12,   190] loss: 0.404\n",
            "[12,   200] loss: 0.498\n",
            "[12,   210] loss: 0.507\n",
            "[12,   220] loss: 0.491\n",
            "[12,   230] loss: 0.455\n",
            "[12,   240] loss: 0.413\n",
            "[12,   250] loss: 0.409\n",
            "[12,   260] loss: 0.431\n",
            "[12,   270] loss: 0.495\n",
            "[12,   280] loss: 0.512\n",
            "[12,   290] loss: 0.475\n",
            "[12,   300] loss: 0.482\n",
            "[12,   310] loss: 0.456\n",
            "[12,   320] loss: 0.417\n",
            "[12,   330] loss: 0.473\n",
            "[12,   340] loss: 0.474\n",
            "[12,   350] loss: 0.448\n",
            "[12,   360] loss: 0.525\n",
            "[12,   370] loss: 0.444\n",
            "[12,   380] loss: 0.489\n",
            "[12,   390] loss: 0.479\n",
            "[12,   400] loss: 0.427\n",
            "[12,   410] loss: 0.453\n",
            "[12,   420] loss: 0.416\n",
            "[12,   430] loss: 0.498\n",
            "[12,   440] loss: 0.477\n",
            "[12,   450] loss: 0.437\n",
            "[12,   460] loss: 0.483\n",
            "[12,   470] loss: 0.444\n",
            "[12,   480] loss: 0.434\n",
            "[12,   490] loss: 0.445\n",
            "[12,   500] loss: 0.491\n",
            "[12,   510] loss: 0.478\n",
            "[12,   520] loss: 0.498\n",
            "[12,   530] loss: 0.449\n",
            "[12,   540] loss: 0.450\n",
            "[13,    10] loss: 0.452\n",
            "[13,    20] loss: 0.494\n",
            "[13,    30] loss: 0.482\n",
            "[13,    40] loss: 0.465\n",
            "[13,    50] loss: 0.470\n",
            "[13,    60] loss: 0.464\n",
            "[13,    70] loss: 0.450\n",
            "[13,    80] loss: 0.435\n",
            "[13,    90] loss: 0.531\n",
            "[13,   100] loss: 0.476\n",
            "[13,   110] loss: 0.480\n",
            "[13,   120] loss: 0.461\n",
            "[13,   130] loss: 0.460\n",
            "[13,   140] loss: 0.526\n",
            "[13,   150] loss: 0.477\n",
            "[13,   160] loss: 0.418\n",
            "[13,   170] loss: 0.446\n",
            "[13,   180] loss: 0.469\n",
            "[13,   190] loss: 0.468\n",
            "[13,   200] loss: 0.424\n",
            "[13,   210] loss: 0.507\n",
            "[13,   220] loss: 0.485\n",
            "[13,   230] loss: 0.520\n",
            "[13,   240] loss: 0.394\n",
            "[13,   250] loss: 0.499\n",
            "[13,   260] loss: 0.451\n",
            "[13,   270] loss: 0.476\n",
            "[13,   280] loss: 0.466\n",
            "[13,   290] loss: 0.445\n",
            "[13,   300] loss: 0.474\n",
            "[13,   310] loss: 0.435\n",
            "[13,   320] loss: 0.462\n",
            "[13,   330] loss: 0.449\n",
            "[13,   340] loss: 0.444\n",
            "[13,   350] loss: 0.511\n",
            "[13,   360] loss: 0.499\n",
            "[13,   370] loss: 0.449\n",
            "[13,   380] loss: 0.489\n",
            "[13,   390] loss: 0.437\n",
            "[13,   400] loss: 0.500\n",
            "[13,   410] loss: 0.522\n",
            "[13,   420] loss: 0.512\n",
            "[13,   430] loss: 0.439\n",
            "[13,   440] loss: 0.414\n",
            "[13,   450] loss: 0.454\n",
            "[13,   460] loss: 0.522\n",
            "[13,   470] loss: 0.423\n",
            "[13,   480] loss: 0.479\n",
            "[13,   490] loss: 0.411\n",
            "[13,   500] loss: 0.427\n",
            "[13,   510] loss: 0.454\n",
            "[13,   520] loss: 0.436\n",
            "[13,   530] loss: 0.500\n",
            "[13,   540] loss: 0.445\n",
            "[14,    10] loss: 0.481\n",
            "[14,    20] loss: 0.504\n",
            "[14,    30] loss: 0.499\n",
            "[14,    40] loss: 0.479\n",
            "[14,    50] loss: 0.494\n",
            "[14,    60] loss: 0.424\n",
            "[14,    70] loss: 0.463\n",
            "[14,    80] loss: 0.457\n",
            "[14,    90] loss: 0.434\n",
            "[14,   100] loss: 0.451\n",
            "[14,   110] loss: 0.478\n",
            "[14,   120] loss: 0.469\n",
            "[14,   130] loss: 0.468\n",
            "[14,   140] loss: 0.523\n",
            "[14,   150] loss: 0.499\n",
            "[14,   160] loss: 0.450\n",
            "[14,   170] loss: 0.426\n",
            "[14,   180] loss: 0.439\n",
            "[14,   190] loss: 0.445\n",
            "[14,   200] loss: 0.585\n",
            "[14,   210] loss: 0.498\n",
            "[14,   220] loss: 0.411\n",
            "[14,   230] loss: 0.504\n",
            "[14,   240] loss: 0.430\n",
            "[14,   250] loss: 0.428\n",
            "[14,   260] loss: 0.461\n",
            "[14,   270] loss: 0.465\n",
            "[14,   280] loss: 0.416\n",
            "[14,   290] loss: 0.440\n",
            "[14,   300] loss: 0.469\n",
            "[14,   310] loss: 0.423\n",
            "[14,   320] loss: 0.425\n",
            "[14,   330] loss: 0.428\n",
            "[14,   340] loss: 0.468\n",
            "[14,   350] loss: 0.479\n",
            "[14,   360] loss: 0.471\n",
            "[14,   370] loss: 0.410\n",
            "[14,   380] loss: 0.390\n",
            "[14,   390] loss: 0.494\n",
            "[14,   400] loss: 0.457\n",
            "[14,   410] loss: 0.446\n",
            "[14,   420] loss: 0.449\n",
            "[14,   430] loss: 0.422\n",
            "[14,   440] loss: 0.426\n",
            "[14,   450] loss: 0.456\n",
            "[14,   460] loss: 0.483\n",
            "[14,   470] loss: 0.441\n",
            "[14,   480] loss: 0.433\n",
            "[14,   490] loss: 0.457\n",
            "[14,   500] loss: 0.513\n",
            "[14,   510] loss: 0.438\n",
            "[14,   520] loss: 0.450\n",
            "[14,   530] loss: 0.455\n",
            "[14,   540] loss: 0.415\n",
            "[15,    10] loss: 0.413\n",
            "[15,    20] loss: 0.439\n",
            "[15,    30] loss: 0.449\n",
            "[15,    40] loss: 0.420\n",
            "[15,    50] loss: 0.427\n",
            "[15,    60] loss: 0.434\n",
            "[15,    70] loss: 0.459\n",
            "[15,    80] loss: 0.452\n",
            "[15,    90] loss: 0.448\n",
            "[15,   100] loss: 0.457\n",
            "[15,   110] loss: 0.466\n",
            "[15,   120] loss: 0.448\n",
            "[15,   130] loss: 0.443\n",
            "[15,   140] loss: 0.420\n",
            "[15,   150] loss: 0.453\n",
            "[15,   160] loss: 0.426\n",
            "[15,   170] loss: 0.456\n",
            "[15,   180] loss: 0.471\n",
            "[15,   190] loss: 0.470\n",
            "[15,   200] loss: 0.431\n",
            "[15,   210] loss: 0.443\n",
            "[15,   220] loss: 0.446\n",
            "[15,   230] loss: 0.444\n",
            "[15,   240] loss: 0.443\n",
            "[15,   250] loss: 0.472\n",
            "[15,   260] loss: 0.434\n",
            "[15,   270] loss: 0.481\n",
            "[15,   280] loss: 0.468\n",
            "[15,   290] loss: 0.466\n",
            "[15,   300] loss: 0.449\n",
            "[15,   310] loss: 0.478\n",
            "[15,   320] loss: 0.484\n",
            "[15,   330] loss: 0.472\n",
            "[15,   340] loss: 0.465\n",
            "[15,   350] loss: 0.423\n",
            "[15,   360] loss: 0.391\n",
            "[15,   370] loss: 0.449\n",
            "[15,   380] loss: 0.435\n",
            "[15,   390] loss: 0.443\n",
            "[15,   400] loss: 0.476\n",
            "[15,   410] loss: 0.427\n",
            "[15,   420] loss: 0.469\n",
            "[15,   430] loss: 0.466\n",
            "[15,   440] loss: 0.421\n",
            "[15,   450] loss: 0.493\n",
            "[15,   460] loss: 0.434\n",
            "[15,   470] loss: 0.486\n",
            "[15,   480] loss: 0.463\n",
            "[15,   490] loss: 0.418\n",
            "[15,   500] loss: 0.517\n",
            "[15,   510] loss: 0.455\n",
            "[15,   520] loss: 0.397\n",
            "[15,   530] loss: 0.476\n",
            "[15,   540] loss: 0.496\n",
            "Training   accuracy: 0.906181\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-4cfd6f9edc70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training   accuracy: %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation accuracy: %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 'validation'"
          ]
        }
      ],
      "source": [
        "# DON'T RERUN THIS CELL\n",
        "EPOCHS = 15\n",
        "IMG_SIZE = 128\n",
        "BATCH_SIZE = 64\n",
        "STEP_SIZE = 5\n",
        "GAMMA = 0.1\n",
        "DECAY = 0.00047\n",
        "\n",
        "data = get_birds_data(1, IMG_SIZE, BATCH_SIZE)\n",
        "print(data['train'].__dict__)\n",
        "print(data['test'].__dict__)\n",
        "\n",
        "# https://pytorch.org/hub/pytorch_vision_resnet/\n",
        "net = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
        "# https://www.pluralsight.com/guides/introduction-to-resnet\n",
        "# set the number of output features to be the number of classes\n",
        "net.fc = nn.Linear(net.fc.in_features, 555)\n",
        "\n",
        "losses = train(net, data['train'], epochs=EPOCHS, decay=DECAY, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "print(\"Training   accuracy: %f\" % accuracy(net, data['train']))\n",
        "print(\"Validation accuracy: %f\" % accuracy(net, data['valid']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a0cddac9856f4f3aab91ea70a210ddce",
            "9290d78dac8a41b2a3834fa884049c46",
            "b4ba8b913b8146f496ff63e18c2077ca",
            "91266558fe3942a7b6026e5bfd072de7",
            "325a044a0c33441ebca37a45068c25c4",
            "b42aa7e7948742b28da08b8cac236415",
            "b50f28647d79476096e318500a274a7d",
            "114d25ec56eb4acf9e9cb29c0ffa9189",
            "2ac2b2728a8047b99927c08c2305a08c",
            "5b78140d4e9d44d8817c3eae820a2de5",
            "659b86ae062044fa90985e9e7f846c31"
          ]
        },
        "id": "wxNZFZ5HONZU",
        "outputId": "dbae860c-bfad-4dd5-e58a-c1d057e890da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0cddac9856f4f3aab91ea70a210ddce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,    10] loss: 6.357\n",
            "[1,    20] loss: 6.310\n",
            "[1,    30] loss: 6.218\n",
            "[1,    40] loss: 6.004\n",
            "[1,    50] loss: 5.724\n",
            "[1,    60] loss: 5.589\n",
            "[1,    70] loss: 5.348\n",
            "[1,    80] loss: 5.064\n",
            "[1,    90] loss: 4.935\n",
            "[1,   100] loss: 4.747\n",
            "[1,   110] loss: 4.539\n",
            "[1,   120] loss: 4.382\n",
            "[1,   130] loss: 4.260\n",
            "[1,   140] loss: 3.973\n",
            "[1,   150] loss: 3.918\n",
            "[1,   160] loss: 3.827\n",
            "[1,   170] loss: 3.757\n",
            "[1,   180] loss: 3.575\n",
            "[1,   190] loss: 3.578\n",
            "[1,   200] loss: 3.474\n",
            "[1,   210] loss: 3.371\n",
            "[1,   220] loss: 3.283\n",
            "[1,   230] loss: 3.317\n",
            "[1,   240] loss: 3.095\n",
            "[1,   250] loss: 3.095\n",
            "[1,   260] loss: 3.035\n",
            "[1,   270] loss: 2.899\n",
            "[1,   280] loss: 2.844\n",
            "[1,   290] loss: 2.816\n",
            "[1,   300] loss: 2.778\n",
            "[1,   310] loss: 2.639\n",
            "[1,   320] loss: 2.636\n",
            "[1,   330] loss: 2.528\n",
            "[1,   340] loss: 2.722\n",
            "[1,   350] loss: 2.609\n",
            "[1,   360] loss: 2.509\n",
            "[1,   370] loss: 2.489\n",
            "[1,   380] loss: 2.523\n",
            "[1,   390] loss: 2.368\n",
            "[1,   400] loss: 2.290\n",
            "[1,   410] loss: 2.359\n",
            "[1,   420] loss: 2.212\n",
            "[1,   430] loss: 2.267\n",
            "[1,   440] loss: 2.309\n",
            "[1,   450] loss: 2.248\n",
            "[1,   460] loss: 2.260\n",
            "[1,   470] loss: 2.137\n",
            "[1,   480] loss: 2.172\n",
            "[1,   490] loss: 2.151\n",
            "[1,   500] loss: 2.061\n",
            "[1,   510] loss: 1.968\n",
            "[1,   520] loss: 2.223\n",
            "[1,   530] loss: 2.007\n",
            "[1,   540] loss: 2.041\n",
            "[2,    10] loss: 1.882\n",
            "[2,    20] loss: 1.886\n",
            "[2,    30] loss: 1.895\n",
            "[2,    40] loss: 1.700\n",
            "[2,    50] loss: 1.791\n",
            "[2,    60] loss: 1.826\n",
            "[2,    70] loss: 1.691\n",
            "[2,    80] loss: 1.824\n",
            "[2,    90] loss: 1.780\n",
            "[2,   100] loss: 1.785\n",
            "[2,   110] loss: 1.648\n",
            "[2,   120] loss: 1.691\n",
            "[2,   130] loss: 1.674\n",
            "[2,   140] loss: 1.736\n",
            "[2,   150] loss: 1.640\n",
            "[2,   160] loss: 1.585\n",
            "[2,   170] loss: 1.583\n",
            "[2,   180] loss: 1.585\n",
            "[2,   190] loss: 1.625\n",
            "[2,   200] loss: 1.594\n",
            "[2,   210] loss: 1.574\n",
            "[2,   220] loss: 1.637\n",
            "[2,   230] loss: 1.477\n",
            "[2,   240] loss: 1.519\n",
            "[2,   250] loss: 1.587\n",
            "[2,   260] loss: 1.572\n",
            "[2,   270] loss: 1.538\n",
            "[2,   280] loss: 1.437\n",
            "[2,   290] loss: 1.568\n",
            "[2,   300] loss: 1.502\n",
            "[2,   310] loss: 1.459\n",
            "[2,   320] loss: 1.573\n",
            "[2,   330] loss: 1.531\n",
            "[2,   340] loss: 1.455\n",
            "[2,   350] loss: 1.645\n",
            "[2,   360] loss: 1.602\n",
            "[2,   370] loss: 1.574\n",
            "[2,   380] loss: 1.549\n",
            "[2,   390] loss: 1.459\n",
            "[2,   400] loss: 1.537\n",
            "[2,   410] loss: 1.556\n",
            "[2,   420] loss: 1.517\n",
            "[2,   430] loss: 1.555\n",
            "[2,   440] loss: 1.458\n",
            "[2,   450] loss: 1.546\n",
            "[2,   460] loss: 1.479\n",
            "[2,   470] loss: 1.440\n",
            "[2,   480] loss: 1.500\n",
            "[2,   490] loss: 1.410\n",
            "[2,   500] loss: 1.433\n",
            "[2,   510] loss: 1.484\n",
            "[2,   520] loss: 1.436\n",
            "[2,   530] loss: 1.419\n",
            "[2,   540] loss: 1.320\n",
            "[3,    10] loss: 1.323\n",
            "[3,    20] loss: 1.269\n",
            "[3,    30] loss: 1.352\n",
            "[3,    40] loss: 1.198\n",
            "[3,    50] loss: 1.171\n",
            "[3,    60] loss: 1.188\n",
            "[3,    70] loss: 1.147\n",
            "[3,    80] loss: 1.191\n",
            "[3,    90] loss: 1.157\n",
            "[3,   100] loss: 1.281\n",
            "[3,   110] loss: 1.135\n",
            "[3,   120] loss: 1.226\n",
            "[3,   130] loss: 1.185\n",
            "[3,   140] loss: 1.096\n",
            "[3,   150] loss: 1.219\n",
            "[3,   160] loss: 1.169\n",
            "[3,   170] loss: 1.187\n",
            "[3,   180] loss: 1.123\n",
            "[3,   190] loss: 1.166\n",
            "[3,   200] loss: 1.175\n",
            "[3,   210] loss: 1.192\n",
            "[3,   220] loss: 1.157\n",
            "[3,   230] loss: 1.214\n",
            "[3,   240] loss: 1.203\n",
            "[3,   250] loss: 1.189\n",
            "[3,   260] loss: 1.284\n",
            "[3,   270] loss: 1.154\n",
            "[3,   280] loss: 1.121\n",
            "[3,   290] loss: 1.177\n",
            "[3,   300] loss: 1.090\n",
            "[3,   310] loss: 1.114\n",
            "[3,   320] loss: 1.168\n",
            "[3,   330] loss: 1.159\n",
            "[3,   340] loss: 1.182\n",
            "[3,   350] loss: 1.033\n",
            "[3,   360] loss: 1.170\n",
            "[3,   370] loss: 1.186\n",
            "[3,   380] loss: 1.168\n",
            "[3,   390] loss: 1.191\n",
            "[3,   400] loss: 1.198\n",
            "[3,   410] loss: 1.149\n",
            "[3,   420] loss: 1.155\n",
            "[3,   430] loss: 1.190\n",
            "[3,   440] loss: 1.085\n",
            "[3,   450] loss: 1.031\n",
            "[3,   460] loss: 1.215\n",
            "[3,   470] loss: 1.118\n",
            "[3,   480] loss: 1.193\n",
            "[3,   490] loss: 1.118\n",
            "[3,   500] loss: 1.094\n",
            "[3,   510] loss: 1.155\n",
            "[3,   520] loss: 1.077\n",
            "[3,   530] loss: 1.098\n",
            "[3,   540] loss: 1.194\n",
            "[4,    10] loss: 0.975\n",
            "[4,    20] loss: 0.891\n",
            "[4,    30] loss: 0.845\n",
            "[4,    40] loss: 0.774\n",
            "[4,    50] loss: 0.775\n",
            "[4,    60] loss: 0.763\n",
            "[4,    70] loss: 0.715\n",
            "[4,    80] loss: 0.786\n",
            "[4,    90] loss: 0.741\n",
            "[4,   100] loss: 0.606\n",
            "[4,   110] loss: 0.618\n",
            "[4,   120] loss: 0.720\n",
            "[4,   130] loss: 0.730\n",
            "[4,   140] loss: 0.660\n",
            "[4,   150] loss: 0.611\n",
            "[4,   160] loss: 0.705\n",
            "[4,   170] loss: 0.620\n",
            "[4,   180] loss: 0.650\n",
            "[4,   190] loss: 0.595\n",
            "[4,   200] loss: 0.610\n",
            "[4,   210] loss: 0.655\n",
            "[4,   220] loss: 0.617\n",
            "[4,   230] loss: 0.640\n",
            "[4,   240] loss: 0.642\n",
            "[4,   250] loss: 0.580\n",
            "[4,   260] loss: 0.645\n",
            "[4,   270] loss: 0.670\n",
            "[4,   280] loss: 0.623\n",
            "[4,   290] loss: 0.657\n",
            "[4,   300] loss: 0.606\n",
            "[4,   310] loss: 0.581\n",
            "[4,   320] loss: 0.613\n",
            "[4,   330] loss: 0.643\n",
            "[4,   340] loss: 0.637\n",
            "[4,   350] loss: 0.649\n",
            "[4,   360] loss: 0.574\n",
            "[4,   370] loss: 0.596\n",
            "[4,   380] loss: 0.616\n",
            "[4,   390] loss: 0.586\n",
            "[4,   400] loss: 0.618\n",
            "[4,   410] loss: 0.566\n",
            "[4,   420] loss: 0.517\n",
            "[4,   430] loss: 0.713\n",
            "[4,   440] loss: 0.583\n",
            "[4,   450] loss: 0.649\n",
            "[4,   460] loss: 0.621\n",
            "[4,   470] loss: 0.600\n",
            "[4,   480] loss: 0.571\n",
            "[4,   490] loss: 0.560\n",
            "[4,   500] loss: 0.602\n",
            "[4,   510] loss: 0.569\n",
            "[4,   520] loss: 0.575\n",
            "[4,   530] loss: 0.554\n",
            "[4,   540] loss: 0.581\n",
            "[5,    10] loss: 0.508\n",
            "[5,    20] loss: 0.525\n",
            "[5,    30] loss: 0.518\n",
            "[5,    40] loss: 0.554\n",
            "[5,    50] loss: 0.549\n",
            "[5,    60] loss: 0.573\n",
            "[5,    70] loss: 0.558\n",
            "[5,    80] loss: 0.526\n",
            "[5,    90] loss: 0.522\n",
            "[5,   100] loss: 0.547\n",
            "[5,   110] loss: 0.554\n",
            "[5,   120] loss: 0.544\n",
            "[5,   130] loss: 0.551\n",
            "[5,   140] loss: 0.531\n",
            "[5,   150] loss: 0.560\n",
            "[5,   160] loss: 0.559\n",
            "[5,   170] loss: 0.476\n",
            "[5,   180] loss: 0.502\n",
            "[5,   190] loss: 0.522\n",
            "[5,   200] loss: 0.527\n",
            "[5,   210] loss: 0.566\n",
            "[5,   220] loss: 0.508\n",
            "[5,   230] loss: 0.512\n",
            "[5,   240] loss: 0.513\n",
            "[5,   250] loss: 0.537\n",
            "[5,   260] loss: 0.519\n",
            "[5,   270] loss: 0.530\n",
            "[5,   280] loss: 0.510\n",
            "[5,   290] loss: 0.527\n",
            "[5,   300] loss: 0.543\n",
            "[5,   310] loss: 0.497\n",
            "[5,   320] loss: 0.516\n",
            "[5,   330] loss: 0.531\n",
            "[5,   340] loss: 0.466\n",
            "[5,   350] loss: 0.505\n",
            "[5,   360] loss: 0.514\n",
            "[5,   370] loss: 0.514\n",
            "[5,   380] loss: 0.497\n",
            "[5,   390] loss: 0.560\n",
            "[5,   400] loss: 0.581\n",
            "[5,   410] loss: 0.494\n",
            "[5,   420] loss: 0.556\n",
            "[5,   430] loss: 0.539\n",
            "[5,   440] loss: 0.529\n",
            "[5,   450] loss: 0.506\n",
            "[5,   460] loss: 0.522\n",
            "[5,   470] loss: 0.523\n",
            "[5,   480] loss: 0.482\n",
            "[5,   490] loss: 0.550\n",
            "[5,   500] loss: 0.526\n",
            "[5,   510] loss: 0.503\n",
            "[5,   520] loss: 0.459\n",
            "[5,   530] loss: 0.549\n",
            "[5,   540] loss: 0.502\n",
            "[6,    10] loss: 0.452\n",
            "[6,    20] loss: 0.465\n",
            "[6,    30] loss: 0.521\n",
            "[6,    40] loss: 0.476\n",
            "[6,    50] loss: 0.464\n",
            "[6,    60] loss: 0.505\n",
            "[6,    70] loss: 0.516\n",
            "[6,    80] loss: 0.469\n",
            "[6,    90] loss: 0.490\n",
            "[6,   100] loss: 0.496\n",
            "[6,   110] loss: 0.498\n",
            "[6,   120] loss: 0.472\n",
            "[6,   130] loss: 0.461\n",
            "[6,   140] loss: 0.434\n",
            "[6,   150] loss: 0.478\n",
            "[6,   160] loss: 0.478\n",
            "[6,   170] loss: 0.481\n",
            "[6,   180] loss: 0.486\n",
            "[6,   190] loss: 0.504\n",
            "[6,   200] loss: 0.515\n",
            "[6,   210] loss: 0.547\n",
            "[6,   220] loss: 0.469\n",
            "[6,   230] loss: 0.493\n",
            "[6,   240] loss: 0.512\n",
            "[6,   250] loss: 0.460\n",
            "[6,   260] loss: 0.493\n",
            "[6,   270] loss: 0.490\n",
            "[6,   280] loss: 0.470\n",
            "[6,   290] loss: 0.463\n",
            "[6,   300] loss: 0.511\n",
            "[6,   310] loss: 0.414\n",
            "[6,   320] loss: 0.452\n",
            "[6,   330] loss: 0.475\n",
            "[6,   340] loss: 0.464\n",
            "[6,   350] loss: 0.470\n",
            "[6,   360] loss: 0.462\n",
            "[6,   370] loss: 0.499\n",
            "[6,   380] loss: 0.461\n",
            "[6,   390] loss: 0.464\n",
            "[6,   400] loss: 0.464\n",
            "[6,   410] loss: 0.468\n",
            "[6,   420] loss: 0.481\n",
            "[6,   430] loss: 0.420\n",
            "[6,   440] loss: 0.447\n",
            "[6,   450] loss: 0.449\n",
            "[6,   460] loss: 0.445\n",
            "[6,   470] loss: 0.478\n",
            "[6,   480] loss: 0.479\n",
            "[6,   490] loss: 0.441\n",
            "[6,   500] loss: 0.454\n",
            "[6,   510] loss: 0.459\n",
            "[6,   520] loss: 0.474\n",
            "[6,   530] loss: 0.392\n",
            "[6,   540] loss: 0.446\n",
            "[7,    10] loss: 0.418\n",
            "[7,    20] loss: 0.414\n",
            "[7,    30] loss: 0.409\n",
            "[7,    40] loss: 0.414\n",
            "[7,    50] loss: 0.414\n",
            "[7,    60] loss: 0.425\n",
            "[7,    70] loss: 0.445\n",
            "[7,    80] loss: 0.468\n",
            "[7,    90] loss: 0.486\n",
            "[7,   100] loss: 0.425\n",
            "[7,   110] loss: 0.413\n",
            "[7,   120] loss: 0.377\n",
            "[7,   130] loss: 0.341\n",
            "[7,   140] loss: 0.470\n",
            "[7,   150] loss: 0.415\n",
            "[7,   160] loss: 0.401\n",
            "[7,   170] loss: 0.405\n",
            "[7,   180] loss: 0.413\n",
            "[7,   190] loss: 0.400\n",
            "[7,   200] loss: 0.469\n",
            "[7,   210] loss: 0.434\n",
            "[7,   220] loss: 0.432\n",
            "[7,   230] loss: 0.422\n",
            "[7,   240] loss: 0.474\n",
            "[7,   250] loss: 0.388\n",
            "[7,   260] loss: 0.416\n",
            "[7,   270] loss: 0.415\n",
            "[7,   280] loss: 0.373\n",
            "[7,   290] loss: 0.426\n",
            "[7,   300] loss: 0.421\n",
            "[7,   310] loss: 0.407\n",
            "[7,   320] loss: 0.440\n",
            "[7,   330] loss: 0.416\n",
            "[7,   340] loss: 0.420\n",
            "[7,   350] loss: 0.442\n",
            "[7,   360] loss: 0.369\n",
            "[7,   370] loss: 0.446\n",
            "[7,   380] loss: 0.452\n",
            "[7,   390] loss: 0.452\n",
            "[7,   400] loss: 0.451\n",
            "[7,   410] loss: 0.415\n",
            "[7,   420] loss: 0.402\n",
            "[7,   430] loss: 0.411\n",
            "[7,   440] loss: 0.446\n",
            "[7,   450] loss: 0.436\n",
            "[7,   460] loss: 0.440\n",
            "[7,   470] loss: 0.447\n",
            "[7,   480] loss: 0.491\n",
            "[7,   490] loss: 0.476\n",
            "[7,   500] loss: 0.436\n",
            "[7,   510] loss: 0.475\n",
            "[7,   520] loss: 0.443\n",
            "[7,   530] loss: 0.467\n",
            "[7,   540] loss: 0.454\n",
            "[8,    10] loss: 0.390\n",
            "[8,    20] loss: 0.434\n",
            "[8,    30] loss: 0.429\n",
            "[8,    40] loss: 0.472\n",
            "[8,    50] loss: 0.418\n",
            "[8,    60] loss: 0.465\n",
            "[8,    70] loss: 0.443\n",
            "[8,    80] loss: 0.405\n",
            "[8,    90] loss: 0.390\n",
            "[8,   100] loss: 0.391\n",
            "[8,   110] loss: 0.449\n",
            "[8,   120] loss: 0.435\n",
            "[8,   130] loss: 0.405\n",
            "[8,   140] loss: 0.404\n",
            "[8,   150] loss: 0.416\n",
            "[8,   160] loss: 0.458\n",
            "[8,   170] loss: 0.431\n",
            "[8,   180] loss: 0.371\n",
            "[8,   190] loss: 0.413\n",
            "[8,   200] loss: 0.406\n",
            "[8,   210] loss: 0.407\n",
            "[8,   220] loss: 0.390\n",
            "[8,   230] loss: 0.429\n",
            "[8,   240] loss: 0.417\n",
            "[8,   250] loss: 0.439\n",
            "[8,   260] loss: 0.357\n",
            "[8,   270] loss: 0.474\n",
            "[8,   280] loss: 0.423\n",
            "[8,   290] loss: 0.410\n",
            "[8,   300] loss: 0.412\n",
            "[8,   310] loss: 0.421\n",
            "[8,   320] loss: 0.438\n",
            "[8,   330] loss: 0.439\n",
            "[8,   340] loss: 0.414\n",
            "[8,   350] loss: 0.376\n",
            "[8,   360] loss: 0.461\n",
            "[8,   370] loss: 0.447\n",
            "[8,   380] loss: 0.424\n",
            "[8,   390] loss: 0.391\n",
            "[8,   400] loss: 0.424\n",
            "[8,   410] loss: 0.376\n",
            "[8,   420] loss: 0.382\n",
            "[8,   430] loss: 0.397\n",
            "[8,   440] loss: 0.462\n",
            "[8,   450] loss: 0.375\n",
            "[8,   460] loss: 0.417\n",
            "[8,   470] loss: 0.417\n",
            "[8,   480] loss: 0.437\n",
            "[8,   490] loss: 0.422\n",
            "[8,   500] loss: 0.414\n",
            "[8,   510] loss: 0.425\n",
            "[8,   520] loss: 0.415\n",
            "[8,   530] loss: 0.473\n",
            "[8,   540] loss: 0.396\n",
            "[9,    10] loss: 0.433\n",
            "[9,    20] loss: 0.428\n",
            "[9,    30] loss: 0.401\n",
            "[9,    40] loss: 0.413\n",
            "[9,    50] loss: 0.480\n",
            "[9,    60] loss: 0.433\n",
            "[9,    70] loss: 0.401\n",
            "[9,    80] loss: 0.376\n",
            "[9,    90] loss: 0.391\n",
            "[9,   100] loss: 0.380\n",
            "[9,   110] loss: 0.430\n",
            "[9,   120] loss: 0.387\n",
            "[9,   130] loss: 0.428\n",
            "[9,   140] loss: 0.427\n",
            "[9,   150] loss: 0.425\n",
            "[9,   160] loss: 0.399\n",
            "[9,   170] loss: 0.360\n",
            "[9,   180] loss: 0.368\n",
            "[9,   190] loss: 0.440\n",
            "[9,   200] loss: 0.428\n",
            "[9,   210] loss: 0.477\n",
            "[9,   220] loss: 0.410\n",
            "[9,   230] loss: 0.372\n",
            "[9,   240] loss: 0.408\n",
            "[9,   250] loss: 0.386\n",
            "[9,   260] loss: 0.437\n",
            "[9,   270] loss: 0.432\n",
            "[9,   280] loss: 0.429\n",
            "[9,   290] loss: 0.420\n",
            "[9,   300] loss: 0.448\n",
            "[9,   310] loss: 0.433\n",
            "[9,   320] loss: 0.431\n",
            "[9,   330] loss: 0.438\n",
            "[9,   340] loss: 0.430\n",
            "[9,   350] loss: 0.435\n",
            "[9,   360] loss: 0.449\n",
            "[9,   370] loss: 0.377\n",
            "[9,   380] loss: 0.398\n",
            "[9,   390] loss: 0.399\n",
            "[9,   400] loss: 0.400\n",
            "[9,   410] loss: 0.413\n",
            "[9,   420] loss: 0.442\n",
            "[9,   430] loss: 0.409\n",
            "[9,   440] loss: 0.401\n",
            "[9,   450] loss: 0.406\n",
            "[9,   460] loss: 0.378\n",
            "[9,   470] loss: 0.416\n",
            "[9,   480] loss: 0.372\n",
            "[9,   490] loss: 0.419\n",
            "[9,   500] loss: 0.414\n",
            "[9,   510] loss: 0.433\n",
            "[9,   520] loss: 0.417\n",
            "[9,   530] loss: 0.447\n",
            "[9,   540] loss: 0.425\n",
            "[10,    10] loss: 0.419\n",
            "[10,    20] loss: 0.381\n",
            "[10,    30] loss: 0.430\n",
            "[10,    40] loss: 0.418\n",
            "[10,    50] loss: 0.415\n",
            "[10,    60] loss: 0.442\n",
            "[10,    70] loss: 0.440\n",
            "[10,    80] loss: 0.388\n",
            "[10,    90] loss: 0.426\n",
            "[10,   100] loss: 0.323\n",
            "[10,   110] loss: 0.403\n",
            "[10,   120] loss: 0.411\n",
            "[10,   130] loss: 0.415\n",
            "[10,   140] loss: 0.432\n",
            "[10,   150] loss: 0.406\n",
            "[10,   160] loss: 0.431\n",
            "[10,   170] loss: 0.422\n",
            "[10,   180] loss: 0.389\n",
            "[10,   190] loss: 0.404\n",
            "[10,   200] loss: 0.405\n",
            "[10,   210] loss: 0.407\n",
            "[10,   220] loss: 0.391\n",
            "[10,   230] loss: 0.450\n",
            "[10,   240] loss: 0.367\n",
            "[10,   250] loss: 0.415\n",
            "[10,   260] loss: 0.379\n",
            "[10,   270] loss: 0.381\n",
            "[10,   280] loss: 0.370\n",
            "[10,   290] loss: 0.361\n",
            "[10,   300] loss: 0.400\n",
            "[10,   310] loss: 0.395\n",
            "[10,   320] loss: 0.400\n",
            "[10,   330] loss: 0.431\n",
            "[10,   340] loss: 0.462\n",
            "[10,   350] loss: 0.435\n",
            "[10,   360] loss: 0.372\n",
            "[10,   370] loss: 0.400\n",
            "[10,   380] loss: 0.450\n",
            "[10,   390] loss: 0.409\n",
            "[10,   400] loss: 0.444\n",
            "[10,   410] loss: 0.395\n",
            "[10,   420] loss: 0.421\n",
            "[10,   430] loss: 0.407\n",
            "[10,   440] loss: 0.405\n",
            "[10,   450] loss: 0.346\n",
            "[10,   460] loss: 0.410\n",
            "[10,   470] loss: 0.432\n",
            "[10,   480] loss: 0.374\n",
            "[10,   490] loss: 0.383\n",
            "[10,   500] loss: 0.376\n",
            "[10,   510] loss: 0.383\n",
            "[10,   520] loss: 0.415\n",
            "[10,   530] loss: 0.413\n",
            "[10,   540] loss: 0.393\n",
            "Training   accuracy: 0.920444\n",
            "Validation accuracy: 0.793622\n",
            "Testing accuracy: 0.001700\n"
          ]
        }
      ],
      "source": [
        "# DON'T RERUN THIS CELL\n",
        "EPOCHS = 10\n",
        "IMG_SIZE = 256\n",
        "BATCH_SIZE = 64\n",
        "STEP_SIZE = 3\n",
        "GAMMA = 0.1\n",
        "DECAY = 0.00047\n",
        "\n",
        "data = get_birds_data(1, IMG_SIZE, BATCH_SIZE)\n",
        "# https://pytorch.org/hub/pytorch_vision_resnet/\n",
        "net = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
        "# https://www.pluralsight.com/guides/introduction-to-resnet\n",
        "# set the number of output features to be the number of classes\n",
        "net.fc = nn.Linear(net.fc.in_features, 555)\n",
        "\n",
        "losses = train(net, data['train'], ck_path=CK_PATH, epochs=EPOCHS, decay=DECAY, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "print(\"Training   accuracy: %f\" % accuracy(net, data['train']))\n",
        "print(\"Validation accuracy: %f\" % accuracy(net, data['valid']))\n",
        "print(\"Testing accuracy: %f\" % accuracy(net, data['test']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhwgjW3wZCI_",
        "outputId": "536f151d-3591-43c8-edeb-147f3a6c89e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torchvision.models.resnet.ResNet'>\n",
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n",
            "3600\n",
            "3700\n",
            "3800\n",
            "3900\n",
            "4000\n",
            "4100\n",
            "4200\n",
            "4300\n",
            "4400\n",
            "4500\n",
            "4600\n",
            "4700\n",
            "4800\n",
            "4900\n",
            "5000\n",
            "5100\n",
            "5200\n",
            "5300\n",
            "5400\n",
            "5500\n",
            "5600\n",
            "5700\n",
            "5800\n",
            "5900\n",
            "6000\n",
            "6100\n",
            "6200\n",
            "6300\n",
            "6400\n",
            "6500\n",
            "6600\n",
            "6700\n",
            "6800\n",
            "6900\n",
            "7000\n",
            "7100\n",
            "7200\n",
            "7300\n",
            "7400\n",
            "7500\n",
            "7600\n",
            "7700\n",
            "7800\n",
            "7900\n",
            "8000\n",
            "8100\n",
            "8200\n",
            "8300\n",
            "8400\n",
            "8500\n",
            "8600\n",
            "8700\n",
            "8800\n",
            "8900\n",
            "9000\n",
            "9100\n",
            "9200\n",
            "9300\n",
            "9400\n",
            "9500\n",
            "9600\n",
            "9700\n",
            "9800\n",
            "9900\n"
          ]
        }
      ],
      "source": [
        "# DON'T RERUN THIS CELL\n",
        "# Load model from checkpoint\n",
        "net = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
        "net.fc = nn.Linear(net.fc.in_features, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(CK_PATH + '/Iter1/ck-10.pkl')\n",
        "print(type(net))\n",
        "net.load_state_dict(state['model_state_dict'])\n",
        "# predict(net, data['valid'], CK_PATH + \"preds.csv\")\n",
        "predict(net, data['test'], CK_PATH + \"preds.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5BwUyyK7-ri",
        "outputId": "97f3abc1-e4b3-4d12-a49b-c093bcb46539"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 10\n",
            "loss: 0.7611852884292603\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=555, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer.load_state_dict(state['optimizer_state_dict'])\n",
        "epoch = state['epoch']\n",
        "loss = state['loss']\n",
        "\n",
        "print(f'epoch: {epoch}')\n",
        "print(f'loss: {loss}')\n",
        "print(net.eval())\n",
        "#print(\"Testing accuracy: %f\" % accuracy(net, data['test']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyAGi-9gUsEp",
        "outputId": "b5d3af1a-2a94-43d5-a2e2-9df50a1d4647"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0,    10] loss: 6.354\n",
            "[0,    20] loss: 6.336\n",
            "[0,    30] loss: 6.169\n",
            "[0,    40] loss: 6.053\n",
            "[0,    50] loss: 5.774\n",
            "[0,    60] loss: 5.550\n",
            "[0,    70] loss: 5.326\n",
            "[0,    80] loss: 5.189\n",
            "[0,    90] loss: 4.935\n",
            "[0,   100] loss: 4.654\n",
            "[0,   110] loss: 4.562\n",
            "[0,   120] loss: 4.483\n",
            "[0,   130] loss: 4.215\n",
            "[0,   140] loss: 4.078\n",
            "[0,   150] loss: 3.915\n",
            "[0,   160] loss: 3.760\n",
            "[0,   170] loss: 3.749\n",
            "[0,   180] loss: 3.630\n",
            "[0,   190] loss: 3.537\n",
            "[0,   200] loss: 3.380\n",
            "[0,   210] loss: 3.404\n",
            "[0,   220] loss: 3.328\n",
            "[0,   230] loss: 3.122\n",
            "[0,   240] loss: 3.102\n",
            "[0,   250] loss: 3.075\n",
            "[0,   260] loss: 3.012\n",
            "[0,   270] loss: 2.980\n",
            "[0,   280] loss: 2.897\n",
            "[0,   290] loss: 2.969\n",
            "[0,   300] loss: 2.809\n",
            "[0,   310] loss: 2.750\n",
            "[0,   320] loss: 2.714\n",
            "[0,   330] loss: 2.613\n",
            "[0,   340] loss: 2.735\n",
            "[0,   350] loss: 2.629\n",
            "[0,   360] loss: 2.577\n",
            "[0,   370] loss: 2.482\n",
            "[0,   380] loss: 2.497\n",
            "[0,   390] loss: 2.433\n",
            "[0,   400] loss: 2.393\n",
            "[0,   410] loss: 2.351\n",
            "[0,   420] loss: 2.342\n",
            "[0,   430] loss: 2.348\n",
            "[0,   440] loss: 2.257\n",
            "[0,   450] loss: 2.278\n",
            "[0,   460] loss: 2.178\n",
            "[0,   470] loss: 2.174\n",
            "[0,   480] loss: 2.172\n",
            "[0,   490] loss: 2.076\n",
            "[0,   500] loss: 1.972\n",
            "[0,   510] loss: 2.213\n",
            "[0,   520] loss: 2.119\n",
            "[0,   530] loss: 1.957\n",
            "[0,   540] loss: 2.154\n",
            "Training   accuracy: 0.481285\n",
            "Validation accuracy: 0.425719\n",
            "Testing accuracy: 0.004000\n"
          ]
        }
      ],
      "source": [
        "# TODO: train for 1 epoch and check for test accuracy, whether there is a huge difference\n",
        "EPOCHS = 1\n",
        "IMG_SIZE = 256\n",
        "BATCH_SIZE = 64\n",
        "STEP_SIZE = 3\n",
        "GAMMA = 0.1\n",
        "DECAY = 0.00047\n",
        "\n",
        "data = get_birds_data(img_size=IMG_SIZE, batch_size=BATCH_SIZE)\n",
        "# print(data['train'].__dict__)\n",
        "# print(data['test'].__dict__)\n",
        "\n",
        "net = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
        "net.fc = nn.Linear(net.fc.in_features, 555)\n",
        "\n",
        "losses = train(net, data['train'], ck_path=CK_PATH, epochs=EPOCHS, decay=DECAY, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "print(\"Training   accuracy: %f\" % accuracy(net, data['train']))\n",
        "print(\"Validation accuracy: %f\" % accuracy(net, data['valid']))\n",
        "print(\"Testing accuracy: %f\" % accuracy(net, data['test']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5ecba45901c643159cc59a40b15ad7f4",
            "4e863513a42f4941b9606887966e0937",
            "27961eeb6f194ef0b78cace46d42b53a",
            "323f9e070bc64acab43ec5c20198a6d0",
            "84b41b749f4f45e5ab0468f95dbbe937",
            "641f973d43d54d569ae6b8df4d54961f",
            "c2ec7571cc7e4645a4479e9b56d660b5",
            "ee1ec23bd9cd4e70ac44e809c4fdf993",
            "a00dfd008e904d6cadf5eefccd4229f9",
            "7a27b33588664815a8ddf67a08892905",
            "50800a086d494e90af6a74703b740aaf"
          ]
        },
        "id": "fq5t-CNNj3We",
        "outputId": "baa80e5c-b2be-4dcc-f6d5-c0507eb57caf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ecba45901c643159cc59a40b15ad7f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0,    10] loss: 6.330\n",
            "[0,    20] loss: 6.299\n",
            "[0,    30] loss: 6.200\n",
            "[0,    40] loss: 5.960\n",
            "[0,    50] loss: 5.796\n",
            "[0,    60] loss: 5.510\n",
            "[0,    70] loss: 5.315\n",
            "[0,    80] loss: 5.133\n",
            "[0,    90] loss: 5.004\n",
            "[0,   100] loss: 4.783\n",
            "[0,   110] loss: 4.606\n",
            "[0,   120] loss: 4.342\n",
            "[0,   130] loss: 4.262\n",
            "[0,   140] loss: 4.029\n",
            "[0,   150] loss: 3.982\n",
            "[0,   160] loss: 3.781\n",
            "[0,   170] loss: 3.727\n",
            "[0,   180] loss: 3.613\n",
            "[0,   190] loss: 3.565\n",
            "[0,   200] loss: 3.479\n",
            "[0,   210] loss: 3.329\n",
            "[0,   220] loss: 3.328\n",
            "[0,   230] loss: 3.279\n",
            "[0,   240] loss: 3.128\n",
            "[0,   250] loss: 3.066\n",
            "[0,   260] loss: 3.023\n",
            "[0,   270] loss: 2.957\n",
            "[0,   280] loss: 2.876\n",
            "[0,   290] loss: 2.776\n",
            "[0,   300] loss: 2.940\n",
            "[0,   310] loss: 2.616\n",
            "[0,   320] loss: 2.689\n",
            "[0,   330] loss: 2.623\n",
            "[0,   340] loss: 2.613\n",
            "[0,   350] loss: 2.397\n",
            "[0,   360] loss: 2.503\n",
            "[0,   370] loss: 2.528\n",
            "[0,   380] loss: 2.463\n",
            "[0,   390] loss: 2.592\n",
            "[0,   400] loss: 2.359\n",
            "[0,   410] loss: 2.513\n",
            "[0,   420] loss: 2.325\n",
            "[0,   430] loss: 2.402\n",
            "[0,   440] loss: 2.372\n",
            "[0,   450] loss: 2.240\n",
            "[0,   460] loss: 2.255\n",
            "[0,   470] loss: 2.185\n",
            "[0,   480] loss: 2.171\n",
            "[0,   490] loss: 2.115\n",
            "[0,   500] loss: 2.208\n",
            "[0,   510] loss: 2.212\n",
            "[0,   520] loss: 1.964\n",
            "[0,   530] loss: 2.037\n",
            "[0,   540] loss: 2.065\n",
            "[1,    10] loss: 1.854\n",
            "[1,    20] loss: 1.921\n",
            "[1,    30] loss: 1.739\n",
            "[1,    40] loss: 1.813\n",
            "[1,    50] loss: 1.759\n",
            "[1,    60] loss: 1.800\n",
            "[1,    70] loss: 1.783\n",
            "[1,    80] loss: 1.871\n",
            "[1,    90] loss: 1.695\n",
            "[1,   100] loss: 1.723\n",
            "[1,   110] loss: 1.844\n",
            "[1,   120] loss: 1.668\n",
            "[1,   130] loss: 1.630\n",
            "[1,   140] loss: 1.590\n",
            "[1,   150] loss: 1.769\n",
            "[1,   160] loss: 1.750\n",
            "[1,   170] loss: 1.643\n",
            "[1,   180] loss: 1.659\n",
            "[1,   190] loss: 1.689\n",
            "[1,   200] loss: 1.677\n",
            "[1,   210] loss: 1.652\n",
            "[1,   220] loss: 1.546\n",
            "[1,   230] loss: 1.586\n",
            "[1,   240] loss: 1.661\n",
            "[1,   250] loss: 1.539\n",
            "[1,   260] loss: 1.516\n",
            "[1,   270] loss: 1.521\n",
            "[1,   280] loss: 1.550\n",
            "[1,   290] loss: 1.520\n",
            "[1,   300] loss: 1.556\n",
            "[1,   310] loss: 1.566\n",
            "[1,   320] loss: 1.495\n",
            "[1,   330] loss: 1.502\n",
            "[1,   340] loss: 1.549\n",
            "[1,   350] loss: 1.497\n",
            "[1,   360] loss: 1.431\n",
            "[1,   370] loss: 1.550\n",
            "[1,   380] loss: 1.464\n",
            "[1,   390] loss: 1.398\n",
            "[1,   400] loss: 1.580\n",
            "[1,   410] loss: 1.473\n",
            "[1,   420] loss: 1.554\n",
            "[1,   430] loss: 1.523\n",
            "[1,   440] loss: 1.447\n",
            "[1,   450] loss: 1.411\n",
            "[1,   460] loss: 1.526\n",
            "[1,   470] loss: 1.535\n",
            "[1,   480] loss: 1.409\n",
            "[1,   490] loss: 1.469\n",
            "[1,   500] loss: 1.422\n",
            "[1,   510] loss: 1.419\n",
            "[1,   520] loss: 1.325\n",
            "[1,   530] loss: 1.475\n",
            "[1,   540] loss: 1.419\n",
            "[2,    10] loss: 1.268\n",
            "[2,    20] loss: 1.241\n",
            "[2,    30] loss: 1.310\n",
            "[2,    40] loss: 1.110\n",
            "[2,    50] loss: 1.163\n",
            "[2,    60] loss: 1.155\n",
            "[2,    70] loss: 1.207\n",
            "[2,    80] loss: 1.208\n",
            "[2,    90] loss: 1.225\n",
            "[2,   100] loss: 1.117\n",
            "[2,   110] loss: 1.230\n",
            "[2,   120] loss: 1.182\n",
            "[2,   130] loss: 1.175\n",
            "[2,   140] loss: 1.113\n",
            "[2,   150] loss: 1.170\n",
            "[2,   160] loss: 1.265\n",
            "[2,   170] loss: 1.095\n",
            "[2,   180] loss: 1.148\n",
            "[2,   190] loss: 1.166\n",
            "[2,   200] loss: 1.216\n",
            "[2,   210] loss: 1.125\n",
            "[2,   220] loss: 1.178\n",
            "[2,   230] loss: 1.133\n",
            "[2,   240] loss: 1.174\n",
            "[2,   250] loss: 1.170\n",
            "[2,   260] loss: 1.113\n",
            "[2,   270] loss: 1.172\n",
            "[2,   280] loss: 1.125\n",
            "[2,   290] loss: 1.233\n",
            "[2,   300] loss: 1.125\n",
            "[2,   310] loss: 1.133\n",
            "[2,   320] loss: 1.132\n",
            "[2,   330] loss: 1.140\n",
            "[2,   340] loss: 1.118\n",
            "[2,   350] loss: 1.071\n",
            "[2,   360] loss: 1.215\n",
            "[2,   370] loss: 1.096\n",
            "[2,   380] loss: 1.122\n",
            "[2,   390] loss: 1.126\n",
            "[2,   400] loss: 1.084\n",
            "[2,   410] loss: 1.224\n",
            "[2,   420] loss: 1.219\n",
            "[2,   430] loss: 1.179\n",
            "[2,   440] loss: 1.069\n",
            "[2,   450] loss: 1.191\n",
            "[2,   460] loss: 1.144\n",
            "[2,   470] loss: 1.158\n",
            "[2,   480] loss: 1.189\n",
            "[2,   490] loss: 1.148\n",
            "[2,   500] loss: 1.076\n",
            "[2,   510] loss: 1.126\n",
            "[2,   520] loss: 1.157\n",
            "[2,   530] loss: 1.163\n",
            "[2,   540] loss: 1.129\n",
            "[3,    10] loss: 0.946\n",
            "[3,    20] loss: 0.820\n",
            "[3,    30] loss: 0.831\n",
            "[3,    40] loss: 0.808\n",
            "[3,    50] loss: 0.679\n",
            "[3,    60] loss: 0.735\n",
            "[3,    70] loss: 0.680\n",
            "[3,    80] loss: 0.671\n",
            "[3,    90] loss: 0.716\n",
            "[3,   100] loss: 0.653\n",
            "[3,   110] loss: 0.663\n",
            "[3,   120] loss: 0.633\n",
            "[3,   130] loss: 0.651\n",
            "[3,   140] loss: 0.668\n",
            "[3,   150] loss: 0.630\n",
            "[3,   160] loss: 0.636\n",
            "[3,   170] loss: 0.695\n",
            "[3,   180] loss: 0.682\n",
            "[3,   190] loss: 0.624\n",
            "[3,   200] loss: 0.689\n",
            "[3,   210] loss: 0.588\n",
            "[3,   220] loss: 0.625\n",
            "[3,   230] loss: 0.681\n",
            "[3,   240] loss: 0.612\n",
            "[3,   250] loss: 0.607\n",
            "[3,   260] loss: 0.625\n",
            "[3,   270] loss: 0.642\n",
            "[3,   280] loss: 0.580\n",
            "[3,   290] loss: 0.664\n",
            "[3,   300] loss: 0.579\n",
            "[3,   310] loss: 0.575\n",
            "[3,   320] loss: 0.630\n",
            "[3,   330] loss: 0.622\n",
            "[3,   340] loss: 0.560\n",
            "[3,   350] loss: 0.618\n",
            "[3,   360] loss: 0.572\n",
            "[3,   370] loss: 0.598\n",
            "[3,   380] loss: 0.626\n",
            "[3,   390] loss: 0.625\n",
            "[3,   400] loss: 0.572\n",
            "[3,   410] loss: 0.627\n",
            "[3,   420] loss: 0.654\n",
            "[3,   430] loss: 0.554\n",
            "[3,   440] loss: 0.582\n",
            "[3,   450] loss: 0.594\n",
            "[3,   460] loss: 0.700\n",
            "[3,   470] loss: 0.576\n",
            "[3,   480] loss: 0.562\n",
            "[3,   490] loss: 0.659\n",
            "[3,   500] loss: 0.589\n",
            "[3,   510] loss: 0.614\n",
            "[3,   520] loss: 0.593\n",
            "[3,   530] loss: 0.601\n",
            "[3,   540] loss: 0.543\n",
            "[4,    10] loss: 0.496\n",
            "[4,    20] loss: 0.521\n",
            "[4,    30] loss: 0.492\n",
            "[4,    40] loss: 0.438\n",
            "[4,    50] loss: 0.450\n",
            "[4,    60] loss: 0.480\n",
            "[4,    70] loss: 0.502\n",
            "[4,    80] loss: 0.524\n",
            "[4,    90] loss: 0.489\n",
            "[4,   100] loss: 0.565\n",
            "[4,   110] loss: 0.507\n",
            "[4,   120] loss: 0.507\n",
            "[4,   130] loss: 0.503\n",
            "[4,   140] loss: 0.484\n",
            "[4,   150] loss: 0.463\n",
            "[4,   160] loss: 0.523\n",
            "[4,   170] loss: 0.480\n",
            "[4,   180] loss: 0.491\n",
            "[4,   190] loss: 0.497\n",
            "[4,   200] loss: 0.497\n",
            "[4,   210] loss: 0.471\n",
            "[4,   220] loss: 0.496\n",
            "[4,   230] loss: 0.548\n",
            "[4,   240] loss: 0.524\n",
            "[4,   250] loss: 0.538\n",
            "[4,   260] loss: 0.481\n",
            "[4,   270] loss: 0.478\n",
            "[4,   280] loss: 0.497\n",
            "[4,   290] loss: 0.520\n",
            "[4,   300] loss: 0.558\n",
            "[4,   310] loss: 0.498\n",
            "[4,   320] loss: 0.489\n",
            "[4,   330] loss: 0.462\n",
            "[4,   340] loss: 0.443\n",
            "[4,   350] loss: 0.556\n",
            "[4,   360] loss: 0.515\n",
            "[4,   370] loss: 0.481\n",
            "[4,   380] loss: 0.498\n",
            "[4,   390] loss: 0.487\n",
            "[4,   400] loss: 0.562\n",
            "[4,   410] loss: 0.599\n",
            "[4,   420] loss: 0.581\n",
            "[4,   430] loss: 0.523\n",
            "[4,   440] loss: 0.485\n",
            "[4,   450] loss: 0.470\n",
            "[4,   460] loss: 0.484\n",
            "[4,   470] loss: 0.463\n",
            "[4,   480] loss: 0.452\n",
            "[4,   490] loss: 0.471\n",
            "[4,   500] loss: 0.482\n",
            "[4,   510] loss: 0.517\n",
            "[4,   520] loss: 0.482\n",
            "[4,   530] loss: 0.547\n",
            "[4,   540] loss: 0.483\n",
            "[5,    10] loss: 0.392\n",
            "[5,    20] loss: 0.442\n",
            "[5,    30] loss: 0.393\n",
            "[5,    40] loss: 0.393\n",
            "[5,    50] loss: 0.374\n",
            "[5,    60] loss: 0.432\n",
            "[5,    70] loss: 0.438\n",
            "[5,    80] loss: 0.472\n",
            "[5,    90] loss: 0.434\n",
            "[5,   100] loss: 0.427\n",
            "[5,   110] loss: 0.412\n",
            "[5,   120] loss: 0.449\n",
            "[5,   130] loss: 0.404\n",
            "[5,   140] loss: 0.399\n",
            "[5,   150] loss: 0.426\n",
            "[5,   160] loss: 0.391\n",
            "[5,   170] loss: 0.482\n",
            "[5,   180] loss: 0.447\n",
            "[5,   190] loss: 0.491\n",
            "[5,   200] loss: 0.435\n",
            "[5,   210] loss: 0.410\n",
            "[5,   220] loss: 0.422\n",
            "[5,   230] loss: 0.447\n",
            "[5,   240] loss: 0.447\n",
            "[5,   250] loss: 0.383\n",
            "[5,   260] loss: 0.474\n",
            "[5,   270] loss: 0.377\n",
            "[5,   280] loss: 0.401\n",
            "[5,   290] loss: 0.421\n",
            "[5,   300] loss: 0.413\n",
            "[5,   310] loss: 0.411\n",
            "[5,   320] loss: 0.469\n",
            "[5,   330] loss: 0.389\n",
            "[5,   340] loss: 0.426\n",
            "[5,   350] loss: 0.389\n",
            "[5,   360] loss: 0.420\n",
            "[5,   370] loss: 0.434\n",
            "[5,   380] loss: 0.415\n",
            "[5,   390] loss: 0.432\n",
            "[5,   400] loss: 0.474\n",
            "[5,   410] loss: 0.485\n",
            "[5,   420] loss: 0.404\n",
            "[5,   430] loss: 0.464\n",
            "[5,   440] loss: 0.444\n",
            "[5,   450] loss: 0.482\n",
            "[5,   460] loss: 0.404\n",
            "[5,   470] loss: 0.398\n",
            "[5,   480] loss: 0.428\n",
            "[5,   490] loss: 0.443\n",
            "[5,   500] loss: 0.460\n",
            "[5,   510] loss: 0.433\n",
            "[5,   520] loss: 0.515\n",
            "[5,   530] loss: 0.473\n",
            "[5,   540] loss: 0.481\n",
            "[6,    10] loss: 0.340\n",
            "[6,    20] loss: 0.377\n",
            "[6,    30] loss: 0.367\n",
            "[6,    40] loss: 0.329\n",
            "[6,    50] loss: 0.348\n",
            "[6,    60] loss: 0.344\n",
            "[6,    70] loss: 0.367\n",
            "[6,    80] loss: 0.367\n",
            "[6,    90] loss: 0.325\n",
            "[6,   100] loss: 0.331\n",
            "[6,   110] loss: 0.306\n",
            "[6,   120] loss: 0.349\n",
            "[6,   130] loss: 0.344\n",
            "[6,   140] loss: 0.324\n",
            "[6,   150] loss: 0.320\n",
            "[6,   160] loss: 0.332\n",
            "[6,   170] loss: 0.324\n",
            "[6,   180] loss: 0.321\n",
            "[6,   190] loss: 0.287\n",
            "[6,   200] loss: 0.311\n",
            "[6,   210] loss: 0.346\n",
            "[6,   220] loss: 0.295\n",
            "[6,   230] loss: 0.315\n",
            "[6,   240] loss: 0.287\n",
            "[6,   250] loss: 0.307\n",
            "[6,   260] loss: 0.362\n",
            "[6,   270] loss: 0.308\n",
            "[6,   280] loss: 0.314\n",
            "[6,   290] loss: 0.343\n",
            "[6,   300] loss: 0.316\n",
            "[6,   310] loss: 0.303\n",
            "[6,   320] loss: 0.313\n",
            "[6,   330] loss: 0.335\n",
            "[6,   340] loss: 0.339\n",
            "[6,   350] loss: 0.383\n",
            "[6,   360] loss: 0.299\n",
            "[6,   370] loss: 0.327\n",
            "[6,   380] loss: 0.386\n",
            "[6,   390] loss: 0.299\n",
            "[6,   400] loss: 0.301\n",
            "[6,   410] loss: 0.312\n",
            "[6,   420] loss: 0.331\n",
            "[6,   430] loss: 0.326\n",
            "[6,   440] loss: 0.283\n",
            "[6,   450] loss: 0.321\n",
            "[6,   460] loss: 0.294\n",
            "[6,   470] loss: 0.297\n",
            "[6,   480] loss: 0.359\n",
            "[6,   490] loss: 0.338\n",
            "[6,   500] loss: 0.345\n",
            "[6,   510] loss: 0.328\n",
            "[6,   520] loss: 0.326\n",
            "[6,   530] loss: 0.326\n",
            "[6,   540] loss: 0.268\n",
            "[7,    10] loss: 0.291\n",
            "[7,    20] loss: 0.303\n",
            "[7,    30] loss: 0.278\n",
            "[7,    40] loss: 0.325\n",
            "[7,    50] loss: 0.296\n",
            "[7,    60] loss: 0.273\n",
            "[7,    70] loss: 0.295\n",
            "[7,    80] loss: 0.289\n",
            "[7,    90] loss: 0.337\n",
            "[7,   100] loss: 0.293\n",
            "[7,   110] loss: 0.309\n",
            "[7,   120] loss: 0.298\n",
            "[7,   130] loss: 0.284\n",
            "[7,   140] loss: 0.309\n",
            "[7,   150] loss: 0.291\n",
            "[7,   160] loss: 0.283\n",
            "[7,   170] loss: 0.291\n",
            "[7,   180] loss: 0.279\n",
            "[7,   190] loss: 0.242\n",
            "[7,   200] loss: 0.295\n",
            "[7,   210] loss: 0.283\n",
            "[7,   220] loss: 0.274\n",
            "[7,   230] loss: 0.299\n",
            "[7,   240] loss: 0.323\n",
            "[7,   250] loss: 0.292\n",
            "[7,   260] loss: 0.276\n",
            "[7,   270] loss: 0.279\n",
            "[7,   280] loss: 0.333\n",
            "[7,   290] loss: 0.332\n",
            "[7,   300] loss: 0.275\n",
            "[7,   310] loss: 0.284\n",
            "[7,   320] loss: 0.287\n",
            "[7,   330] loss: 0.283\n",
            "[7,   340] loss: 0.352\n",
            "[7,   350] loss: 0.275\n",
            "[7,   360] loss: 0.310\n",
            "[7,   370] loss: 0.280\n",
            "[7,   380] loss: 0.318\n",
            "[7,   390] loss: 0.306\n",
            "[7,   400] loss: 0.272\n",
            "[7,   410] loss: 0.263\n",
            "[7,   420] loss: 0.341\n",
            "[7,   430] loss: 0.326\n",
            "[7,   440] loss: 0.308\n",
            "[7,   450] loss: 0.299\n",
            "[7,   460] loss: 0.272\n",
            "[7,   470] loss: 0.309\n",
            "[7,   480] loss: 0.283\n",
            "[7,   490] loss: 0.287\n",
            "[7,   500] loss: 0.305\n",
            "[7,   510] loss: 0.302\n",
            "[7,   520] loss: 0.279\n",
            "[7,   530] loss: 0.249\n",
            "[7,   540] loss: 0.277\n",
            "[8,    10] loss: 0.280\n",
            "[8,    20] loss: 0.268\n",
            "[8,    30] loss: 0.244\n",
            "[8,    40] loss: 0.283\n",
            "[8,    50] loss: 0.265\n",
            "[8,    60] loss: 0.286\n",
            "[8,    70] loss: 0.308\n",
            "[8,    80] loss: 0.273\n",
            "[8,    90] loss: 0.264\n",
            "[8,   100] loss: 0.269\n",
            "[8,   110] loss: 0.269\n",
            "[8,   120] loss: 0.235\n",
            "[8,   130] loss: 0.245\n",
            "[8,   140] loss: 0.245\n",
            "[8,   150] loss: 0.303\n",
            "[8,   160] loss: 0.263\n",
            "[8,   170] loss: 0.252\n",
            "[8,   180] loss: 0.258\n",
            "[8,   190] loss: 0.250\n",
            "[8,   200] loss: 0.291\n",
            "[8,   210] loss: 0.277\n",
            "[8,   220] loss: 0.269\n",
            "[8,   230] loss: 0.290\n",
            "[8,   240] loss: 0.272\n",
            "[8,   250] loss: 0.261\n",
            "[8,   260] loss: 0.262\n",
            "[8,   270] loss: 0.230\n",
            "[8,   280] loss: 0.233\n",
            "[8,   290] loss: 0.241\n",
            "[8,   300] loss: 0.301\n",
            "[8,   310] loss: 0.281\n",
            "[8,   320] loss: 0.286\n",
            "[8,   330] loss: 0.265\n",
            "[8,   340] loss: 0.307\n",
            "[8,   350] loss: 0.299\n",
            "[8,   360] loss: 0.269\n",
            "[8,   370] loss: 0.254\n",
            "[8,   380] loss: 0.323\n",
            "[8,   390] loss: 0.281\n",
            "[8,   400] loss: 0.279\n",
            "[8,   410] loss: 0.298\n",
            "[8,   420] loss: 0.304\n",
            "[8,   430] loss: 0.268\n",
            "[8,   440] loss: 0.260\n",
            "[8,   450] loss: 0.290\n",
            "[8,   460] loss: 0.282\n",
            "[8,   470] loss: 0.263\n",
            "[8,   480] loss: 0.268\n",
            "[8,   490] loss: 0.257\n",
            "[8,   500] loss: 0.292\n",
            "[8,   510] loss: 0.315\n",
            "[8,   520] loss: 0.257\n",
            "[8,   530] loss: 0.262\n",
            "[8,   540] loss: 0.281\n",
            "[9,    10] loss: 0.262\n",
            "[9,    20] loss: 0.254\n",
            "[9,    30] loss: 0.247\n",
            "[9,    40] loss: 0.268\n",
            "[9,    50] loss: 0.273\n",
            "[9,    60] loss: 0.261\n",
            "[9,    70] loss: 0.230\n",
            "[9,    80] loss: 0.249\n",
            "[9,    90] loss: 0.282\n",
            "[9,   100] loss: 0.246\n",
            "[9,   110] loss: 0.256\n",
            "[9,   120] loss: 0.249\n",
            "[9,   130] loss: 0.215\n",
            "[9,   140] loss: 0.250\n",
            "[9,   150] loss: 0.298\n",
            "[9,   160] loss: 0.272\n",
            "[9,   170] loss: 0.257\n",
            "[9,   180] loss: 0.245\n",
            "[9,   190] loss: 0.255\n",
            "[9,   200] loss: 0.277\n",
            "[9,   210] loss: 0.275\n",
            "[9,   220] loss: 0.276\n",
            "[9,   230] loss: 0.232\n",
            "[9,   240] loss: 0.258\n",
            "[9,   250] loss: 0.241\n",
            "[9,   260] loss: 0.265\n",
            "[9,   270] loss: 0.264\n",
            "[9,   280] loss: 0.217\n",
            "[9,   290] loss: 0.222\n",
            "[9,   300] loss: 0.237\n",
            "[9,   310] loss: 0.258\n",
            "[9,   320] loss: 0.253\n",
            "[9,   330] loss: 0.187\n",
            "[9,   340] loss: 0.272\n",
            "[9,   350] loss: 0.235\n",
            "[9,   360] loss: 0.264\n",
            "[9,   370] loss: 0.236\n",
            "[9,   380] loss: 0.233\n",
            "[9,   390] loss: 0.261\n",
            "[9,   400] loss: 0.267\n",
            "[9,   410] loss: 0.236\n",
            "[9,   420] loss: 0.229\n",
            "[9,   430] loss: 0.232\n",
            "[9,   440] loss: 0.263\n",
            "[9,   450] loss: 0.244\n",
            "[9,   460] loss: 0.240\n",
            "[9,   470] loss: 0.295\n",
            "[9,   480] loss: 0.245\n",
            "[9,   490] loss: 0.269\n",
            "[9,   500] loss: 0.221\n",
            "[9,   510] loss: 0.260\n",
            "[9,   520] loss: 0.265\n",
            "[9,   530] loss: 0.254\n",
            "[9,   540] loss: 0.212\n",
            "Training   accuracy: 0.964558\n",
            "Validation accuracy: 0.817993\n",
            "Testing accuracy: 0.001400\n"
          ]
        }
      ],
      "source": [
        "# TODO: train for 1 epoch and check for test accuracy, whether there is a huge difference\n",
        "EPOCHS = 10\n",
        "IMG_SIZE = 256\n",
        "BATCH_SIZE = 64\n",
        "STEP_SIZE = 3\n",
        "GAMMA = 0.3\n",
        "DECAY = 0.00047\n",
        "\n",
        "data = get_birds_data(img_size=IMG_SIZE, batch_size=BATCH_SIZE)\n",
        "# print(data['train'].__dict__)\n",
        "# print(data['test'].__dict__)\n",
        "\n",
        "net = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
        "net.fc = nn.Linear(net.fc.in_features, 555)\n",
        "\n",
        "losses = train(net, data['train'], ck_path=CK_PATH, epochs=EPOCHS, decay=DECAY, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "print(\"Training   accuracy: %f\" % accuracy(net, data['train']))\n",
        "print(\"Validation accuracy: %f\" % accuracy(net, data['valid']))\n",
        "print(\"Testing accuracy: %f\" % accuracy(net, data['test']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ4Et1V9-9cM",
        "outputId": "6540f7ba-586f-45c7-ad98-c922dc4c3d99"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torchvision.models.resnet.ResNet'>\n",
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n",
            "3600\n",
            "3700\n",
            "3800\n",
            "3900\n",
            "4000\n",
            "4100\n",
            "4200\n",
            "4300\n",
            "4400\n",
            "4500\n",
            "4600\n",
            "4700\n",
            "4800\n",
            "4900\n",
            "5000\n",
            "5100\n",
            "5200\n",
            "5300\n",
            "5400\n",
            "5500\n",
            "5600\n",
            "5700\n",
            "5800\n",
            "5900\n",
            "6000\n",
            "6100\n",
            "6200\n",
            "6300\n",
            "6400\n",
            "6500\n",
            "6600\n",
            "6700\n",
            "6800\n",
            "6900\n",
            "7000\n",
            "7100\n",
            "7200\n",
            "7300\n",
            "7400\n",
            "7500\n",
            "7600\n",
            "7700\n",
            "7800\n",
            "7900\n",
            "8000\n",
            "8100\n",
            "8200\n",
            "8300\n",
            "8400\n",
            "8500\n",
            "8600\n",
            "8700\n",
            "8800\n",
            "8900\n",
            "9000\n",
            "9100\n",
            "9200\n",
            "9300\n",
            "9400\n",
            "9500\n",
            "9600\n",
            "9700\n",
            "9800\n",
            "9900\n"
          ]
        }
      ],
      "source": [
        "net = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
        "net.fc = nn.Linear(net.fc.in_features, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(CK_PATH + '/ck-10.pkl')\n",
        "print(type(net))\n",
        "net.load_state_dict(state['model_state_dict'])\n",
        "# predict(net, data['valid'], CK_PATH + \"preds.csv\")\n",
        "predict(net, data['test'], CK_PATH + \"preds1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPTqrGfnPZHL",
        "outputId": "947711e9-d92d-4a55-eb5c-2182f7f40541"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0,    10] loss: 6.337\n",
            "[0,    20] loss: 6.299\n",
            "[0,    30] loss: 6.186\n",
            "[0,    40] loss: 5.963\n",
            "[0,    50] loss: 5.775\n",
            "[0,    60] loss: 5.671\n",
            "[0,    70] loss: 5.323\n",
            "[0,    80] loss: 5.238\n",
            "[0,    90] loss: 4.980\n",
            "[0,   100] loss: 4.782\n",
            "[0,   110] loss: 4.457\n",
            "[0,   120] loss: 4.338\n",
            "[0,   130] loss: 4.258\n",
            "[0,   140] loss: 4.104\n",
            "[0,   150] loss: 4.020\n",
            "[0,   160] loss: 3.806\n",
            "[0,   170] loss: 3.671\n",
            "[0,   180] loss: 3.606\n",
            "[0,   190] loss: 3.545\n",
            "[0,   200] loss: 3.456\n",
            "[0,   210] loss: 3.282\n",
            "[0,   220] loss: 3.337\n",
            "[0,   230] loss: 3.338\n",
            "[0,   240] loss: 3.145\n",
            "[0,   250] loss: 3.049\n",
            "[0,   260] loss: 2.959\n",
            "[0,   270] loss: 2.878\n",
            "[0,   280] loss: 2.836\n",
            "[0,   290] loss: 2.844\n",
            "[0,   300] loss: 2.788\n",
            "[0,   310] loss: 2.679\n",
            "[0,   320] loss: 2.723\n",
            "[0,   330] loss: 2.780\n",
            "[0,   340] loss: 2.666\n",
            "[0,   350] loss: 2.523\n",
            "[0,   360] loss: 2.547\n",
            "[0,   370] loss: 2.413\n",
            "[0,   380] loss: 2.524\n",
            "[0,   390] loss: 2.406\n",
            "[0,   400] loss: 2.391\n",
            "[0,   410] loss: 2.300\n",
            "[0,   420] loss: 2.462\n",
            "[0,   430] loss: 2.344\n",
            "[0,   440] loss: 2.270\n",
            "[0,   450] loss: 2.229\n",
            "[0,   460] loss: 2.261\n",
            "[0,   470] loss: 2.164\n",
            "[0,   480] loss: 2.203\n",
            "[0,   490] loss: 2.240\n",
            "[0,   500] loss: 2.299\n",
            "[0,   510] loss: 2.119\n",
            "[0,   520] loss: 2.083\n",
            "[0,   530] loss: 1.972\n",
            "[0,   540] loss: 2.040\n",
            "[1,    10] loss: 1.904\n",
            "[1,    20] loss: 1.858\n",
            "[1,    30] loss: 1.793\n",
            "[1,    40] loss: 1.692\n",
            "[1,    50] loss: 1.845\n",
            "[1,    60] loss: 1.674\n",
            "[1,    70] loss: 1.725\n",
            "[1,    80] loss: 1.678\n",
            "[1,    90] loss: 1.643\n",
            "[1,   100] loss: 1.683\n",
            "[1,   110] loss: 1.793\n",
            "[1,   120] loss: 1.724\n",
            "[1,   130] loss: 1.816\n",
            "[1,   140] loss: 1.696\n",
            "[1,   150] loss: 1.667\n",
            "[1,   160] loss: 1.688\n",
            "[1,   170] loss: 1.692\n",
            "[1,   180] loss: 1.633\n",
            "[1,   190] loss: 1.590\n",
            "[1,   200] loss: 1.599\n",
            "[1,   210] loss: 1.591\n",
            "[1,   220] loss: 1.614\n",
            "[1,   230] loss: 1.492\n",
            "[1,   240] loss: 1.631\n",
            "[1,   250] loss: 1.674\n",
            "[1,   260] loss: 1.502\n",
            "[1,   270] loss: 1.601\n",
            "[1,   280] loss: 1.611\n",
            "[1,   290] loss: 1.620\n",
            "[1,   300] loss: 1.592\n",
            "[1,   310] loss: 1.583\n",
            "[1,   320] loss: 1.526\n",
            "[1,   330] loss: 1.572\n",
            "[1,   340] loss: 1.513\n",
            "[1,   350] loss: 1.510\n",
            "[1,   360] loss: 1.430\n",
            "[1,   370] loss: 1.417\n",
            "[1,   380] loss: 1.553\n",
            "[1,   390] loss: 1.494\n",
            "[1,   400] loss: 1.511\n",
            "[1,   410] loss: 1.544\n",
            "[1,   420] loss: 1.451\n",
            "[1,   430] loss: 1.453\n",
            "[1,   440] loss: 1.503\n",
            "[1,   450] loss: 1.430\n",
            "[1,   460] loss: 1.534\n",
            "[1,   470] loss: 1.433\n",
            "[1,   480] loss: 1.543\n",
            "[1,   490] loss: 1.496\n",
            "[1,   500] loss: 1.390\n",
            "[1,   510] loss: 1.476\n",
            "[1,   520] loss: 1.370\n",
            "[1,   530] loss: 1.438\n",
            "[1,   540] loss: 1.366\n",
            "[2,    10] loss: 1.306\n",
            "[2,    20] loss: 1.318\n",
            "[2,    30] loss: 1.253\n",
            "[2,    40] loss: 1.207\n",
            "[2,    50] loss: 1.210\n",
            "[2,    60] loss: 1.166\n",
            "[2,    70] loss: 1.099\n",
            "[2,    80] loss: 1.181\n",
            "[2,    90] loss: 1.187\n",
            "[2,   100] loss: 1.243\n",
            "[2,   110] loss: 1.069\n",
            "[2,   120] loss: 1.175\n",
            "[2,   130] loss: 1.290\n",
            "[2,   140] loss: 1.210\n",
            "[2,   150] loss: 1.110\n",
            "[2,   160] loss: 1.168\n",
            "[2,   170] loss: 1.132\n",
            "[2,   180] loss: 1.148\n",
            "[2,   190] loss: 1.148\n",
            "[2,   200] loss: 1.180\n",
            "[2,   210] loss: 1.080\n",
            "[2,   220] loss: 1.247\n",
            "[2,   230] loss: 1.159\n",
            "[2,   240] loss: 1.252\n",
            "[2,   250] loss: 1.272\n",
            "[2,   260] loss: 1.241\n",
            "[2,   270] loss: 1.207\n",
            "[2,   280] loss: 1.137\n",
            "[2,   290] loss: 1.172\n",
            "[2,   300] loss: 1.127\n",
            "[2,   310] loss: 1.157\n",
            "[2,   320] loss: 1.117\n",
            "[2,   330] loss: 1.093\n",
            "[2,   340] loss: 1.152\n",
            "[2,   350] loss: 1.056\n",
            "[2,   360] loss: 1.184\n",
            "[2,   370] loss: 1.212\n",
            "[2,   380] loss: 1.212\n",
            "[2,   390] loss: 1.111\n",
            "[2,   400] loss: 1.111\n",
            "[2,   410] loss: 1.147\n",
            "[2,   420] loss: 1.077\n",
            "[2,   430] loss: 1.284\n",
            "[2,   440] loss: 1.125\n",
            "[2,   450] loss: 1.162\n",
            "[2,   460] loss: 1.113\n",
            "[2,   470] loss: 1.125\n",
            "[2,   480] loss: 1.130\n",
            "[2,   490] loss: 1.126\n",
            "[2,   500] loss: 1.044\n",
            "[2,   510] loss: 1.124\n",
            "[2,   520] loss: 1.109\n",
            "[2,   530] loss: 1.124\n",
            "[2,   540] loss: 1.150\n",
            "[3,    10] loss: 0.983\n",
            "[3,    20] loss: 0.969\n",
            "[3,    30] loss: 0.971\n",
            "[3,    40] loss: 0.780\n",
            "[3,    50] loss: 0.769\n",
            "[3,    60] loss: 0.667\n",
            "[3,    70] loss: 0.751\n",
            "[3,    80] loss: 0.667\n",
            "[3,    90] loss: 0.699\n",
            "[3,   100] loss: 0.751\n",
            "[3,   110] loss: 0.711\n",
            "[3,   120] loss: 0.776\n",
            "[3,   130] loss: 0.651\n",
            "[3,   140] loss: 0.743\n",
            "[3,   150] loss: 0.750\n",
            "[3,   160] loss: 0.721\n",
            "[3,   170] loss: 0.651\n",
            "[3,   180] loss: 0.706\n",
            "[3,   190] loss: 0.675\n",
            "[3,   200] loss: 0.697\n",
            "[3,   210] loss: 0.625\n",
            "[3,   220] loss: 0.696\n",
            "[3,   230] loss: 0.771\n",
            "[3,   240] loss: 0.675\n",
            "[3,   250] loss: 0.663\n",
            "[3,   260] loss: 0.662\n",
            "[3,   270] loss: 0.684\n",
            "[3,   280] loss: 0.630\n",
            "[3,   290] loss: 0.637\n",
            "[3,   300] loss: 0.646\n",
            "[3,   310] loss: 0.663\n",
            "[3,   320] loss: 0.651\n",
            "[3,   330] loss: 0.720\n",
            "[3,   340] loss: 0.680\n",
            "[3,   350] loss: 0.662\n",
            "[3,   360] loss: 0.666\n",
            "[3,   370] loss: 0.695\n",
            "[3,   380] loss: 0.722\n",
            "[3,   390] loss: 0.760\n",
            "[3,   400] loss: 0.691\n",
            "[3,   410] loss: 0.645\n",
            "[3,   420] loss: 0.616\n",
            "[3,   430] loss: 0.682\n",
            "[3,   440] loss: 0.641\n",
            "[3,   450] loss: 0.660\n",
            "[3,   460] loss: 0.692\n",
            "[3,   470] loss: 0.661\n",
            "[3,   480] loss: 0.632\n",
            "[3,   490] loss: 0.693\n",
            "[3,   500] loss: 0.740\n",
            "[3,   510] loss: 0.598\n",
            "[3,   520] loss: 0.673\n",
            "[3,   530] loss: 0.616\n",
            "[3,   540] loss: 0.697\n",
            "[4,    10] loss: 0.565\n",
            "[4,    20] loss: 0.562\n",
            "[4,    30] loss: 0.559\n",
            "[4,    40] loss: 0.529\n",
            "[4,    50] loss: 0.470\n",
            "[4,    60] loss: 0.536\n",
            "[4,    70] loss: 0.498\n",
            "[4,    80] loss: 0.559\n",
            "[4,    90] loss: 0.529\n",
            "[4,   100] loss: 0.567\n",
            "[4,   110] loss: 0.500\n",
            "[4,   120] loss: 0.578\n",
            "[4,   130] loss: 0.531\n",
            "[4,   140] loss: 0.503\n",
            "[4,   150] loss: 0.508\n",
            "[4,   160] loss: 0.536\n",
            "[4,   170] loss: 0.515\n",
            "[4,   180] loss: 0.547\n",
            "[4,   190] loss: 0.548\n",
            "[4,   200] loss: 0.568\n",
            "[4,   210] loss: 0.507\n",
            "[4,   220] loss: 0.543\n",
            "[4,   230] loss: 0.592\n",
            "[4,   240] loss: 0.566\n",
            "[4,   250] loss: 0.635\n",
            "[4,   260] loss: 0.528\n",
            "[4,   270] loss: 0.554\n",
            "[4,   280] loss: 0.602\n",
            "[4,   290] loss: 0.573\n",
            "[4,   300] loss: 0.601\n",
            "[4,   310] loss: 0.531\n",
            "[4,   320] loss: 0.593\n",
            "[4,   330] loss: 0.526\n",
            "[4,   340] loss: 0.543\n",
            "[4,   350] loss: 0.543\n",
            "[4,   360] loss: 0.588\n",
            "[4,   370] loss: 0.623\n",
            "[4,   380] loss: 0.601\n",
            "[4,   390] loss: 0.576\n",
            "[4,   400] loss: 0.615\n",
            "[4,   410] loss: 0.540\n",
            "[4,   420] loss: 0.592\n",
            "[4,   430] loss: 0.550\n",
            "[4,   440] loss: 0.496\n",
            "[4,   450] loss: 0.553\n",
            "[4,   460] loss: 0.604\n",
            "[4,   470] loss: 0.510\n",
            "[4,   480] loss: 0.563\n",
            "[4,   490] loss: 0.619\n",
            "[4,   500] loss: 0.572\n",
            "[4,   510] loss: 0.616\n",
            "[4,   520] loss: 0.498\n",
            "[4,   530] loss: 0.583\n",
            "[4,   540] loss: 0.558\n",
            "[5,    10] loss: 0.456\n",
            "[5,    20] loss: 0.463\n",
            "[5,    30] loss: 0.428\n",
            "[5,    40] loss: 0.453\n",
            "[5,    50] loss: 0.435\n",
            "[5,    60] loss: 0.455\n",
            "[5,    70] loss: 0.439\n",
            "[5,    80] loss: 0.486\n",
            "[5,    90] loss: 0.415\n",
            "[5,   100] loss: 0.449\n",
            "[5,   110] loss: 0.436\n",
            "[5,   120] loss: 0.444\n",
            "[5,   130] loss: 0.466\n",
            "[5,   140] loss: 0.481\n",
            "[5,   150] loss: 0.471\n",
            "[5,   160] loss: 0.506\n",
            "[5,   170] loss: 0.456\n",
            "[5,   180] loss: 0.392\n",
            "[5,   190] loss: 0.462\n",
            "[5,   200] loss: 0.416\n",
            "[5,   210] loss: 0.481\n",
            "[5,   220] loss: 0.387\n",
            "[5,   230] loss: 0.438\n",
            "[5,   240] loss: 0.506\n",
            "[5,   250] loss: 0.396\n",
            "[5,   260] loss: 0.465\n",
            "[5,   270] loss: 0.479\n",
            "[5,   280] loss: 0.472\n",
            "[5,   290] loss: 0.445\n",
            "[5,   300] loss: 0.488\n",
            "[5,   310] loss: 0.502\n",
            "[5,   320] loss: 0.464\n",
            "[5,   330] loss: 0.460\n",
            "[5,   340] loss: 0.452\n",
            "[5,   350] loss: 0.487\n",
            "[5,   360] loss: 0.485\n",
            "[5,   370] loss: 0.474\n",
            "[5,   380] loss: 0.487\n",
            "[5,   390] loss: 0.494\n",
            "[5,   400] loss: 0.432\n",
            "[5,   410] loss: 0.495\n",
            "[5,   420] loss: 0.477\n",
            "[5,   430] loss: 0.500\n",
            "[5,   440] loss: 0.438\n",
            "[5,   450] loss: 0.522\n",
            "[5,   460] loss: 0.450\n",
            "[5,   470] loss: 0.516\n",
            "[5,   480] loss: 0.487\n",
            "[5,   490] loss: 0.437\n",
            "[5,   500] loss: 0.499\n",
            "[5,   510] loss: 0.499\n",
            "[5,   520] loss: 0.505\n",
            "[5,   530] loss: 0.471\n",
            "[5,   540] loss: 0.529\n",
            "[6,    10] loss: 0.382\n",
            "[6,    20] loss: 0.392\n",
            "[6,    30] loss: 0.381\n",
            "[6,    40] loss: 0.381\n",
            "[6,    50] loss: 0.358\n",
            "[6,    60] loss: 0.393\n",
            "[6,    70] loss: 0.361\n",
            "[6,    80] loss: 0.339\n",
            "[6,    90] loss: 0.307\n",
            "[6,   100] loss: 0.326\n",
            "[6,   110] loss: 0.284\n",
            "[6,   120] loss: 0.276\n",
            "[6,   130] loss: 0.346\n",
            "[6,   140] loss: 0.345\n",
            "[6,   150] loss: 0.262\n",
            "[6,   160] loss: 0.302\n",
            "[6,   170] loss: 0.280\n",
            "[6,   180] loss: 0.315\n",
            "[6,   190] loss: 0.308\n",
            "[6,   200] loss: 0.329\n",
            "[6,   210] loss: 0.333\n",
            "[6,   220] loss: 0.339\n",
            "[6,   230] loss: 0.314\n",
            "[6,   240] loss: 0.312\n",
            "[6,   250] loss: 0.333\n",
            "[6,   260] loss: 0.313\n",
            "[6,   270] loss: 0.338\n",
            "[6,   280] loss: 0.273\n",
            "[6,   290] loss: 0.343\n",
            "[6,   300] loss: 0.295\n",
            "[6,   310] loss: 0.289\n",
            "[6,   320] loss: 0.329\n",
            "[6,   330] loss: 0.334\n",
            "[6,   340] loss: 0.330\n",
            "[6,   350] loss: 0.303\n",
            "[6,   360] loss: 0.289\n",
            "[6,   370] loss: 0.318\n",
            "[6,   380] loss: 0.298\n",
            "[6,   390] loss: 0.346\n",
            "[6,   400] loss: 0.311\n",
            "[6,   410] loss: 0.332\n",
            "[6,   420] loss: 0.334\n",
            "[6,   430] loss: 0.286\n",
            "[6,   440] loss: 0.351\n",
            "[6,   450] loss: 0.304\n",
            "[6,   460] loss: 0.311\n",
            "[6,   470] loss: 0.318\n",
            "[6,   480] loss: 0.297\n",
            "[6,   490] loss: 0.332\n",
            "[6,   500] loss: 0.326\n",
            "[6,   510] loss: 0.272\n",
            "[6,   520] loss: 0.322\n",
            "[6,   530] loss: 0.331\n",
            "[6,   540] loss: 0.342\n",
            "[7,    10] loss: 0.241\n",
            "[7,    20] loss: 0.255\n",
            "[7,    30] loss: 0.246\n",
            "[7,    40] loss: 0.273\n",
            "[7,    50] loss: 0.232\n",
            "[7,    60] loss: 0.262\n",
            "[7,    70] loss: 0.250\n",
            "[7,    80] loss: 0.257\n",
            "[7,    90] loss: 0.255\n",
            "[7,   100] loss: 0.273\n",
            "[7,   110] loss: 0.243\n",
            "[7,   120] loss: 0.280\n",
            "[7,   130] loss: 0.255\n",
            "[7,   140] loss: 0.279\n",
            "[7,   150] loss: 0.236\n",
            "[7,   160] loss: 0.230\n",
            "[7,   170] loss: 0.259\n",
            "[7,   180] loss: 0.267\n",
            "[7,   190] loss: 0.299\n",
            "[7,   200] loss: 0.261\n",
            "[7,   210] loss: 0.252\n",
            "[7,   220] loss: 0.242\n",
            "[7,   230] loss: 0.257\n",
            "[7,   240] loss: 0.274\n",
            "[7,   250] loss: 0.263\n",
            "[7,   260] loss: 0.259\n",
            "[7,   270] loss: 0.315\n",
            "[7,   280] loss: 0.270\n",
            "[7,   290] loss: 0.269\n",
            "[7,   300] loss: 0.261\n",
            "[7,   310] loss: 0.261\n",
            "[7,   320] loss: 0.299\n",
            "[7,   330] loss: 0.274\n",
            "[7,   340] loss: 0.224\n",
            "[7,   350] loss: 0.295\n",
            "[7,   360] loss: 0.247\n",
            "[7,   370] loss: 0.255\n",
            "[7,   380] loss: 0.279\n",
            "[7,   390] loss: 0.290\n",
            "[7,   400] loss: 0.236\n",
            "[7,   410] loss: 0.294\n",
            "[7,   420] loss: 0.275\n",
            "[7,   430] loss: 0.230\n",
            "[7,   440] loss: 0.259\n",
            "[7,   450] loss: 0.296\n",
            "[7,   460] loss: 0.252\n",
            "[7,   470] loss: 0.265\n",
            "[7,   480] loss: 0.331\n",
            "[7,   490] loss: 0.282\n",
            "[7,   500] loss: 0.295\n",
            "[7,   510] loss: 0.309\n",
            "[7,   520] loss: 0.265\n",
            "[7,   530] loss: 0.256\n",
            "[7,   540] loss: 0.266\n",
            "[8,    10] loss: 0.242\n",
            "[8,    20] loss: 0.247\n",
            "[8,    30] loss: 0.225\n",
            "[8,    40] loss: 0.238\n",
            "[8,    50] loss: 0.199\n",
            "[8,    60] loss: 0.219\n",
            "[8,    70] loss: 0.217\n",
            "[8,    80] loss: 0.236\n",
            "[8,    90] loss: 0.268\n",
            "[8,   100] loss: 0.252\n",
            "[8,   110] loss: 0.234\n",
            "[8,   120] loss: 0.220\n",
            "[8,   130] loss: 0.211\n",
            "[8,   140] loss: 0.235\n",
            "[8,   150] loss: 0.200\n",
            "[8,   160] loss: 0.231\n",
            "[8,   170] loss: 0.256\n",
            "[8,   180] loss: 0.238\n",
            "[8,   190] loss: 0.232\n",
            "[8,   200] loss: 0.229\n",
            "[8,   210] loss: 0.217\n",
            "[8,   220] loss: 0.212\n",
            "[8,   230] loss: 0.219\n",
            "[8,   240] loss: 0.254\n",
            "[8,   250] loss: 0.236\n",
            "[8,   260] loss: 0.248\n",
            "[8,   270] loss: 0.236\n",
            "[8,   280] loss: 0.284\n",
            "[8,   290] loss: 0.213\n",
            "[8,   300] loss: 0.256\n",
            "[8,   310] loss: 0.263\n",
            "[8,   320] loss: 0.239\n",
            "[8,   330] loss: 0.246\n",
            "[8,   340] loss: 0.250\n",
            "[8,   350] loss: 0.239\n",
            "[8,   360] loss: 0.253\n",
            "[8,   370] loss: 0.241\n",
            "[8,   380] loss: 0.219\n",
            "[8,   390] loss: 0.234\n",
            "[8,   400] loss: 0.244\n",
            "[8,   410] loss: 0.218\n",
            "[8,   420] loss: 0.254\n",
            "[8,   430] loss: 0.245\n",
            "[8,   440] loss: 0.274\n",
            "[8,   450] loss: 0.196\n",
            "[8,   460] loss: 0.226\n",
            "[8,   470] loss: 0.279\n",
            "[8,   480] loss: 0.265\n",
            "[8,   490] loss: 0.245\n",
            "[8,   500] loss: 0.226\n",
            "[8,   510] loss: 0.207\n",
            "[8,   520] loss: 0.216\n",
            "[8,   530] loss: 0.258\n",
            "[8,   540] loss: 0.232\n",
            "[9,    10] loss: 0.210\n",
            "[9,    20] loss: 0.186\n",
            "[9,    30] loss: 0.189\n",
            "[9,    40] loss: 0.188\n",
            "[9,    50] loss: 0.206\n",
            "[9,    60] loss: 0.207\n",
            "[9,    70] loss: 0.197\n",
            "[9,    80] loss: 0.183\n",
            "[9,    90] loss: 0.169\n",
            "[9,   100] loss: 0.175\n",
            "[9,   110] loss: 0.188\n",
            "[9,   120] loss: 0.166\n",
            "[9,   130] loss: 0.214\n",
            "[9,   140] loss: 0.215\n"
          ]
        }
      ],
      "source": [
        "# TODO: train for 1 epoch and check for test accuracy, whether there is a huge difference\n",
        "EPOCHS = 10\n",
        "IMG_SIZE = 256\n",
        "BATCH_SIZE = 64\n",
        "STEP_SIZE = 3\n",
        "GAMMA = 0.5\n",
        "DECAY = 0.00047\n",
        "\n",
        "data = get_birds_data(img_size=IMG_SIZE, batch_size=BATCH_SIZE)\n",
        "# print(data['train'].__dict__)\n",
        "# print(data['test'].__dict__)\n",
        "\n",
        "net = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
        "net.fc = nn.Linear(net.fc.in_features, 555)\n",
        "\n",
        "losses = train(net, data['train'], ck_path=CK_PATH, epochs=EPOCHS, decay=DECAY, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "print(\"Training   accuracy: %f\" % accuracy(net, data['train']))\n",
        "print(\"Validation accuracy: %f\" % accuracy(net, data['valid']))\n",
        "print(\"Testing accuracy: %f\" % accuracy(net, data['test']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add step size and gamma values for scheduler\n",
        "# add logic for loading checkpoints\n",
        "# add checkpoint path, checkpoint state parameters\n",
        "# add start epoch, initialize to 0, only update when there is a checkpoint state\n",
        "\n",
        "def train(net, dataloader, checkpoint=None, ck_path=None, epochs=1, lr=0.01, \n",
        "          momentum=0.9, decay=0.0, verbose=1, step_size=3, gamma=0.1):\n",
        "  net.to(device)\n",
        "  net.train()\n",
        "  start_epoch = 0\n",
        "  # keep track of used learning rates for plotting\n",
        "  lrs = []\n",
        "  losses = []\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=decay)\n",
        "  # use a step scheduler for learning rate schedules\n",
        "  # https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR\n",
        "  # https://neptune.ai/blog/how-to-choose-a-learning-rate-scheduler\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "  # https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html\n",
        "  if checkpoint:\n",
        "    net.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    losses = checkpoint['losses']\n",
        "\n",
        "  for epoch in range(start_epoch, epochs):\n",
        "    sum_loss = 0.0\n",
        "    for i, batch in enumerate(dataloader, 0):\n",
        "      # get the inputs; data is a list of [inputs, labels]\n",
        "      inputs, labels = batch[0].to(device), batch[1].to(device)\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # forward + backward + optimize \n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()  # autograd magic, computes all the partial derivatives\n",
        "      optimizer.step() # takes a step in gradient direction\n",
        "      \n",
        "\n",
        "      # print statistics\n",
        "      losses.append(loss.item())\n",
        "      sum_loss += loss.item()\n",
        "      if i % 10 == 9:    # print every 10 mini-batches\n",
        "        if verbose:\n",
        "          print('[%d, %5d] loss: %.3f' % (epoch, i + 1, sum_loss / 10))\n",
        "        sum_loss = 0.0\n",
        "\n",
        "    if ck_path:\n",
        "      # save current checkpoint into a pickle file\n",
        "      torch.save({\n",
        "                  'epoch': epoch + 1,\n",
        "                  'model_state_dict': net.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'losses': losses,\n",
        "                 }, os.path.join(CK_PATH, 'ck-%d.pkl' % (epoch + 1)))\n",
        "      \n",
        "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
        "    scheduler.step()\n",
        "  return losses"
      ],
      "metadata": {
        "id": "XMa_Y-6R1BZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: train for 1 epoch and check for test accuracy, whether there is a huge difference\n",
        "EPOCHS = 10\n",
        "IMG_SIZE = 256\n",
        "BATCH_SIZE = 64\n",
        "STEP_SIZE = 3\n",
        "GAMMA = 0.3\n",
        "DECAY = 0.00047\n",
        "\n",
        "data = get_birds_data(img_size=IMG_SIZE, batch_size=BATCH_SIZE)\n",
        "# print(data['train'].__dict__)\n",
        "# print(data['test'].__dict__)\n",
        "\n",
        "net = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
        "net.fc = nn.Linear(net.fc.in_features, 555)\n",
        "\n",
        "losses = train(net, data['train'], ck_path=CK_PATH, epochs=EPOCHS, decay=DECAY, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "print(\"Training   accuracy: %f\" % accuracy(net, data['train']))\n",
        "print(\"Validation accuracy: %f\" % accuracy(net, data['valid']))\n",
        "print(\"Testing accuracy: %f\" % accuracy(net, data['test']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wrjZSmBs1cSW",
        "outputId": "d9a3ae9d-8e3e-43a0-c945-75572ba15a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt101_32X8D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt101_32X8D_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-39843fef6abf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m555\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This will reinitialize the layer as well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/ck-10.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mck_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCK_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDECAY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training   accuracy: %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation accuracy: %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-1aa89c98a176>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, dataloader, checkpoint, ck_path, epochs, lr, momentum, decay, verbose, step_size, gamma)\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;31m# https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mstart_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1670\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1671\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1672\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"layer3.6.conv1.weight\", \"layer3.6.bn1.weight\", \"layer3.6.bn1.bias\", \"layer3.6.bn1.running_mean\", \"layer3.6.bn1.running_var\", \"layer3.6.conv2.weight\", \"layer3.6.bn2.weight\", \"layer3.6.bn2.bias\", \"layer3.6.bn2.running_mean\", \"layer3.6.bn2.running_var\", \"layer3.6.conv3.weight\", \"layer3.6.bn3.weight\", \"layer3.6.bn3.bias\", \"layer3.6.bn3.running_mean\", \"layer3.6.bn3.running_var\", \"layer3.7.conv1.weight\", \"layer3.7.bn1.weight\", \"layer3.7.bn1.bias\", \"layer3.7.bn1.running_mean\", \"layer3.7.bn1.running_var\", \"layer3.7.conv2.weight\", \"layer3.7.bn2.weight\", \"layer3.7.bn2.bias\", \"layer3.7.bn2.running_mean\", \"layer3.7.bn2.running_var\", \"layer3.7.conv3.weight\", \"layer3.7.bn3.weight\", \"layer3.7.bn3.bias\", \"layer3.7.bn3.running_mean\", \"layer3.7.bn3.running_var\", \"layer3.8.conv1.weight\", \"layer3.8.bn1.weight\", \"layer3.8.bn1.bias\", \"layer3.8.bn1.running_mean\", \"layer3.8.bn1.running_var\", \"layer3.8.conv2.weight\", \"layer3.8.bn2.weight\", \"layer3.8.bn2.bias\", \"layer3.8.bn2.running_mean\", \"layer3.8.bn2.running_var\", \"layer3.8.conv3.weight\", \"layer3.8.bn3.weight\", \"layer3.8.bn3.bias\", \"layer3.8.bn3.running_mean\", \"layer3.8.bn3.running_var\", \"layer3.9.conv1.weight\", \"layer3.9.bn1.weight\", \"layer3.9.bn1.bias\", \"layer3.9.bn1.running_mean\", \"layer3.9.bn1.running_var\", \"layer3.9.conv2.weight\", \"layer3.9.bn2.weight\", \"layer3.9.bn2.bias\", \"layer3.9.bn2.running_mean\", \"layer3.9.bn2.running_var\", \"layer3.9.conv3.weight\", \"layer3.9.bn3.weight\", \"layer3.9.bn3.bias\", \"layer3.9.b...\n\tsize mismatch for layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n\tsize mismatch for layer1.0.bn1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.0.bn1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.0.bn1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.0.bn1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.0.conv2.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 8, 3, 3]).\n\tsize mismatch for layer1.0.bn2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.0.bn2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.0.bn2.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.0.bn2.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.0.conv3.weight: copying a param with shape torch.Size([256, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([64, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for layer1.1.bn1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.1.bn1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.1.bn1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.1.bn1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.1.conv2.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 8, 3, 3]).\n\tsize mismatch for layer1.1.bn2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.1.bn2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.1.bn2.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.1.bn2.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.1.conv3.weight: copying a param with shape torch.Size([256, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for layer1.2.conv1.weight: copying a param with shape torch.Size([64, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for layer1.2.bn1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.2.bn1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.2.bn1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.2.bn1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.2.conv2.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 8, 3, 3]).\n\tsize mismatch for layer1.2.bn2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.2.bn2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.2.bn2.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.2.bn2.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for layer1.2.conv3.weight: copying a param with shape torch.Size([256, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for layer2.0.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for layer2.0.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.0.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.0.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.0.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.0.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 16, 3, 3]).\n\tsize mismatch for layer2.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.0.conv3.weight: copying a param with shape torch.Size([512, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).\n\tsize mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([128, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).\n\tsize mismatch for layer2.1.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.1.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.1.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.1.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.1.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 16, 3, 3]).\n\tsize mismatch for layer2.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.1.conv3.weight: copying a param with shape torch.Size([512, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).\n\tsize mismatch for layer2.2.conv1.weight: copying a param with shape torch.Size([128, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).\n\tsize mismatch for layer2.2.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.2.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.2.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.2.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.2.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 16, 3, 3]).\n\tsize mismatch for layer2.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.2.conv3.weight: copying a param with shape torch.Size([512, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).\n\tsize mismatch for layer2.3.conv1.weight: copying a param with shape torch.Size([128, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).\n\tsize mismatch for layer2.3.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.3.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.3.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.3.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.3.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 16, 3, 3]).\n\tsize mismatch for layer2.3.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.3.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.3.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.3.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.3.conv3.weight: copying a param with shape torch.Size([512, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).\n\tsize mismatch for layer3.0.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for layer3.0.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.0.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.0.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.0.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.0.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 32, 3, 3]).\n\tsize mismatch for layer3.0.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.0.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.0.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.0.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.0.conv3.weight: copying a param with shape torch.Size([1024, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 1, 1]).\n\tsize mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([256, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 1, 1]).\n\tsize mismatch for layer3.1.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.1.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.1.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.1.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.1.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 32, 3, 3]).\n\tsize mismatch for layer3.1.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.1.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.1.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.1.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.1.conv3.weight: copying a param with shape torch.Size([1024, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 1, 1]).\n\tsize mismatch for layer3.2.conv1.weight: copying a param with shape torch.Size([256, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 1, 1]).\n\tsize mismatch for layer3.2.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.2.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.2.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.2.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.2.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 32, 3, 3]).\n\tsize mismatch for layer3.2.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.2.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.2.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.2.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.2.conv3.weight: copying a param with shape torch.Size([1024, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 1, 1]).\n\tsize mismatch for layer3.3.conv1.weight: copying a param with shape torch.Size([256, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 1, 1]).\n\tsize mismatch for layer3.3.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.3.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.3.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.3.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.3.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 32, 3, 3]).\n\tsize mismatch for layer3.3.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.3.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.3.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.3.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.3.conv3.weight: copying a param with shape torch.Size([1024, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 1, 1]).\n\tsize mismatch for layer3.4.conv1.weight: copying a param with shape torch.Size([256, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 1, 1]).\n\tsize mismatch for layer3.4.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.4.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.4.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.4.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.4.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 32, 3, 3]).\n\tsize mismatch for layer3.4.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.4.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.4.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.4.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.4.conv3.weight: copying a param with shape torch.Size([1024, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 1, 1]).\n\tsize mismatch for layer3.5.conv1.weight: copying a param with shape torch.Size([256, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 1, 1]).\n\tsize mismatch for layer3.5.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.5.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.5.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.5.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.5.conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 32, 3, 3]).\n\tsize mismatch for layer3.5.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.5.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.5.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.5.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.5.conv3.weight: copying a param with shape torch.Size([1024, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 1, 1]).\n\tsize mismatch for layer4.0.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n\tsize mismatch for layer4.0.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.0.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.0.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.0.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.0.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 64, 3, 3]).\n\tsize mismatch for layer4.0.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.0.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.0.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.0.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.0.conv3.weight: copying a param with shape torch.Size([2048, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 1, 1]).\n\tsize mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([512, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 1, 1]).\n\tsize mismatch for layer4.1.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.1.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.1.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.1.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.1.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 64, 3, 3]).\n\tsize mismatch for layer4.1.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.1.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.1.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.1.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.1.conv3.weight: copying a param with shape torch.Size([2048, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 1, 1]).\n\tsize mismatch for layer4.2.conv1.weight: copying a param with shape torch.Size([512, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 1, 1]).\n\tsize mismatch for layer4.2.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.2.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.2.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.2.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.2.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 64, 3, 3]).\n\tsize mismatch for layer4.2.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.2.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.2.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.2.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.2.conv3.weight: copying a param with shape torch.Size([2048, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 1, 1])."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "IMG_SIZE = 256\n",
        "BATCH_SIZE = 32\n",
        "DECAY = 0.00047\n",
        "# Load model fraom checkpoint\n",
        "net = torch.hub.load('pytorch/vision:v0.10.0', 'resnext101_32x8d', pretrained=True)\n",
        "net.fc = nn.Linear(net.fc.in_features, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(BASE_PATH + '/ck-10.pkl')\n",
        "net.load_state_dict(state['model_state_dict'])\n",
        "data = get_birds_data(img_size=IMG_SIZE, batch_size=BATCH_SIZE)\n",
        "# predict(net, data['valid'], CK_PATH + \"preds.csv\")\n",
        "predict(net, data['test'], CK_PATH + \"preds.csv\")"
      ],
      "metadata": {
        "id": "9Vw0uVbB1CZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, dataloader, checkpoint=None, ck_path=None, epochs=1, lr=0.01, \n",
        "          momentum=0.9, decay=0.0, verbose=1, schedule={}):\n",
        "  net.to(device)\n",
        "  net.train()\n",
        "  start_epoch = 0\n",
        "  losses = []\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=decay)\n",
        "\n",
        "  if checkpoint:\n",
        "    net.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    losses = checkpoint['losses']\n",
        "  \n",
        "  # Fast forward lr schedule through already trained epochs\n",
        "  for epoch in range(start_epoch):\n",
        "    if epoch in schedule:\n",
        "      print (\"Learning rate: %f\"% schedule[epoch])\n",
        "      for g in optimizer.param_groups:\n",
        "        g['lr'] = schedule[epoch]\n",
        "\n",
        "  for epoch in range(start_epoch, epochs):\n",
        "    sum_loss = 0.0\n",
        "\n",
        "    # Update learning rate when scheduled\n",
        "    if epoch in schedule:\n",
        "      print (\"Learning rate: %f\"% schedule[epoch])\n",
        "      for g in optimizer.param_groups:\n",
        "        g['lr'] = schedule[epoch]\n",
        "    \n",
        "    for i, batch in enumerate(dataloader, 0):\n",
        "      # get the inputs; data is a list of [inputs, labels]\n",
        "      inputs, labels = batch[0].to(device), batch[1].to(device)\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # forward + backward + optimize \n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()  # autograd magic, computes all the partial derivatives\n",
        "      optimizer.step() # takes a step in gradient direction\n",
        "      \n",
        "\n",
        "      # print statistics\n",
        "      losses.append(loss.item())\n",
        "      sum_loss += loss.item()\n",
        "      if i % 10 == 9:    # print every 10 mini-batches\n",
        "        if verbose:\n",
        "          print('[%d, %5d] loss: %.3f' % (epoch, i + 1, sum_loss / 10))\n",
        "        sum_loss = 0.0\n",
        "\n",
        "    if ck_path:\n",
        "      # save current checkpoint into a pickle file\n",
        "      torch.save({\n",
        "                  'epoch': epoch + 1,\n",
        "                  'model_state_dict': net.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'losses': losses,\n",
        "                 }, os.path.join(CK_PATH, 'ck-%d.pkl' % (epoch + 1)))\n",
        "  return losses"
      ],
      "metadata": {
        "id": "Pwx-N9mapVdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changed train() function so that it doesn't use stepLR\n",
        "EPOCHS = 20\n",
        "IMG_SIZE = 256\n",
        "BATCH_SIZE = 32\n",
        "DECAY = 0.00047\n",
        "\n",
        "data = get_birds_data(img_size=IMG_SIZE, batch_size=BATCH_SIZE)\n",
        "\n",
        "net = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
        "net.fc = nn.Linear(net.fc.in_features, 555)\n",
        "\n",
        "losses = train(net, data['train'], ck_path=CK_PATH, epochs=EPOCHS, decay=DECAY, schedule={0: 0.01, 3: 0.0075, 5: 0.005, 7: 0.0025, 9: 0.001})\n",
        "\n",
        "print(\"Training   accuracy: %f\" % accuracy(net, data['train']))\n",
        "print(\"Validation accuracy: %f\" % accuracy(net, data['valid']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cWBIuSWpioE",
        "outputId": "21425c15-a3b0-4086-d93c-ce9604cfcfab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: 0.010000\n",
            "[0,    10] loss: 6.356\n",
            "[0,    20] loss: 6.347\n",
            "[0,    30] loss: 6.315\n",
            "[0,    40] loss: 6.144\n",
            "[0,    50] loss: 5.989\n",
            "[0,    60] loss: 5.724\n",
            "[0,    70] loss: 5.542\n",
            "[0,    80] loss: 5.307\n",
            "[0,    90] loss: 5.213\n",
            "[0,   100] loss: 5.144\n",
            "[0,   110] loss: 4.967\n",
            "[0,   120] loss: 4.912\n",
            "[0,   130] loss: 4.737\n",
            "[0,   140] loss: 4.558\n",
            "[0,   150] loss: 4.548\n",
            "[0,   160] loss: 4.220\n",
            "[0,   170] loss: 4.237\n",
            "[0,   180] loss: 4.240\n",
            "[0,   190] loss: 4.154\n",
            "[0,   200] loss: 3.939\n",
            "[0,   210] loss: 4.064\n",
            "[0,   220] loss: 3.744\n",
            "[0,   230] loss: 3.829\n",
            "[0,   240] loss: 3.673\n",
            "[0,   250] loss: 3.650\n",
            "[0,   260] loss: 3.580\n",
            "[0,   270] loss: 3.511\n",
            "[0,   280] loss: 3.697\n",
            "[0,   290] loss: 3.322\n",
            "[0,   300] loss: 3.505\n",
            "[0,   310] loss: 3.321\n",
            "[0,   320] loss: 3.295\n",
            "[0,   330] loss: 3.152\n",
            "[0,   340] loss: 3.464\n",
            "[0,   350] loss: 3.307\n",
            "[0,   360] loss: 3.215\n",
            "[0,   370] loss: 3.096\n",
            "[0,   380] loss: 3.092\n",
            "[0,   390] loss: 3.064\n",
            "[0,   400] loss: 2.820\n",
            "[0,   410] loss: 3.096\n",
            "[0,   420] loss: 2.940\n",
            "[0,   430] loss: 3.147\n",
            "[0,   440] loss: 2.828\n",
            "[0,   450] loss: 2.828\n",
            "[0,   460] loss: 2.899\n",
            "[0,   470] loss: 3.036\n",
            "[0,   480] loss: 2.933\n",
            "[0,   490] loss: 2.913\n",
            "[0,   500] loss: 2.872\n",
            "[0,   510] loss: 2.466\n",
            "[0,   520] loss: 2.666\n",
            "[0,   530] loss: 2.758\n",
            "[0,   540] loss: 2.727\n",
            "[0,   550] loss: 2.652\n",
            "[0,   560] loss: 2.654\n",
            "[0,   570] loss: 2.624\n",
            "[0,   580] loss: 2.646\n",
            "[0,   590] loss: 2.513\n",
            "[0,   600] loss: 2.472\n",
            "[0,   610] loss: 2.502\n",
            "[0,   620] loss: 2.442\n",
            "[0,   630] loss: 2.592\n",
            "[0,   640] loss: 2.677\n",
            "[0,   650] loss: 2.611\n",
            "[0,   660] loss: 2.595\n",
            "[0,   670] loss: 2.283\n",
            "[0,   680] loss: 2.498\n",
            "[0,   690] loss: 2.498\n",
            "[0,   700] loss: 2.493\n",
            "[0,   710] loss: 2.403\n",
            "[0,   720] loss: 2.303\n",
            "[0,   730] loss: 2.566\n",
            "[0,   740] loss: 2.440\n",
            "[0,   750] loss: 2.377\n",
            "[0,   760] loss: 2.327\n",
            "[0,   770] loss: 2.213\n",
            "[0,   780] loss: 2.327\n",
            "[0,   790] loss: 2.280\n",
            "[0,   800] loss: 2.320\n",
            "[0,   810] loss: 2.174\n",
            "[0,   820] loss: 2.360\n",
            "[0,   830] loss: 2.269\n",
            "[0,   840] loss: 2.105\n",
            "[0,   850] loss: 2.261\n",
            "[0,   860] loss: 2.258\n",
            "[0,   870] loss: 2.334\n",
            "[0,   880] loss: 2.237\n",
            "[0,   890] loss: 2.192\n",
            "[0,   900] loss: 2.076\n",
            "[0,   910] loss: 2.450\n",
            "[0,   920] loss: 2.232\n",
            "[0,   930] loss: 2.146\n",
            "[0,   940] loss: 2.097\n",
            "[0,   950] loss: 1.941\n",
            "[0,   960] loss: 2.206\n",
            "[0,   970] loss: 2.295\n",
            "[0,   980] loss: 2.051\n",
            "[0,   990] loss: 2.178\n",
            "[0,  1000] loss: 2.137\n",
            "[0,  1010] loss: 2.312\n",
            "[0,  1020] loss: 2.044\n",
            "[0,  1030] loss: 2.063\n",
            "[0,  1040] loss: 2.225\n",
            "[0,  1050] loss: 2.041\n",
            "[0,  1060] loss: 2.116\n",
            "[0,  1070] loss: 2.052\n",
            "[0,  1080] loss: 1.933\n",
            "[1,    10] loss: 1.794\n",
            "[1,    20] loss: 1.786\n",
            "[1,    30] loss: 1.810\n",
            "[1,    40] loss: 1.844\n",
            "[1,    50] loss: 1.916\n",
            "[1,    60] loss: 1.735\n",
            "[1,    70] loss: 1.749\n",
            "[1,    80] loss: 1.776\n",
            "[1,    90] loss: 1.790\n",
            "[1,   100] loss: 1.815\n",
            "[1,   110] loss: 1.818\n",
            "[1,   120] loss: 1.877\n",
            "[1,   130] loss: 1.839\n",
            "[1,   140] loss: 1.860\n",
            "[1,   150] loss: 1.847\n",
            "[1,   160] loss: 1.786\n",
            "[1,   170] loss: 1.716\n",
            "[1,   180] loss: 1.953\n",
            "[1,   190] loss: 1.689\n",
            "[1,   200] loss: 1.869\n",
            "[1,   210] loss: 1.693\n",
            "[1,   220] loss: 1.770\n",
            "[1,   230] loss: 1.743\n",
            "[1,   240] loss: 1.789\n",
            "[1,   250] loss: 1.958\n",
            "[1,   260] loss: 1.851\n",
            "[1,   270] loss: 1.658\n",
            "[1,   280] loss: 1.783\n",
            "[1,   290] loss: 1.649\n",
            "[1,   300] loss: 1.760\n",
            "[1,   310] loss: 1.672\n",
            "[1,   320] loss: 1.719\n",
            "[1,   330] loss: 1.579\n",
            "[1,   340] loss: 1.683\n",
            "[1,   350] loss: 1.720\n",
            "[1,   360] loss: 1.599\n",
            "[1,   370] loss: 1.645\n",
            "[1,   380] loss: 1.583\n",
            "[1,   390] loss: 1.600\n",
            "[1,   400] loss: 1.732\n",
            "[1,   410] loss: 1.901\n",
            "[1,   420] loss: 1.653\n",
            "[1,   430] loss: 1.776\n",
            "[1,   440] loss: 1.767\n",
            "[1,   450] loss: 1.743\n",
            "[1,   460] loss: 1.672\n",
            "[1,   470] loss: 1.759\n",
            "[1,   480] loss: 1.739\n",
            "[1,   490] loss: 1.919\n",
            "[1,   500] loss: 1.657\n",
            "[1,   510] loss: 1.922\n",
            "[1,   520] loss: 1.859\n",
            "[1,   530] loss: 1.726\n",
            "[1,   540] loss: 1.676\n",
            "[1,   550] loss: 1.961\n",
            "[1,   560] loss: 1.920\n",
            "[1,   570] loss: 1.735\n",
            "[1,   580] loss: 1.929\n",
            "[1,   590] loss: 1.672\n",
            "[1,   600] loss: 1.749\n",
            "[1,   610] loss: 1.695\n",
            "[1,   620] loss: 1.536\n",
            "[1,   630] loss: 1.663\n",
            "[1,   640] loss: 1.707\n",
            "[1,   650] loss: 1.586\n",
            "[1,   660] loss: 1.578\n",
            "[1,   670] loss: 1.733\n",
            "[1,   680] loss: 1.708\n",
            "[1,   690] loss: 1.582\n",
            "[1,   700] loss: 1.655\n",
            "[1,   710] loss: 1.651\n",
            "[1,   720] loss: 1.544\n",
            "[1,   730] loss: 1.644\n",
            "[1,   740] loss: 1.556\n",
            "[1,   750] loss: 1.678\n",
            "[1,   760] loss: 1.613\n",
            "[1,   770] loss: 1.536\n",
            "[1,   780] loss: 1.677\n",
            "[1,   790] loss: 1.404\n",
            "[1,   800] loss: 1.594\n",
            "[1,   810] loss: 1.635\n",
            "[1,   820] loss: 1.683\n",
            "[1,   830] loss: 1.615\n",
            "[1,   840] loss: 1.798\n",
            "[1,   850] loss: 1.643\n",
            "[1,   860] loss: 1.603\n",
            "[1,   870] loss: 1.509\n",
            "[1,   880] loss: 1.714\n",
            "[1,   890] loss: 1.529\n",
            "[1,   900] loss: 1.471\n",
            "[1,   910] loss: 1.464\n",
            "[1,   920] loss: 1.452\n",
            "[1,   930] loss: 1.618\n",
            "[1,   940] loss: 1.434\n",
            "[1,   950] loss: 1.537\n",
            "[1,   960] loss: 1.706\n",
            "[1,   970] loss: 1.572\n",
            "[1,   980] loss: 1.491\n",
            "[1,   990] loss: 1.678\n",
            "[1,  1000] loss: 1.564\n",
            "[1,  1010] loss: 1.683\n",
            "[1,  1020] loss: 1.572\n",
            "[1,  1030] loss: 1.584\n",
            "[1,  1040] loss: 1.551\n",
            "[1,  1050] loss: 1.406\n",
            "[1,  1060] loss: 1.640\n",
            "[1,  1070] loss: 1.507\n",
            "[1,  1080] loss: 1.430\n",
            "[2,    10] loss: 1.328\n",
            "[2,    20] loss: 1.423\n",
            "[2,    30] loss: 1.427\n",
            "[2,    40] loss: 1.197\n",
            "[2,    50] loss: 1.298\n",
            "[2,    60] loss: 1.308\n",
            "[2,    70] loss: 1.502\n",
            "[2,    80] loss: 1.236\n",
            "[2,    90] loss: 1.399\n",
            "[2,   100] loss: 1.253\n",
            "[2,   110] loss: 1.271\n",
            "[2,   120] loss: 1.416\n",
            "[2,   130] loss: 1.303\n",
            "[2,   140] loss: 1.254\n",
            "[2,   150] loss: 1.308\n",
            "[2,   160] loss: 1.240\n",
            "[2,   170] loss: 1.467\n",
            "[2,   180] loss: 1.189\n",
            "[2,   190] loss: 1.343\n",
            "[2,   200] loss: 1.331\n",
            "[2,   210] loss: 1.294\n",
            "[2,   220] loss: 1.481\n",
            "[2,   230] loss: 1.393\n",
            "[2,   240] loss: 1.293\n",
            "[2,   250] loss: 1.431\n",
            "[2,   260] loss: 1.294\n",
            "[2,   270] loss: 1.267\n",
            "[2,   280] loss: 1.458\n",
            "[2,   290] loss: 1.477\n",
            "[2,   300] loss: 1.397\n",
            "[2,   310] loss: 1.542\n",
            "[2,   320] loss: 1.273\n",
            "[2,   330] loss: 1.408\n",
            "[2,   340] loss: 1.215\n",
            "[2,   350] loss: 1.415\n",
            "[2,   360] loss: 1.300\n",
            "[2,   370] loss: 1.334\n",
            "[2,   380] loss: 1.394\n",
            "[2,   390] loss: 1.330\n",
            "[2,   400] loss: 1.305\n",
            "[2,   410] loss: 1.339\n",
            "[2,   420] loss: 1.359\n",
            "[2,   430] loss: 1.203\n",
            "[2,   440] loss: 1.360\n",
            "[2,   450] loss: 1.281\n",
            "[2,   460] loss: 1.284\n",
            "[2,   470] loss: 1.273\n",
            "[2,   480] loss: 1.247\n",
            "[2,   490] loss: 1.253\n",
            "[2,   500] loss: 1.288\n",
            "[2,   510] loss: 1.278\n",
            "[2,   520] loss: 1.154\n",
            "[2,   530] loss: 1.338\n",
            "[2,   540] loss: 1.287\n",
            "[2,   550] loss: 1.207\n",
            "[2,   560] loss: 1.452\n",
            "[2,   570] loss: 1.392\n",
            "[2,   580] loss: 1.355\n",
            "[2,   590] loss: 1.310\n",
            "[2,   600] loss: 1.308\n",
            "[2,   610] loss: 1.349\n",
            "[2,   620] loss: 1.285\n",
            "[2,   630] loss: 1.343\n",
            "[2,   640] loss: 1.315\n",
            "[2,   650] loss: 1.250\n",
            "[2,   660] loss: 1.248\n",
            "[2,   670] loss: 1.186\n",
            "[2,   680] loss: 1.353\n",
            "[2,   690] loss: 1.181\n",
            "[2,   700] loss: 1.259\n",
            "[2,   710] loss: 1.387\n",
            "[2,   720] loss: 1.418\n",
            "[2,   730] loss: 1.232\n",
            "[2,   740] loss: 1.336\n",
            "[2,   750] loss: 1.253\n",
            "[2,   760] loss: 1.371\n",
            "[2,   770] loss: 1.230\n",
            "[2,   780] loss: 1.346\n",
            "[2,   790] loss: 1.384\n",
            "[2,   800] loss: 1.296\n",
            "[2,   810] loss: 1.336\n",
            "[2,   820] loss: 1.169\n",
            "[2,   830] loss: 1.203\n",
            "[2,   840] loss: 1.328\n",
            "[2,   850] loss: 1.286\n",
            "[2,   860] loss: 1.265\n",
            "[2,   870] loss: 1.416\n",
            "[2,   880] loss: 1.213\n",
            "[2,   890] loss: 1.368\n",
            "[2,   900] loss: 1.411\n",
            "[2,   910] loss: 1.464\n",
            "[2,   920] loss: 1.469\n",
            "[2,   930] loss: 1.353\n",
            "[2,   940] loss: 1.166\n",
            "[2,   950] loss: 1.308\n",
            "[2,   960] loss: 1.236\n",
            "[2,   970] loss: 1.364\n",
            "[2,   980] loss: 1.461\n",
            "[2,   990] loss: 1.320\n",
            "[2,  1000] loss: 1.357\n",
            "[2,  1010] loss: 1.350\n",
            "[2,  1020] loss: 1.304\n",
            "[2,  1030] loss: 1.260\n",
            "[2,  1040] loss: 1.286\n",
            "[2,  1050] loss: 1.266\n",
            "[2,  1060] loss: 1.475\n",
            "[2,  1070] loss: 1.341\n",
            "[2,  1080] loss: 1.335\n",
            "Learning rate: 0.007500\n",
            "[3,    10] loss: 1.012\n",
            "[3,    20] loss: 1.016\n",
            "[3,    30] loss: 0.931\n",
            "[3,    40] loss: 0.951\n",
            "[3,    50] loss: 0.965\n",
            "[3,    60] loss: 1.005\n",
            "[3,    70] loss: 0.967\n",
            "[3,    80] loss: 1.027\n",
            "[3,    90] loss: 0.905\n",
            "[3,   100] loss: 0.838\n",
            "[3,   110] loss: 0.946\n",
            "[3,   120] loss: 0.908\n",
            "[3,   130] loss: 1.017\n",
            "[3,   140] loss: 1.007\n",
            "[3,   150] loss: 0.992\n",
            "[3,   160] loss: 0.918\n",
            "[3,   170] loss: 0.938\n",
            "[3,   180] loss: 1.050\n",
            "[3,   190] loss: 0.941\n",
            "[3,   200] loss: 0.994\n",
            "[3,   210] loss: 0.999\n",
            "[3,   220] loss: 0.963\n",
            "[3,   230] loss: 0.894\n",
            "[3,   240] loss: 0.838\n",
            "[3,   250] loss: 0.926\n",
            "[3,   260] loss: 0.913\n",
            "[3,   270] loss: 0.943\n",
            "[3,   280] loss: 0.988\n",
            "[3,   290] loss: 0.892\n",
            "[3,   300] loss: 0.864\n",
            "[3,   310] loss: 0.910\n",
            "[3,   320] loss: 0.840\n",
            "[3,   330] loss: 0.941\n",
            "[3,   340] loss: 0.994\n",
            "[3,   350] loss: 0.804\n",
            "[3,   360] loss: 0.871\n",
            "[3,   370] loss: 0.939\n",
            "[3,   380] loss: 0.836\n",
            "[3,   390] loss: 0.826\n",
            "[3,   400] loss: 0.861\n",
            "[3,   410] loss: 0.971\n",
            "[3,   420] loss: 0.909\n",
            "[3,   430] loss: 0.892\n",
            "[3,   440] loss: 0.836\n",
            "[3,   450] loss: 0.895\n",
            "[3,   460] loss: 0.821\n",
            "[3,   470] loss: 0.909\n",
            "[3,   480] loss: 1.070\n",
            "[3,   490] loss: 0.843\n",
            "[3,   500] loss: 0.763\n",
            "[3,   510] loss: 0.869\n",
            "[3,   520] loss: 0.839\n",
            "[3,   530] loss: 0.834\n",
            "[3,   540] loss: 0.928\n",
            "[3,   550] loss: 0.814\n",
            "[3,   560] loss: 0.985\n",
            "[3,   570] loss: 0.917\n",
            "[3,   580] loss: 0.818\n",
            "[3,   590] loss: 0.986\n",
            "[3,   600] loss: 0.846\n",
            "[3,   610] loss: 1.039\n",
            "[3,   620] loss: 0.809\n",
            "[3,   630] loss: 1.033\n",
            "[3,   640] loss: 0.851\n",
            "[3,   650] loss: 0.826\n",
            "[3,   660] loss: 0.954\n",
            "[3,   670] loss: 0.925\n",
            "[3,   680] loss: 0.921\n",
            "[3,   690] loss: 0.988\n",
            "[3,   700] loss: 0.969\n",
            "[3,   710] loss: 0.891\n",
            "[3,   720] loss: 1.094\n",
            "[3,   730] loss: 0.883\n",
            "[3,   740] loss: 0.880\n",
            "[3,   750] loss: 0.850\n",
            "[3,   760] loss: 0.863\n",
            "[3,   770] loss: 1.037\n",
            "[3,   780] loss: 0.860\n",
            "[3,   790] loss: 0.944\n",
            "[3,   800] loss: 1.002\n",
            "[3,   810] loss: 0.996\n",
            "[3,   820] loss: 0.923\n",
            "[3,   830] loss: 0.849\n",
            "[3,   840] loss: 0.912\n",
            "[3,   850] loss: 0.944\n",
            "[3,   860] loss: 1.030\n",
            "[3,   870] loss: 0.895\n",
            "[3,   880] loss: 0.975\n",
            "[3,   890] loss: 0.914\n",
            "[3,   900] loss: 0.992\n",
            "[3,   910] loss: 0.950\n",
            "[3,   920] loss: 0.950\n",
            "[3,   930] loss: 0.949\n",
            "[3,   940] loss: 0.933\n",
            "[3,   950] loss: 0.891\n",
            "[3,   960] loss: 0.918\n",
            "[3,   970] loss: 0.862\n",
            "[3,   980] loss: 0.893\n",
            "[3,   990] loss: 0.861\n",
            "[3,  1000] loss: 0.891\n",
            "[3,  1010] loss: 0.825\n",
            "[3,  1020] loss: 0.869\n",
            "[3,  1030] loss: 0.950\n",
            "[3,  1040] loss: 0.946\n",
            "[3,  1050] loss: 0.911\n",
            "[3,  1060] loss: 0.845\n",
            "[3,  1070] loss: 0.937\n",
            "[3,  1080] loss: 0.909\n",
            "[4,    10] loss: 0.773\n",
            "[4,    20] loss: 0.884\n",
            "[4,    30] loss: 0.813\n",
            "[4,    40] loss: 0.805\n",
            "[4,    50] loss: 0.723\n",
            "[4,    60] loss: 0.724\n",
            "[4,    70] loss: 0.716\n",
            "[4,    80] loss: 0.826\n",
            "[4,    90] loss: 0.825\n",
            "[4,   100] loss: 0.715\n",
            "[4,   110] loss: 0.763\n",
            "[4,   120] loss: 0.775\n",
            "[4,   130] loss: 0.803\n",
            "[4,   140] loss: 0.741\n",
            "[4,   150] loss: 0.785\n",
            "[4,   160] loss: 0.687\n",
            "[4,   170] loss: 0.786\n",
            "[4,   180] loss: 0.822\n",
            "[4,   190] loss: 0.703\n",
            "[4,   200] loss: 0.900\n",
            "[4,   210] loss: 0.803\n",
            "[4,   220] loss: 0.864\n",
            "[4,   230] loss: 0.741\n",
            "[4,   240] loss: 0.779\n",
            "[4,   250] loss: 0.743\n",
            "[4,   260] loss: 0.850\n",
            "[4,   270] loss: 0.786\n",
            "[4,   280] loss: 0.816\n",
            "[4,   290] loss: 0.778\n",
            "[4,   300] loss: 0.819\n",
            "[4,   310] loss: 0.819\n",
            "[4,   320] loss: 0.812\n",
            "[4,   330] loss: 0.693\n",
            "[4,   340] loss: 0.698\n",
            "[4,   350] loss: 0.748\n",
            "[4,   360] loss: 0.863\n",
            "[4,   370] loss: 0.854\n",
            "[4,   380] loss: 0.654\n",
            "[4,   390] loss: 0.776\n",
            "[4,   400] loss: 0.745\n",
            "[4,   410] loss: 0.726\n",
            "[4,   420] loss: 0.717\n",
            "[4,   430] loss: 0.747\n",
            "[4,   440] loss: 0.796\n",
            "[4,   450] loss: 0.677\n",
            "[4,   460] loss: 0.748\n",
            "[4,   470] loss: 0.673\n",
            "[4,   480] loss: 0.801\n",
            "[4,   490] loss: 0.887\n",
            "[4,   500] loss: 0.772\n",
            "[4,   510] loss: 0.747\n",
            "[4,   520] loss: 0.874\n",
            "[4,   530] loss: 0.661\n",
            "[4,   540] loss: 0.787\n",
            "[4,   550] loss: 0.764\n",
            "[4,   560] loss: 0.689\n",
            "[4,   570] loss: 0.705\n",
            "[4,   580] loss: 0.778\n",
            "[4,   590] loss: 0.718\n",
            "[4,   600] loss: 0.874\n",
            "[4,   610] loss: 0.804\n",
            "[4,   620] loss: 0.772\n",
            "[4,   630] loss: 0.814\n",
            "[4,   640] loss: 0.862\n",
            "[4,   650] loss: 0.768\n",
            "[4,   660] loss: 0.698\n",
            "[4,   670] loss: 0.772\n",
            "[4,   680] loss: 0.831\n",
            "[4,   690] loss: 0.728\n",
            "[4,   700] loss: 0.826\n",
            "[4,   710] loss: 0.767\n",
            "[4,   720] loss: 0.706\n",
            "[4,   730] loss: 0.946\n",
            "[4,   740] loss: 0.766\n",
            "[4,   750] loss: 0.660\n",
            "[4,   760] loss: 0.873\n",
            "[4,   770] loss: 0.829\n",
            "[4,   780] loss: 0.832\n",
            "[4,   790] loss: 0.822\n",
            "[4,   800] loss: 0.822\n",
            "[4,   810] loss: 0.774\n",
            "[4,   820] loss: 0.760\n",
            "[4,   830] loss: 0.772\n",
            "[4,   840] loss: 0.898\n",
            "[4,   850] loss: 0.899\n",
            "[4,   860] loss: 0.868\n",
            "[4,   870] loss: 0.951\n",
            "[4,   880] loss: 0.764\n",
            "[4,   890] loss: 0.930\n",
            "[4,   900] loss: 0.855\n",
            "[4,   910] loss: 0.769\n",
            "[4,   920] loss: 0.869\n",
            "[4,   930] loss: 0.786\n",
            "[4,   940] loss: 0.890\n",
            "[4,   950] loss: 0.741\n",
            "[4,   960] loss: 0.820\n",
            "[4,   970] loss: 0.737\n",
            "[4,   980] loss: 0.769\n",
            "[4,   990] loss: 0.894\n",
            "[4,  1000] loss: 0.757\n",
            "[4,  1010] loss: 0.686\n",
            "[4,  1020] loss: 0.920\n",
            "[4,  1030] loss: 0.750\n",
            "[4,  1040] loss: 0.816\n",
            "[4,  1050] loss: 0.779\n",
            "[4,  1060] loss: 0.907\n",
            "[4,  1070] loss: 0.727\n",
            "[4,  1080] loss: 0.913\n",
            "Learning rate: 0.005000\n",
            "[5,    10] loss: 0.699\n",
            "[5,    20] loss: 0.566\n",
            "[5,    30] loss: 0.568\n",
            "[5,    40] loss: 0.561\n",
            "[5,    50] loss: 0.549\n",
            "[5,    60] loss: 0.498\n",
            "[5,    70] loss: 0.548\n",
            "[5,    80] loss: 0.679\n",
            "[5,    90] loss: 0.600\n",
            "[5,   100] loss: 0.563\n",
            "[5,   110] loss: 0.572\n",
            "[5,   120] loss: 0.505\n",
            "[5,   130] loss: 0.481\n",
            "[5,   140] loss: 0.516\n",
            "[5,   150] loss: 0.487\n",
            "[5,   160] loss: 0.528\n",
            "[5,   170] loss: 0.455\n",
            "[5,   180] loss: 0.504\n",
            "[5,   190] loss: 0.541\n",
            "[5,   200] loss: 0.524\n",
            "[5,   210] loss: 0.537\n",
            "[5,   220] loss: 0.463\n",
            "[5,   230] loss: 0.480\n",
            "[5,   240] loss: 0.476\n",
            "[5,   250] loss: 0.464\n",
            "[5,   260] loss: 0.523\n",
            "[5,   270] loss: 0.504\n",
            "[5,   280] loss: 0.583\n",
            "[5,   290] loss: 0.540\n",
            "[5,   300] loss: 0.529\n",
            "[5,   310] loss: 0.446\n",
            "[5,   320] loss: 0.514\n",
            "[5,   330] loss: 0.511\n",
            "[5,   340] loss: 0.502\n",
            "[5,   350] loss: 0.465\n",
            "[5,   360] loss: 0.484\n",
            "[5,   370] loss: 0.493\n",
            "[5,   380] loss: 0.552\n",
            "[5,   390] loss: 0.534\n",
            "[5,   400] loss: 0.563\n",
            "[5,   410] loss: 0.504\n",
            "[5,   420] loss: 0.536\n",
            "[5,   430] loss: 0.476\n",
            "[5,   440] loss: 0.575\n",
            "[5,   450] loss: 0.502\n",
            "[5,   460] loss: 0.526\n",
            "[5,   470] loss: 0.487\n",
            "[5,   480] loss: 0.540\n",
            "[5,   490] loss: 0.485\n",
            "[5,   500] loss: 0.550\n",
            "[5,   510] loss: 0.561\n",
            "[5,   520] loss: 0.498\n",
            "[5,   530] loss: 0.485\n",
            "[5,   540] loss: 0.574\n",
            "[5,   550] loss: 0.439\n",
            "[5,   560] loss: 0.461\n",
            "[5,   570] loss: 0.509\n",
            "[5,   580] loss: 0.523\n",
            "[5,   590] loss: 0.433\n",
            "[5,   600] loss: 0.515\n",
            "[5,   610] loss: 0.469\n",
            "[5,   620] loss: 0.538\n",
            "[5,   630] loss: 0.496\n",
            "[5,   640] loss: 0.521\n",
            "[5,   650] loss: 0.477\n",
            "[5,   660] loss: 0.555\n",
            "[5,   670] loss: 0.471\n",
            "[5,   680] loss: 0.437\n",
            "[5,   690] loss: 0.546\n",
            "[5,   700] loss: 0.508\n",
            "[5,   710] loss: 0.462\n",
            "[5,   720] loss: 0.493\n",
            "[5,   730] loss: 0.586\n",
            "[5,   740] loss: 0.396\n",
            "[5,   750] loss: 0.504\n",
            "[5,   760] loss: 0.441\n",
            "[5,   770] loss: 0.503\n",
            "[5,   780] loss: 0.527\n",
            "[5,   790] loss: 0.538\n",
            "[5,   800] loss: 0.506\n",
            "[5,   810] loss: 0.418\n",
            "[5,   820] loss: 0.517\n",
            "[5,   830] loss: 0.517\n",
            "[5,   840] loss: 0.648\n",
            "[5,   850] loss: 0.453\n",
            "[5,   860] loss: 0.574\n",
            "[5,   870] loss: 0.470\n",
            "[5,   880] loss: 0.575\n",
            "[5,   890] loss: 0.559\n",
            "[5,   900] loss: 0.499\n",
            "[5,   910] loss: 0.560\n",
            "[5,   920] loss: 0.515\n",
            "[5,   930] loss: 0.621\n",
            "[5,   940] loss: 0.459\n",
            "[5,   950] loss: 0.514\n",
            "[5,   960] loss: 0.546\n",
            "[5,   970] loss: 0.560\n",
            "[5,   980] loss: 0.541\n",
            "[5,   990] loss: 0.509\n",
            "[5,  1000] loss: 0.484\n",
            "[5,  1010] loss: 0.612\n",
            "[5,  1020] loss: 0.453\n",
            "[5,  1030] loss: 0.508\n",
            "[5,  1040] loss: 0.622\n",
            "[5,  1050] loss: 0.549\n",
            "[5,  1060] loss: 0.512\n",
            "[5,  1070] loss: 0.475\n",
            "[5,  1080] loss: 0.516\n",
            "[6,    10] loss: 0.428\n",
            "[6,    20] loss: 0.361\n",
            "[6,    30] loss: 0.376\n",
            "[6,    40] loss: 0.488\n",
            "[6,    50] loss: 0.330\n",
            "[6,    60] loss: 0.438\n",
            "[6,    70] loss: 0.407\n",
            "[6,    80] loss: 0.464\n",
            "[6,    90] loss: 0.437\n",
            "[6,   100] loss: 0.422\n",
            "[6,   110] loss: 0.404\n",
            "[6,   120] loss: 0.404\n",
            "[6,   130] loss: 0.409\n",
            "[6,   140] loss: 0.390\n",
            "[6,   150] loss: 0.374\n",
            "[6,   160] loss: 0.393\n",
            "[6,   170] loss: 0.317\n",
            "[6,   180] loss: 0.452\n",
            "[6,   190] loss: 0.388\n",
            "[6,   200] loss: 0.411\n",
            "[6,   210] loss: 0.423\n",
            "[6,   220] loss: 0.416\n",
            "[6,   230] loss: 0.485\n",
            "[6,   240] loss: 0.345\n",
            "[6,   250] loss: 0.475\n",
            "[6,   260] loss: 0.371\n",
            "[6,   270] loss: 0.302\n",
            "[6,   280] loss: 0.430\n",
            "[6,   290] loss: 0.364\n",
            "[6,   300] loss: 0.456\n",
            "[6,   310] loss: 0.368\n",
            "[6,   320] loss: 0.446\n",
            "[6,   330] loss: 0.443\n",
            "[6,   340] loss: 0.391\n",
            "[6,   350] loss: 0.473\n",
            "[6,   360] loss: 0.324\n",
            "[6,   370] loss: 0.402\n",
            "[6,   380] loss: 0.429\n",
            "[6,   390] loss: 0.373\n",
            "[6,   400] loss: 0.419\n",
            "[6,   410] loss: 0.390\n",
            "[6,   420] loss: 0.445\n",
            "[6,   430] loss: 0.437\n",
            "[6,   440] loss: 0.408\n",
            "[6,   450] loss: 0.492\n",
            "[6,   460] loss: 0.439\n",
            "[6,   470] loss: 0.467\n",
            "[6,   480] loss: 0.375\n",
            "[6,   490] loss: 0.408\n",
            "[6,   500] loss: 0.464\n",
            "[6,   510] loss: 0.446\n",
            "[6,   520] loss: 0.473\n",
            "[6,   530] loss: 0.399\n",
            "[6,   540] loss: 0.468\n",
            "[6,   550] loss: 0.478\n",
            "[6,   560] loss: 0.494\n",
            "[6,   570] loss: 0.396\n",
            "[6,   580] loss: 0.442\n",
            "[6,   590] loss: 0.481\n",
            "[6,   600] loss: 0.415\n",
            "[6,   610] loss: 0.448\n",
            "[6,   620] loss: 0.472\n",
            "[6,   630] loss: 0.465\n",
            "[6,   640] loss: 0.425\n",
            "[6,   650] loss: 0.512\n",
            "[6,   660] loss: 0.410\n",
            "[6,   670] loss: 0.491\n",
            "[6,   680] loss: 0.461\n",
            "[6,   690] loss: 0.418\n",
            "[6,   700] loss: 0.390\n",
            "[6,   710] loss: 0.427\n",
            "[6,   720] loss: 0.468\n",
            "[6,   730] loss: 0.497\n",
            "[6,   740] loss: 0.456\n",
            "[6,   750] loss: 0.435\n",
            "[6,   760] loss: 0.395\n",
            "[6,   770] loss: 0.557\n",
            "[6,   780] loss: 0.441\n",
            "[6,   790] loss: 0.368\n",
            "[6,   800] loss: 0.402\n",
            "[6,   810] loss: 0.432\n",
            "[6,   820] loss: 0.447\n",
            "[6,   830] loss: 0.515\n",
            "[6,   840] loss: 0.452\n",
            "[6,   850] loss: 0.444\n",
            "[6,   860] loss: 0.464\n",
            "[6,   870] loss: 0.428\n",
            "[6,   880] loss: 0.567\n",
            "[6,   890] loss: 0.393\n",
            "[6,   900] loss: 0.474\n",
            "[6,   910] loss: 0.501\n",
            "[6,   920] loss: 0.478\n",
            "[6,   930] loss: 0.447\n",
            "[6,   940] loss: 0.438\n",
            "[6,   950] loss: 0.446\n",
            "[6,   960] loss: 0.425\n",
            "[6,   970] loss: 0.404\n",
            "[6,   980] loss: 0.508\n",
            "[6,   990] loss: 0.506\n",
            "[6,  1000] loss: 0.492\n",
            "[6,  1010] loss: 0.499\n",
            "[6,  1020] loss: 0.486\n",
            "[6,  1030] loss: 0.515\n",
            "[6,  1040] loss: 0.417\n",
            "[6,  1050] loss: 0.590\n",
            "[6,  1060] loss: 0.498\n",
            "[6,  1070] loss: 0.443\n",
            "[6,  1080] loss: 0.538\n",
            "Learning rate: 0.002500\n",
            "[7,    10] loss: 0.299\n",
            "[7,    20] loss: 0.285\n",
            "[7,    30] loss: 0.333\n",
            "[7,    40] loss: 0.312\n",
            "[7,    50] loss: 0.333\n",
            "[7,    60] loss: 0.289\n",
            "[7,    70] loss: 0.295\n",
            "[7,    80] loss: 0.305\n",
            "[7,    90] loss: 0.365\n",
            "[7,   100] loss: 0.283\n",
            "[7,   110] loss: 0.283\n",
            "[7,   120] loss: 0.296\n",
            "[7,   130] loss: 0.232\n",
            "[7,   140] loss: 0.291\n",
            "[7,   150] loss: 0.263\n",
            "[7,   160] loss: 0.222\n",
            "[7,   170] loss: 0.240\n",
            "[7,   180] loss: 0.293\n",
            "[7,   190] loss: 0.280\n",
            "[7,   200] loss: 0.257\n",
            "[7,   210] loss: 0.287\n",
            "[7,   220] loss: 0.252\n",
            "[7,   230] loss: 0.379\n",
            "[7,   240] loss: 0.258\n",
            "[7,   250] loss: 0.235\n",
            "[7,   260] loss: 0.221\n",
            "[7,   270] loss: 0.259\n",
            "[7,   280] loss: 0.270\n",
            "[7,   290] loss: 0.240\n",
            "[7,   300] loss: 0.256\n",
            "[7,   310] loss: 0.289\n",
            "[7,   320] loss: 0.334\n",
            "[7,   330] loss: 0.269\n",
            "[7,   340] loss: 0.247\n",
            "[7,   350] loss: 0.322\n",
            "[7,   360] loss: 0.235\n",
            "[7,   370] loss: 0.283\n",
            "[7,   380] loss: 0.299\n",
            "[7,   390] loss: 0.282\n",
            "[7,   400] loss: 0.305\n",
            "[7,   410] loss: 0.233\n",
            "[7,   420] loss: 0.335\n",
            "[7,   430] loss: 0.258\n",
            "[7,   440] loss: 0.284\n",
            "[7,   450] loss: 0.314\n",
            "[7,   460] loss: 0.299\n",
            "[7,   470] loss: 0.253\n",
            "[7,   480] loss: 0.234\n",
            "[7,   490] loss: 0.273\n",
            "[7,   500] loss: 0.292\n",
            "[7,   510] loss: 0.271\n",
            "[7,   520] loss: 0.259\n",
            "[7,   530] loss: 0.281\n",
            "[7,   540] loss: 0.281\n",
            "[7,   550] loss: 0.235\n",
            "[7,   560] loss: 0.271\n",
            "[7,   570] loss: 0.253\n",
            "[7,   580] loss: 0.203\n",
            "[7,   590] loss: 0.217\n",
            "[7,   600] loss: 0.239\n",
            "[7,   610] loss: 0.307\n",
            "[7,   620] loss: 0.297\n",
            "[7,   630] loss: 0.300\n",
            "[7,   640] loss: 0.269\n",
            "[7,   650] loss: 0.241\n",
            "[7,   660] loss: 0.281\n",
            "[7,   670] loss: 0.332\n",
            "[7,   680] loss: 0.223\n",
            "[7,   690] loss: 0.252\n",
            "[7,   700] loss: 0.306\n",
            "[7,   710] loss: 0.226\n",
            "[7,   720] loss: 0.278\n",
            "[7,   730] loss: 0.226\n",
            "[7,   740] loss: 0.271\n",
            "[7,   750] loss: 0.266\n",
            "[7,   760] loss: 0.283\n",
            "[7,   770] loss: 0.198\n",
            "[7,   780] loss: 0.210\n",
            "[7,   790] loss: 0.312\n",
            "[7,   800] loss: 0.302\n",
            "[7,   810] loss: 0.327\n",
            "[7,   820] loss: 0.282\n",
            "[7,   830] loss: 0.233\n",
            "[7,   840] loss: 0.255\n",
            "[7,   850] loss: 0.253\n",
            "[7,   860] loss: 0.233\n",
            "[7,   870] loss: 0.253\n",
            "[7,   880] loss: 0.236\n",
            "[7,   890] loss: 0.224\n",
            "[7,   900] loss: 0.298\n",
            "[7,   910] loss: 0.254\n",
            "[7,   920] loss: 0.223\n",
            "[7,   930] loss: 0.247\n",
            "[7,   940] loss: 0.255\n",
            "[7,   950] loss: 0.406\n",
            "[7,   960] loss: 0.261\n",
            "[7,   970] loss: 0.193\n",
            "[7,   980] loss: 0.216\n",
            "[7,   990] loss: 0.324\n",
            "[7,  1000] loss: 0.237\n",
            "[7,  1010] loss: 0.244\n",
            "[7,  1020] loss: 0.273\n",
            "[7,  1030] loss: 0.255\n",
            "[7,  1040] loss: 0.286\n",
            "[7,  1050] loss: 0.316\n",
            "[7,  1060] loss: 0.260\n",
            "[7,  1070] loss: 0.233\n",
            "[7,  1080] loss: 0.246\n",
            "[8,    10] loss: 0.170\n",
            "[8,    20] loss: 0.189\n",
            "[8,    30] loss: 0.185\n",
            "[8,    40] loss: 0.246\n",
            "[8,    50] loss: 0.160\n",
            "[8,    60] loss: 0.150\n",
            "[8,    70] loss: 0.204\n",
            "[8,    80] loss: 0.205\n",
            "[8,    90] loss: 0.225\n",
            "[8,   100] loss: 0.209\n",
            "[8,   110] loss: 0.284\n",
            "[8,   120] loss: 0.211\n",
            "[8,   130] loss: 0.220\n",
            "[8,   140] loss: 0.251\n",
            "[8,   150] loss: 0.263\n",
            "[8,   160] loss: 0.192\n",
            "[8,   170] loss: 0.230\n",
            "[8,   180] loss: 0.178\n",
            "[8,   190] loss: 0.207\n",
            "[8,   200] loss: 0.205\n",
            "[8,   210] loss: 0.215\n",
            "[8,   220] loss: 0.181\n",
            "[8,   230] loss: 0.212\n",
            "[8,   240] loss: 0.180\n",
            "[8,   250] loss: 0.167\n",
            "[8,   260] loss: 0.212\n",
            "[8,   270] loss: 0.212\n",
            "[8,   280] loss: 0.166\n",
            "[8,   290] loss: 0.194\n",
            "[8,   300] loss: 0.234\n",
            "[8,   310] loss: 0.195\n",
            "[8,   320] loss: 0.175\n",
            "[8,   330] loss: 0.233\n",
            "[8,   340] loss: 0.199\n",
            "[8,   350] loss: 0.151\n",
            "[8,   360] loss: 0.204\n",
            "[8,   370] loss: 0.181\n",
            "[8,   380] loss: 0.149\n",
            "[8,   390] loss: 0.241\n",
            "[8,   400] loss: 0.226\n",
            "[8,   410] loss: 0.201\n",
            "[8,   420] loss: 0.212\n",
            "[8,   430] loss: 0.184\n",
            "[8,   440] loss: 0.232\n",
            "[8,   450] loss: 0.220\n",
            "[8,   460] loss: 0.216\n",
            "[8,   470] loss: 0.217\n",
            "[8,   480] loss: 0.149\n",
            "[8,   490] loss: 0.166\n",
            "[8,   500] loss: 0.198\n",
            "[8,   510] loss: 0.241\n",
            "[8,   520] loss: 0.216\n",
            "[8,   530] loss: 0.217\n",
            "[8,   540] loss: 0.189\n",
            "[8,   550] loss: 0.196\n",
            "[8,   560] loss: 0.189\n",
            "[8,   570] loss: 0.188\n",
            "[8,   580] loss: 0.178\n",
            "[8,   590] loss: 0.216\n",
            "[8,   600] loss: 0.173\n",
            "[8,   610] loss: 0.191\n",
            "[8,   620] loss: 0.223\n",
            "[8,   630] loss: 0.236\n",
            "[8,   640] loss: 0.293\n",
            "[8,   650] loss: 0.219\n",
            "[8,   660] loss: 0.231\n",
            "[8,   670] loss: 0.218\n",
            "[8,   680] loss: 0.223\n",
            "[8,   690] loss: 0.201\n",
            "[8,   700] loss: 0.170\n",
            "[8,   710] loss: 0.256\n",
            "[8,   720] loss: 0.180\n",
            "[8,   730] loss: 0.228\n",
            "[8,   740] loss: 0.190\n",
            "[8,   750] loss: 0.226\n",
            "[8,   760] loss: 0.226\n",
            "[8,   770] loss: 0.174\n",
            "[8,   780] loss: 0.196\n",
            "[8,   790] loss: 0.172\n",
            "[8,   800] loss: 0.230\n",
            "[8,   810] loss: 0.234\n",
            "[8,   820] loss: 0.218\n",
            "[8,   830] loss: 0.219\n",
            "[8,   840] loss: 0.195\n",
            "[8,   850] loss: 0.188\n",
            "[8,   860] loss: 0.169\n",
            "[8,   870] loss: 0.205\n",
            "[8,   880] loss: 0.198\n",
            "[8,   890] loss: 0.217\n",
            "[8,   900] loss: 0.235\n",
            "[8,   910] loss: 0.196\n",
            "[8,   920] loss: 0.229\n",
            "[8,   930] loss: 0.191\n",
            "[8,   940] loss: 0.201\n",
            "[8,   950] loss: 0.254\n",
            "[8,   960] loss: 0.197\n",
            "[8,   970] loss: 0.217\n",
            "[8,   980] loss: 0.235\n",
            "[8,   990] loss: 0.183\n",
            "[8,  1000] loss: 0.202\n",
            "[8,  1010] loss: 0.233\n",
            "[8,  1020] loss: 0.218\n",
            "[8,  1030] loss: 0.295\n",
            "[8,  1040] loss: 0.216\n",
            "[8,  1050] loss: 0.258\n",
            "[8,  1060] loss: 0.255\n",
            "[8,  1070] loss: 0.279\n",
            "[8,  1080] loss: 0.186\n",
            "Learning rate: 0.001000\n",
            "[9,    10] loss: 0.151\n",
            "[9,    20] loss: 0.157\n",
            "[9,    30] loss: 0.183\n",
            "[9,    40] loss: 0.158\n",
            "[9,    50] loss: 0.167\n",
            "[9,    60] loss: 0.116\n",
            "[9,    70] loss: 0.175\n",
            "[9,    80] loss: 0.141\n",
            "[9,    90] loss: 0.150\n",
            "[9,   100] loss: 0.157\n",
            "[9,   110] loss: 0.189\n",
            "[9,   120] loss: 0.157\n",
            "[9,   130] loss: 0.186\n",
            "[9,   140] loss: 0.202\n",
            "[9,   150] loss: 0.156\n",
            "[9,   160] loss: 0.152\n",
            "[9,   170] loss: 0.140\n",
            "[9,   180] loss: 0.142\n",
            "[9,   190] loss: 0.161\n",
            "[9,   200] loss: 0.160\n",
            "[9,   210] loss: 0.116\n",
            "[9,   220] loss: 0.175\n",
            "[9,   230] loss: 0.130\n",
            "[9,   240] loss: 0.115\n",
            "[9,   250] loss: 0.132\n",
            "[9,   260] loss: 0.187\n",
            "[9,   270] loss: 0.151\n",
            "[9,   280] loss: 0.156\n",
            "[9,   290] loss: 0.158\n",
            "[9,   300] loss: 0.199\n",
            "[9,   310] loss: 0.159\n",
            "[9,   320] loss: 0.141\n",
            "[9,   330] loss: 0.154\n",
            "[9,   340] loss: 0.125\n",
            "[9,   350] loss: 0.163\n",
            "[9,   360] loss: 0.120\n",
            "[9,   370] loss: 0.127\n",
            "[9,   380] loss: 0.138\n",
            "[9,   390] loss: 0.140\n",
            "[9,   400] loss: 0.169\n",
            "[9,   410] loss: 0.152\n",
            "[9,   420] loss: 0.137\n",
            "[9,   430] loss: 0.160\n",
            "[9,   440] loss: 0.172\n",
            "[9,   450] loss: 0.171\n",
            "[9,   460] loss: 0.139\n",
            "[9,   470] loss: 0.155\n",
            "[9,   480] loss: 0.130\n",
            "[9,   490] loss: 0.161\n",
            "[9,   500] loss: 0.109\n",
            "[9,   510] loss: 0.152\n",
            "[9,   520] loss: 0.158\n",
            "[9,   530] loss: 0.121\n",
            "[9,   540] loss: 0.148\n",
            "[9,   550] loss: 0.136\n",
            "[9,   560] loss: 0.113\n",
            "[9,   570] loss: 0.164\n",
            "[9,   580] loss: 0.120\n",
            "[9,   590] loss: 0.143\n",
            "[9,   600] loss: 0.119\n",
            "[9,   610] loss: 0.151\n",
            "[9,   620] loss: 0.139\n",
            "[9,   630] loss: 0.159\n",
            "[9,   640] loss: 0.159\n",
            "[9,   650] loss: 0.151\n",
            "[9,   660] loss: 0.162\n",
            "[9,   670] loss: 0.184\n",
            "[9,   680] loss: 0.131\n",
            "[9,   690] loss: 0.121\n",
            "[9,   700] loss: 0.166\n",
            "[9,   710] loss: 0.166\n",
            "[9,   720] loss: 0.105\n",
            "[9,   730] loss: 0.140\n",
            "[9,   740] loss: 0.144\n",
            "[9,   750] loss: 0.147\n",
            "[9,   760] loss: 0.164\n",
            "[9,   770] loss: 0.159\n",
            "[9,   780] loss: 0.136\n",
            "[9,   790] loss: 0.161\n",
            "[9,   800] loss: 0.146\n",
            "[9,   810] loss: 0.137\n",
            "[9,   820] loss: 0.182\n",
            "[9,   830] loss: 0.143\n",
            "[9,   840] loss: 0.175\n",
            "[9,   850] loss: 0.127\n",
            "[9,   860] loss: 0.150\n",
            "[9,   870] loss: 0.179\n",
            "[9,   880] loss: 0.139\n",
            "[9,   890] loss: 0.152\n",
            "[9,   900] loss: 0.131\n",
            "[9,   910] loss: 0.137\n",
            "[9,   920] loss: 0.140\n",
            "[9,   930] loss: 0.145\n",
            "[9,   940] loss: 0.115\n",
            "[9,   950] loss: 0.116\n",
            "[9,   960] loss: 0.171\n",
            "[9,   970] loss: 0.112\n",
            "[9,   980] loss: 0.156\n",
            "[9,   990] loss: 0.185\n",
            "[9,  1000] loss: 0.126\n",
            "[9,  1010] loss: 0.140\n",
            "[9,  1020] loss: 0.198\n",
            "[9,  1030] loss: 0.126\n",
            "[9,  1040] loss: 0.165\n",
            "[9,  1050] loss: 0.106\n",
            "[9,  1060] loss: 0.131\n",
            "[9,  1070] loss: 0.168\n",
            "[9,  1080] loss: 0.125\n",
            "[10,    10] loss: 0.156\n",
            "[10,    20] loss: 0.110\n",
            "[10,    30] loss: 0.115\n",
            "[10,    40] loss: 0.144\n",
            "[10,    50] loss: 0.145\n",
            "[10,    60] loss: 0.117\n",
            "[10,    70] loss: 0.108\n",
            "[10,    80] loss: 0.141\n",
            "[10,    90] loss: 0.162\n",
            "[10,   100] loss: 0.121\n",
            "[10,   110] loss: 0.170\n",
            "[10,   120] loss: 0.168\n",
            "[10,   130] loss: 0.101\n",
            "[10,   140] loss: 0.143\n",
            "[10,   150] loss: 0.113\n",
            "[10,   160] loss: 0.163\n",
            "[10,   170] loss: 0.182\n",
            "[10,   180] loss: 0.101\n",
            "[10,   190] loss: 0.132\n",
            "[10,   200] loss: 0.115\n",
            "[10,   210] loss: 0.126\n",
            "[10,   220] loss: 0.126\n",
            "[10,   230] loss: 0.138\n",
            "[10,   240] loss: 0.163\n",
            "[10,   250] loss: 0.116\n",
            "[10,   260] loss: 0.146\n",
            "[10,   270] loss: 0.184\n",
            "[10,   280] loss: 0.164\n",
            "[10,   290] loss: 0.176\n",
            "[10,   300] loss: 0.114\n",
            "[10,   310] loss: 0.134\n",
            "[10,   320] loss: 0.158\n",
            "[10,   330] loss: 0.120\n",
            "[10,   340] loss: 0.103\n",
            "[10,   350] loss: 0.163\n",
            "[10,   360] loss: 0.103\n",
            "[10,   370] loss: 0.154\n",
            "[10,   380] loss: 0.120\n",
            "[10,   390] loss: 0.094\n",
            "[10,   400] loss: 0.161\n",
            "[10,   410] loss: 0.150\n",
            "[10,   420] loss: 0.156\n",
            "[10,   430] loss: 0.152\n",
            "[10,   440] loss: 0.141\n",
            "[10,   450] loss: 0.131\n",
            "[10,   460] loss: 0.131\n",
            "[10,   470] loss: 0.152\n",
            "[10,   480] loss: 0.137\n",
            "[10,   490] loss: 0.131\n",
            "[10,   500] loss: 0.133\n",
            "[10,   510] loss: 0.139\n",
            "[10,   520] loss: 0.114\n",
            "[10,   530] loss: 0.122\n",
            "[10,   540] loss: 0.143\n",
            "[10,   550] loss: 0.155\n",
            "[10,   560] loss: 0.137\n",
            "[10,   570] loss: 0.117\n",
            "[10,   580] loss: 0.115\n",
            "[10,   590] loss: 0.132\n",
            "[10,   600] loss: 0.190\n",
            "[10,   610] loss: 0.127\n",
            "[10,   620] loss: 0.127\n",
            "[10,   630] loss: 0.150\n",
            "[10,   640] loss: 0.124\n",
            "[10,   650] loss: 0.148\n",
            "[10,   660] loss: 0.109\n",
            "[10,   670] loss: 0.165\n",
            "[10,   680] loss: 0.143\n",
            "[10,   690] loss: 0.097\n",
            "[10,   700] loss: 0.117\n",
            "[10,   710] loss: 0.130\n",
            "[10,   720] loss: 0.105\n",
            "[10,   730] loss: 0.164\n",
            "[10,   740] loss: 0.113\n",
            "[10,   750] loss: 0.158\n",
            "[10,   760] loss: 0.141\n",
            "[10,   770] loss: 0.112\n",
            "[10,   780] loss: 0.129\n",
            "[10,   790] loss: 0.154\n",
            "[10,   800] loss: 0.122\n",
            "[10,   810] loss: 0.115\n",
            "[10,   820] loss: 0.125\n",
            "[10,   830] loss: 0.156\n",
            "[10,   840] loss: 0.146\n",
            "[10,   850] loss: 0.119\n",
            "[10,   860] loss: 0.098\n",
            "[10,   870] loss: 0.133\n",
            "[10,   880] loss: 0.162\n",
            "[10,   890] loss: 0.119\n",
            "[10,   900] loss: 0.143\n",
            "[10,   910] loss: 0.137\n",
            "[10,   920] loss: 0.173\n",
            "[10,   930] loss: 0.153\n",
            "[10,   940] loss: 0.108\n",
            "[10,   950] loss: 0.116\n",
            "[10,   960] loss: 0.104\n",
            "[10,   970] loss: 0.110\n",
            "[10,   980] loss: 0.121\n",
            "[10,   990] loss: 0.127\n",
            "[10,  1000] loss: 0.142\n",
            "[10,  1010] loss: 0.141\n",
            "[10,  1020] loss: 0.114\n",
            "[10,  1030] loss: 0.087\n",
            "[10,  1040] loss: 0.145\n",
            "[10,  1050] loss: 0.141\n",
            "[10,  1060] loss: 0.128\n",
            "[10,  1070] loss: 0.141\n",
            "[10,  1080] loss: 0.101\n",
            "[11,    10] loss: 0.102\n",
            "[11,    20] loss: 0.115\n",
            "[11,    30] loss: 0.133\n",
            "[11,    40] loss: 0.105\n",
            "[11,    50] loss: 0.121\n",
            "[11,    60] loss: 0.125\n",
            "[11,    70] loss: 0.146\n",
            "[11,    80] loss: 0.149\n",
            "[11,    90] loss: 0.095\n",
            "[11,   100] loss: 0.130\n",
            "[11,   110] loss: 0.103\n",
            "[11,   120] loss: 0.117\n",
            "[11,   130] loss: 0.111\n",
            "[11,   140] loss: 0.126\n",
            "[11,   150] loss: 0.132\n",
            "[11,   160] loss: 0.131\n",
            "[11,   170] loss: 0.101\n",
            "[11,   180] loss: 0.099\n",
            "[11,   190] loss: 0.089\n",
            "[11,   200] loss: 0.094\n",
            "[11,   210] loss: 0.134\n",
            "[11,   220] loss: 0.102\n",
            "[11,   230] loss: 0.106\n",
            "[11,   240] loss: 0.074\n",
            "[11,   250] loss: 0.112\n",
            "[11,   260] loss: 0.119\n",
            "[11,   270] loss: 0.110\n",
            "[11,   280] loss: 0.092\n",
            "[11,   290] loss: 0.113\n",
            "[11,   300] loss: 0.104\n",
            "[11,   310] loss: 0.089\n",
            "[11,   320] loss: 0.118\n",
            "[11,   330] loss: 0.110\n",
            "[11,   340] loss: 0.096\n",
            "[11,   350] loss: 0.093\n",
            "[11,   360] loss: 0.140\n",
            "[11,   370] loss: 0.125\n",
            "[11,   380] loss: 0.118\n",
            "[11,   390] loss: 0.110\n",
            "[11,   400] loss: 0.133\n",
            "[11,   410] loss: 0.131\n",
            "[11,   420] loss: 0.133\n",
            "[11,   430] loss: 0.115\n",
            "[11,   440] loss: 0.109\n",
            "[11,   450] loss: 0.131\n",
            "[11,   460] loss: 0.112\n",
            "[11,   470] loss: 0.123\n",
            "[11,   480] loss: 0.149\n",
            "[11,   490] loss: 0.105\n",
            "[11,   500] loss: 0.115\n",
            "[11,   510] loss: 0.151\n",
            "[11,   520] loss: 0.137\n",
            "[11,   530] loss: 0.089\n",
            "[11,   540] loss: 0.114\n",
            "[11,   550] loss: 0.156\n",
            "[11,   560] loss: 0.098\n",
            "[11,   570] loss: 0.113\n",
            "[11,   580] loss: 0.112\n",
            "[11,   590] loss: 0.134\n",
            "[11,   600] loss: 0.094\n",
            "[11,   610] loss: 0.096\n",
            "[11,   620] loss: 0.112\n",
            "[11,   630] loss: 0.117\n",
            "[11,   640] loss: 0.139\n",
            "[11,   650] loss: 0.124\n",
            "[11,   660] loss: 0.106\n",
            "[11,   670] loss: 0.112\n",
            "[11,   680] loss: 0.151\n",
            "[11,   690] loss: 0.140\n",
            "[11,   700] loss: 0.122\n",
            "[11,   710] loss: 0.093\n",
            "[11,   720] loss: 0.122\n",
            "[11,   730] loss: 0.138\n",
            "[11,   740] loss: 0.125\n",
            "[11,   750] loss: 0.118\n",
            "[11,   760] loss: 0.108\n",
            "[11,   770] loss: 0.127\n",
            "[11,   780] loss: 0.126\n",
            "[11,   790] loss: 0.087\n",
            "[11,   800] loss: 0.141\n",
            "[11,   810] loss: 0.087\n",
            "[11,   820] loss: 0.136\n",
            "[11,   830] loss: 0.120\n",
            "[11,   840] loss: 0.116\n",
            "[11,   850] loss: 0.086\n",
            "[11,   860] loss: 0.142\n",
            "[11,   870] loss: 0.092\n",
            "[11,   880] loss: 0.138\n",
            "[11,   890] loss: 0.133\n",
            "[11,   900] loss: 0.105\n",
            "[11,   910] loss: 0.164\n",
            "[11,   920] loss: 0.121\n",
            "[11,   930] loss: 0.094\n",
            "[11,   940] loss: 0.126\n",
            "[11,   950] loss: 0.103\n",
            "[11,   960] loss: 0.154\n",
            "[11,   970] loss: 0.109\n",
            "[11,   980] loss: 0.158\n",
            "[11,   990] loss: 0.118\n",
            "[11,  1000] loss: 0.124\n",
            "[11,  1010] loss: 0.120\n",
            "[11,  1020] loss: 0.126\n",
            "[11,  1030] loss: 0.108\n",
            "[11,  1040] loss: 0.099\n",
            "[11,  1050] loss: 0.101\n",
            "[11,  1060] loss: 0.112\n",
            "[11,  1070] loss: 0.139\n",
            "[11,  1080] loss: 0.109\n",
            "[12,    10] loss: 0.094\n",
            "[12,    20] loss: 0.093\n",
            "[12,    30] loss: 0.084\n",
            "[12,    40] loss: 0.084\n",
            "[12,    50] loss: 0.090\n",
            "[12,    60] loss: 0.087\n",
            "[12,    70] loss: 0.094\n",
            "[12,    80] loss: 0.109\n",
            "[12,    90] loss: 0.117\n",
            "[12,   100] loss: 0.089\n",
            "[12,   110] loss: 0.100\n",
            "[12,   120] loss: 0.114\n",
            "[12,   130] loss: 0.099\n",
            "[12,   140] loss: 0.109\n",
            "[12,   150] loss: 0.090\n",
            "[12,   160] loss: 0.107\n",
            "[12,   170] loss: 0.122\n",
            "[12,   180] loss: 0.110\n",
            "[12,   190] loss: 0.125\n",
            "[12,   200] loss: 0.122\n",
            "[12,   210] loss: 0.129\n",
            "[12,   220] loss: 0.088\n",
            "[12,   230] loss: 0.075\n",
            "[12,   240] loss: 0.090\n",
            "[12,   250] loss: 0.087\n",
            "[12,   260] loss: 0.086\n",
            "[12,   270] loss: 0.115\n",
            "[12,   280] loss: 0.107\n",
            "[12,   290] loss: 0.106\n",
            "[12,   300] loss: 0.133\n",
            "[12,   310] loss: 0.101\n",
            "[12,   320] loss: 0.119\n",
            "[12,   330] loss: 0.111\n",
            "[12,   340] loss: 0.116\n",
            "[12,   350] loss: 0.121\n",
            "[12,   360] loss: 0.136\n",
            "[12,   370] loss: 0.132\n",
            "[12,   380] loss: 0.100\n",
            "[12,   390] loss: 0.111\n",
            "[12,   400] loss: 0.080\n",
            "[12,   410] loss: 0.128\n",
            "[12,   420] loss: 0.094\n",
            "[12,   430] loss: 0.108\n",
            "[12,   440] loss: 0.119\n",
            "[12,   450] loss: 0.083\n",
            "[12,   460] loss: 0.153\n",
            "[12,   470] loss: 0.094\n",
            "[12,   480] loss: 0.105\n",
            "[12,   490] loss: 0.118\n",
            "[12,   500] loss: 0.109\n",
            "[12,   510] loss: 0.122\n",
            "[12,   520] loss: 0.105\n",
            "[12,   530] loss: 0.108\n",
            "[12,   540] loss: 0.096\n",
            "[12,   550] loss: 0.132\n",
            "[12,   560] loss: 0.101\n",
            "[12,   570] loss: 0.094\n",
            "[12,   580] loss: 0.123\n",
            "[12,   590] loss: 0.119\n",
            "[12,   600] loss: 0.083\n",
            "[12,   610] loss: 0.103\n",
            "[12,   620] loss: 0.118\n",
            "[12,   630] loss: 0.110\n",
            "[12,   640] loss: 0.147\n",
            "[12,   650] loss: 0.078\n",
            "[12,   660] loss: 0.100\n",
            "[12,   670] loss: 0.104\n",
            "[12,   680] loss: 0.101\n",
            "[12,   690] loss: 0.145\n",
            "[12,   700] loss: 0.105\n",
            "[12,   710] loss: 0.107\n",
            "[12,   720] loss: 0.101\n",
            "[12,   730] loss: 0.094\n",
            "[12,   740] loss: 0.121\n",
            "[12,   750] loss: 0.132\n",
            "[12,   760] loss: 0.118\n",
            "[12,   770] loss: 0.109\n",
            "[12,   780] loss: 0.081\n",
            "[12,   790] loss: 0.106\n",
            "[12,   800] loss: 0.133\n",
            "[12,   810] loss: 0.126\n",
            "[12,   820] loss: 0.101\n",
            "[12,   830] loss: 0.108\n",
            "[12,   840] loss: 0.093\n",
            "[12,   850] loss: 0.095\n",
            "[12,   860] loss: 0.108\n",
            "[12,   870] loss: 0.123\n",
            "[12,   880] loss: 0.102\n",
            "[12,   890] loss: 0.091\n",
            "[12,   900] loss: 0.100\n",
            "[12,   910] loss: 0.111\n",
            "[12,   920] loss: 0.076\n",
            "[12,   930] loss: 0.107\n",
            "[12,   940] loss: 0.077\n",
            "[12,   950] loss: 0.125\n",
            "[12,   960] loss: 0.109\n",
            "[12,   970] loss: 0.099\n",
            "[12,   980] loss: 0.156\n",
            "[12,   990] loss: 0.084\n",
            "[12,  1000] loss: 0.127\n",
            "[12,  1010] loss: 0.101\n",
            "[12,  1020] loss: 0.103\n",
            "[12,  1030] loss: 0.114\n",
            "[12,  1040] loss: 0.113\n",
            "[12,  1050] loss: 0.150\n",
            "[12,  1060] loss: 0.148\n",
            "[12,  1070] loss: 0.122\n",
            "[12,  1080] loss: 0.110\n",
            "[13,    10] loss: 0.102\n",
            "[13,    20] loss: 0.097\n",
            "[13,    30] loss: 0.154\n",
            "[13,    40] loss: 0.085\n",
            "[13,    50] loss: 0.093\n",
            "[13,    60] loss: 0.120\n",
            "[13,    70] loss: 0.109\n",
            "[13,    80] loss: 0.112\n",
            "[13,    90] loss: 0.093\n",
            "[13,   100] loss: 0.089\n",
            "[13,   110] loss: 0.106\n",
            "[13,   120] loss: 0.130\n",
            "[13,   130] loss: 0.126\n",
            "[13,   140] loss: 0.076\n",
            "[13,   150] loss: 0.083\n",
            "[13,   160] loss: 0.093\n",
            "[13,   170] loss: 0.112\n",
            "[13,   180] loss: 0.113\n",
            "[13,   190] loss: 0.130\n",
            "[13,   200] loss: 0.094\n",
            "[13,   210] loss: 0.095\n",
            "[13,   220] loss: 0.100\n",
            "[13,   230] loss: 0.094\n",
            "[13,   240] loss: 0.107\n",
            "[13,   250] loss: 0.110\n",
            "[13,   260] loss: 0.123\n",
            "[13,   270] loss: 0.101\n",
            "[13,   280] loss: 0.086\n",
            "[13,   290] loss: 0.077\n",
            "[13,   300] loss: 0.106\n",
            "[13,   310] loss: 0.103\n",
            "[13,   320] loss: 0.111\n",
            "[13,   330] loss: 0.094\n",
            "[13,   340] loss: 0.119\n",
            "[13,   350] loss: 0.084\n",
            "[13,   360] loss: 0.104\n",
            "[13,   370] loss: 0.111\n",
            "[13,   380] loss: 0.115\n",
            "[13,   390] loss: 0.105\n",
            "[13,   400] loss: 0.121\n",
            "[13,   410] loss: 0.084\n",
            "[13,   420] loss: 0.092\n",
            "[13,   430] loss: 0.094\n",
            "[13,   440] loss: 0.103\n",
            "[13,   450] loss: 0.110\n",
            "[13,   460] loss: 0.100\n",
            "[13,   470] loss: 0.099\n",
            "[13,   480] loss: 0.093\n",
            "[13,   490] loss: 0.091\n",
            "[13,   500] loss: 0.111\n",
            "[13,   510] loss: 0.069\n",
            "[13,   520] loss: 0.098\n",
            "[13,   530] loss: 0.121\n",
            "[13,   540] loss: 0.103\n",
            "[13,   550] loss: 0.091\n",
            "[13,   560] loss: 0.082\n",
            "[13,   570] loss: 0.119\n",
            "[13,   580] loss: 0.084\n",
            "[13,   590] loss: 0.099\n",
            "[13,   600] loss: 0.134\n",
            "[13,   610] loss: 0.089\n",
            "[13,   620] loss: 0.078\n",
            "[13,   630] loss: 0.103\n",
            "[13,   640] loss: 0.100\n",
            "[13,   650] loss: 0.137\n",
            "[13,   660] loss: 0.113\n",
            "[13,   670] loss: 0.100\n",
            "[13,   680] loss: 0.098\n",
            "[13,   690] loss: 0.070\n",
            "[13,   700] loss: 0.082\n",
            "[13,   710] loss: 0.087\n",
            "[13,   720] loss: 0.131\n",
            "[13,   730] loss: 0.111\n",
            "[13,   740] loss: 0.107\n",
            "[13,   750] loss: 0.105\n",
            "[13,   760] loss: 0.089\n",
            "[13,   770] loss: 0.131\n",
            "[13,   780] loss: 0.094\n",
            "[13,   790] loss: 0.090\n",
            "[13,   800] loss: 0.108\n",
            "[13,   810] loss: 0.100\n",
            "[13,   820] loss: 0.094\n",
            "[13,   830] loss: 0.094\n",
            "[13,   840] loss: 0.089\n",
            "[13,   850] loss: 0.087\n",
            "[13,   860] loss: 0.118\n",
            "[13,   870] loss: 0.117\n",
            "[13,   880] loss: 0.088\n",
            "[13,   890] loss: 0.095\n",
            "[13,   900] loss: 0.103\n",
            "[13,   910] loss: 0.096\n",
            "[13,   920] loss: 0.094\n",
            "[13,   930] loss: 0.085\n",
            "[13,   940] loss: 0.098\n",
            "[13,   950] loss: 0.131\n",
            "[13,   960] loss: 0.110\n",
            "[13,   970] loss: 0.111\n",
            "[13,   980] loss: 0.104\n",
            "[13,   990] loss: 0.076\n",
            "[13,  1000] loss: 0.113\n",
            "[13,  1010] loss: 0.085\n",
            "[13,  1020] loss: 0.096\n",
            "[13,  1030] loss: 0.092\n",
            "[13,  1040] loss: 0.112\n",
            "[13,  1050] loss: 0.103\n",
            "[13,  1060] loss: 0.102\n",
            "[13,  1070] loss: 0.133\n",
            "[13,  1080] loss: 0.115\n",
            "[14,    10] loss: 0.096\n",
            "[14,    20] loss: 0.080\n",
            "[14,    30] loss: 0.105\n",
            "[14,    40] loss: 0.108\n",
            "[14,    50] loss: 0.106\n",
            "[14,    60] loss: 0.087\n",
            "[14,    70] loss: 0.100\n",
            "[14,    80] loss: 0.079\n",
            "[14,    90] loss: 0.116\n",
            "[14,   100] loss: 0.109\n",
            "[14,   110] loss: 0.067\n",
            "[14,   120] loss: 0.095\n",
            "[14,   130] loss: 0.073\n",
            "[14,   140] loss: 0.132\n",
            "[14,   150] loss: 0.093\n",
            "[14,   160] loss: 0.086\n",
            "[14,   170] loss: 0.081\n",
            "[14,   180] loss: 0.079\n",
            "[14,   190] loss: 0.086\n",
            "[14,   200] loss: 0.115\n",
            "[14,   210] loss: 0.073\n",
            "[14,   220] loss: 0.113\n",
            "[14,   230] loss: 0.078\n",
            "[14,   240] loss: 0.071\n",
            "[14,   250] loss: 0.095\n",
            "[14,   260] loss: 0.102\n",
            "[14,   270] loss: 0.071\n",
            "[14,   280] loss: 0.111\n",
            "[14,   290] loss: 0.116\n",
            "[14,   300] loss: 0.101\n",
            "[14,   310] loss: 0.083\n",
            "[14,   320] loss: 0.135\n",
            "[14,   330] loss: 0.079\n",
            "[14,   340] loss: 0.109\n",
            "[14,   350] loss: 0.108\n",
            "[14,   360] loss: 0.111\n",
            "[14,   370] loss: 0.074\n",
            "[14,   380] loss: 0.100\n",
            "[14,   390] loss: 0.074\n",
            "[14,   400] loss: 0.122\n",
            "[14,   410] loss: 0.104\n",
            "[14,   420] loss: 0.067\n",
            "[14,   430] loss: 0.077\n",
            "[14,   440] loss: 0.099\n",
            "[14,   450] loss: 0.094\n",
            "[14,   460] loss: 0.156\n",
            "[14,   470] loss: 0.074\n",
            "[14,   480] loss: 0.066\n",
            "[14,   490] loss: 0.117\n",
            "[14,   500] loss: 0.112\n",
            "[14,   510] loss: 0.100\n",
            "[14,   520] loss: 0.086\n",
            "[14,   530] loss: 0.068\n",
            "[14,   540] loss: 0.089\n",
            "[14,   550] loss: 0.094\n",
            "[14,   560] loss: 0.088\n",
            "[14,   570] loss: 0.097\n",
            "[14,   580] loss: 0.099\n",
            "[14,   590] loss: 0.129\n",
            "[14,   600] loss: 0.086\n",
            "[14,   610] loss: 0.096\n",
            "[14,   620] loss: 0.072\n",
            "[14,   630] loss: 0.088\n",
            "[14,   640] loss: 0.102\n",
            "[14,   650] loss: 0.079\n",
            "[14,   660] loss: 0.094\n",
            "[14,   670] loss: 0.095\n",
            "[14,   680] loss: 0.089\n",
            "[14,   690] loss: 0.099\n",
            "[14,   700] loss: 0.121\n",
            "[14,   710] loss: 0.079\n",
            "[14,   720] loss: 0.080\n",
            "[14,   730] loss: 0.119\n",
            "[14,   740] loss: 0.082\n",
            "[14,   750] loss: 0.111\n",
            "[14,   760] loss: 0.124\n",
            "[14,   770] loss: 0.103\n",
            "[14,   780] loss: 0.115\n",
            "[14,   790] loss: 0.108\n",
            "[14,   800] loss: 0.082\n",
            "[14,   810] loss: 0.086\n",
            "[14,   820] loss: 0.083\n",
            "[14,   830] loss: 0.080\n",
            "[14,   840] loss: 0.078\n",
            "[14,   850] loss: 0.122\n",
            "[14,   860] loss: 0.091\n",
            "[14,   870] loss: 0.092\n",
            "[14,   880] loss: 0.108\n",
            "[14,   890] loss: 0.086\n",
            "[14,   900] loss: 0.093\n",
            "[14,   910] loss: 0.095\n",
            "[14,   920] loss: 0.111\n",
            "[14,   930] loss: 0.101\n",
            "[14,   940] loss: 0.082\n",
            "[14,   950] loss: 0.119\n",
            "[14,   960] loss: 0.097\n",
            "[14,   970] loss: 0.107\n",
            "[14,   980] loss: 0.078\n",
            "[14,   990] loss: 0.093\n",
            "[14,  1000] loss: 0.094\n",
            "[14,  1010] loss: 0.096\n",
            "[14,  1020] loss: 0.117\n",
            "[14,  1030] loss: 0.102\n",
            "[14,  1040] loss: 0.115\n",
            "[14,  1050] loss: 0.121\n",
            "[14,  1060] loss: 0.089\n",
            "[14,  1070] loss: 0.083\n",
            "[14,  1080] loss: 0.080\n",
            "[15,    10] loss: 0.089\n",
            "[15,    20] loss: 0.074\n",
            "[15,    30] loss: 0.088\n",
            "[15,    40] loss: 0.081\n",
            "[15,    50] loss: 0.099\n",
            "[15,    60] loss: 0.068\n",
            "[15,    70] loss: 0.083\n",
            "[15,    80] loss: 0.086\n",
            "[15,    90] loss: 0.089\n",
            "[15,   100] loss: 0.067\n",
            "[15,   110] loss: 0.067\n",
            "[15,   120] loss: 0.069\n",
            "[15,   130] loss: 0.070\n",
            "[15,   140] loss: 0.077\n",
            "[15,   150] loss: 0.128\n",
            "[15,   160] loss: 0.099\n",
            "[15,   170] loss: 0.078\n",
            "[15,   180] loss: 0.105\n",
            "[15,   190] loss: 0.104\n",
            "[15,   200] loss: 0.089\n",
            "[15,   210] loss: 0.090\n",
            "[15,   220] loss: 0.089\n",
            "[15,   230] loss: 0.078\n",
            "[15,   240] loss: 0.096\n",
            "[15,   250] loss: 0.088\n",
            "[15,   260] loss: 0.084\n",
            "[15,   270] loss: 0.099\n",
            "[15,   280] loss: 0.112\n",
            "[15,   290] loss: 0.075\n",
            "[15,   300] loss: 0.074\n",
            "[15,   310] loss: 0.074\n",
            "[15,   320] loss: 0.083\n",
            "[15,   330] loss: 0.088\n",
            "[15,   340] loss: 0.095\n",
            "[15,   350] loss: 0.114\n",
            "[15,   360] loss: 0.091\n",
            "[15,   370] loss: 0.088\n",
            "[15,   380] loss: 0.094\n",
            "[15,   390] loss: 0.074\n",
            "[15,   400] loss: 0.077\n",
            "[15,   410] loss: 0.068\n",
            "[15,   420] loss: 0.095\n",
            "[15,   430] loss: 0.081\n",
            "[15,   440] loss: 0.092\n",
            "[15,   450] loss: 0.084\n",
            "[15,   460] loss: 0.089\n",
            "[15,   470] loss: 0.131\n",
            "[15,   480] loss: 0.094\n",
            "[15,   490] loss: 0.095\n",
            "[15,   500] loss: 0.069\n",
            "[15,   510] loss: 0.113\n",
            "[15,   520] loss: 0.093\n",
            "[15,   530] loss: 0.080\n",
            "[15,   540] loss: 0.101\n",
            "[15,   550] loss: 0.079\n",
            "[15,   560] loss: 0.089\n",
            "[15,   570] loss: 0.105\n",
            "[15,   580] loss: 0.088\n",
            "[15,   590] loss: 0.065\n",
            "[15,   600] loss: 0.104\n",
            "[15,   610] loss: 0.114\n",
            "[15,   620] loss: 0.079\n",
            "[15,   630] loss: 0.094\n",
            "[15,   640] loss: 0.081\n",
            "[15,   650] loss: 0.067\n",
            "[15,   660] loss: 0.096\n",
            "[15,   670] loss: 0.086\n",
            "[15,   680] loss: 0.066\n",
            "[15,   690] loss: 0.067\n",
            "[15,   700] loss: 0.086\n",
            "[15,   710] loss: 0.108\n",
            "[15,   720] loss: 0.125\n",
            "[15,   730] loss: 0.078\n",
            "[15,   740] loss: 0.081\n",
            "[15,   750] loss: 0.101\n",
            "[15,   760] loss: 0.108\n",
            "[15,   770] loss: 0.075\n",
            "[15,   780] loss: 0.081\n",
            "[15,   790] loss: 0.096\n",
            "[15,   800] loss: 0.080\n",
            "[15,   810] loss: 0.106\n",
            "[15,   820] loss: 0.104\n",
            "[15,   830] loss: 0.090\n",
            "[15,   840] loss: 0.092\n",
            "[15,   850] loss: 0.106\n",
            "[15,   860] loss: 0.090\n",
            "[15,   870] loss: 0.106\n",
            "[15,   880] loss: 0.095\n",
            "[15,   890] loss: 0.126\n",
            "[15,   900] loss: 0.077\n",
            "[15,   910] loss: 0.098\n",
            "[15,   920] loss: 0.057\n",
            "[15,   930] loss: 0.089\n",
            "[15,   940] loss: 0.086\n",
            "[15,   950] loss: 0.112\n",
            "[15,   960] loss: 0.105\n",
            "[15,   970] loss: 0.076\n",
            "[15,   980] loss: 0.087\n",
            "[15,   990] loss: 0.080\n",
            "[15,  1000] loss: 0.078\n",
            "[15,  1010] loss: 0.075\n",
            "[15,  1020] loss: 0.107\n",
            "[15,  1030] loss: 0.098\n",
            "[15,  1040] loss: 0.076\n",
            "[15,  1050] loss: 0.152\n",
            "[15,  1060] loss: 0.089\n",
            "[15,  1070] loss: 0.098\n",
            "[15,  1080] loss: 0.085\n",
            "[16,    10] loss: 0.091\n",
            "[16,    20] loss: 0.094\n",
            "[16,    30] loss: 0.062\n",
            "[16,    40] loss: 0.064\n",
            "[16,    50] loss: 0.108\n",
            "[16,    60] loss: 0.093\n",
            "[16,    70] loss: 0.068\n",
            "[16,    80] loss: 0.077\n",
            "[16,    90] loss: 0.077\n",
            "[16,   100] loss: 0.079\n",
            "[16,   110] loss: 0.071\n",
            "[16,   120] loss: 0.065\n",
            "[16,   130] loss: 0.133\n",
            "[16,   140] loss: 0.089\n",
            "[16,   150] loss: 0.069\n",
            "[16,   160] loss: 0.081\n",
            "[16,   170] loss: 0.090\n",
            "[16,   180] loss: 0.075\n",
            "[16,   190] loss: 0.089\n",
            "[16,   200] loss: 0.083\n",
            "[16,   210] loss: 0.089\n",
            "[16,   220] loss: 0.105\n",
            "[16,   230] loss: 0.073\n",
            "[16,   240] loss: 0.077\n",
            "[16,   250] loss: 0.070\n",
            "[16,   260] loss: 0.068\n",
            "[16,   270] loss: 0.070\n",
            "[16,   280] loss: 0.086\n",
            "[16,   290] loss: 0.085\n",
            "[16,   300] loss: 0.081\n",
            "[16,   310] loss: 0.080\n",
            "[16,   320] loss: 0.071\n",
            "[16,   330] loss: 0.084\n",
            "[16,   340] loss: 0.108\n",
            "[16,   350] loss: 0.088\n",
            "[16,   360] loss: 0.082\n",
            "[16,   370] loss: 0.097\n",
            "[16,   380] loss: 0.116\n",
            "[16,   390] loss: 0.071\n",
            "[16,   400] loss: 0.095\n",
            "[16,   410] loss: 0.078\n",
            "[16,   420] loss: 0.081\n",
            "[16,   430] loss: 0.083\n",
            "[16,   440] loss: 0.104\n",
            "[16,   450] loss: 0.072\n",
            "[16,   460] loss: 0.066\n",
            "[16,   470] loss: 0.091\n",
            "[16,   480] loss: 0.086\n",
            "[16,   490] loss: 0.074\n",
            "[16,   500] loss: 0.083\n",
            "[16,   510] loss: 0.117\n",
            "[16,   520] loss: 0.063\n",
            "[16,   530] loss: 0.059\n",
            "[16,   540] loss: 0.068\n",
            "[16,   550] loss: 0.066\n",
            "[16,   560] loss: 0.090\n",
            "[16,   570] loss: 0.105\n",
            "[16,   580] loss: 0.060\n",
            "[16,   590] loss: 0.070\n",
            "[16,   600] loss: 0.078\n",
            "[16,   610] loss: 0.086\n",
            "[16,   620] loss: 0.076\n",
            "[16,   630] loss: 0.065\n",
            "[16,   640] loss: 0.076\n",
            "[16,   650] loss: 0.072\n",
            "[16,   660] loss: 0.082\n",
            "[16,   670] loss: 0.083\n",
            "[16,   680] loss: 0.095\n",
            "[16,   690] loss: 0.136\n",
            "[16,   700] loss: 0.079\n",
            "[16,   710] loss: 0.065\n",
            "[16,   720] loss: 0.062\n",
            "[16,   730] loss: 0.080\n",
            "[16,   740] loss: 0.092\n",
            "[16,   750] loss: 0.101\n",
            "[16,   760] loss: 0.072\n",
            "[16,   770] loss: 0.104\n",
            "[16,   780] loss: 0.081\n",
            "[16,   790] loss: 0.089\n",
            "[16,   800] loss: 0.086\n",
            "[16,   810] loss: 0.083\n",
            "[16,   820] loss: 0.080\n",
            "[16,   830] loss: 0.077\n",
            "[16,   840] loss: 0.112\n",
            "[16,   850] loss: 0.077\n",
            "[16,   860] loss: 0.065\n",
            "[16,   870] loss: 0.080\n",
            "[16,   880] loss: 0.077\n",
            "[16,   890] loss: 0.076\n",
            "[16,   900] loss: 0.067\n",
            "[16,   910] loss: 0.090\n",
            "[16,   920] loss: 0.097\n",
            "[16,   930] loss: 0.125\n",
            "[16,   940] loss: 0.083\n",
            "[16,   950] loss: 0.069\n",
            "[16,   960] loss: 0.073\n",
            "[16,   970] loss: 0.089\n",
            "[16,   980] loss: 0.098\n",
            "[16,   990] loss: 0.069\n",
            "[16,  1000] loss: 0.080\n",
            "[16,  1010] loss: 0.074\n",
            "[16,  1020] loss: 0.068\n",
            "[16,  1030] loss: 0.059\n",
            "[16,  1040] loss: 0.088\n",
            "[16,  1050] loss: 0.106\n",
            "[16,  1060] loss: 0.102\n",
            "[16,  1070] loss: 0.080\n",
            "[16,  1080] loss: 0.066\n",
            "[17,    10] loss: 0.066\n",
            "[17,    20] loss: 0.086\n",
            "[17,    30] loss: 0.069\n",
            "[17,    40] loss: 0.055\n",
            "[17,    50] loss: 0.101\n",
            "[17,    60] loss: 0.101\n",
            "[17,    70] loss: 0.059\n",
            "[17,    80] loss: 0.049\n",
            "[17,    90] loss: 0.096\n",
            "[17,   100] loss: 0.106\n",
            "[17,   110] loss: 0.069\n",
            "[17,   120] loss: 0.065\n",
            "[17,   130] loss: 0.070\n",
            "[17,   140] loss: 0.077\n",
            "[17,   150] loss: 0.078\n",
            "[17,   160] loss: 0.087\n",
            "[17,   170] loss: 0.066\n",
            "[17,   180] loss: 0.081\n",
            "[17,   190] loss: 0.071\n",
            "[17,   200] loss: 0.065\n",
            "[17,   210] loss: 0.067\n",
            "[17,   220] loss: 0.083\n",
            "[17,   230] loss: 0.061\n",
            "[17,   240] loss: 0.073\n",
            "[17,   250] loss: 0.067\n",
            "[17,   260] loss: 0.075\n",
            "[17,   270] loss: 0.061\n",
            "[17,   280] loss: 0.091\n",
            "[17,   290] loss: 0.081\n",
            "[17,   300] loss: 0.061\n",
            "[17,   310] loss: 0.091\n",
            "[17,   320] loss: 0.074\n",
            "[17,   330] loss: 0.069\n",
            "[17,   340] loss: 0.093\n",
            "[17,   350] loss: 0.099\n",
            "[17,   360] loss: 0.074\n",
            "[17,   370] loss: 0.084\n",
            "[17,   380] loss: 0.068\n",
            "[17,   390] loss: 0.084\n",
            "[17,   400] loss: 0.063\n",
            "[17,   410] loss: 0.076\n",
            "[17,   420] loss: 0.075\n",
            "[17,   430] loss: 0.073\n",
            "[17,   440] loss: 0.063\n",
            "[17,   450] loss: 0.073\n",
            "[17,   460] loss: 0.063\n",
            "[17,   470] loss: 0.071\n",
            "[17,   480] loss: 0.064\n",
            "[17,   490] loss: 0.077\n",
            "[17,   500] loss: 0.052\n",
            "[17,   510] loss: 0.081\n",
            "[17,   520] loss: 0.062\n",
            "[17,   530] loss: 0.099\n",
            "[17,   540] loss: 0.075\n",
            "[17,   550] loss: 0.070\n",
            "[17,   560] loss: 0.123\n",
            "[17,   570] loss: 0.093\n",
            "[17,   580] loss: 0.080\n",
            "[17,   590] loss: 0.061\n",
            "[17,   600] loss: 0.079\n",
            "[17,   610] loss: 0.095\n",
            "[17,   620] loss: 0.086\n",
            "[17,   630] loss: 0.089\n",
            "[17,   640] loss: 0.098\n",
            "[17,   650] loss: 0.076\n",
            "[17,   660] loss: 0.065\n",
            "[17,   670] loss: 0.072\n",
            "[17,   680] loss: 0.096\n",
            "[17,   690] loss: 0.078\n",
            "[17,   700] loss: 0.077\n",
            "[17,   710] loss: 0.095\n",
            "[17,   720] loss: 0.070\n",
            "[17,   730] loss: 0.083\n",
            "[17,   740] loss: 0.074\n",
            "[17,   750] loss: 0.083\n",
            "[17,   760] loss: 0.065\n",
            "[17,   770] loss: 0.071\n",
            "[17,   780] loss: 0.084\n",
            "[17,   790] loss: 0.096\n",
            "[17,   800] loss: 0.062\n",
            "[17,   810] loss: 0.078\n",
            "[17,   820] loss: 0.077\n",
            "[17,   830] loss: 0.082\n",
            "[17,   840] loss: 0.070\n",
            "[17,   850] loss: 0.080\n",
            "[17,   860] loss: 0.075\n",
            "[17,   870] loss: 0.089\n",
            "[17,   880] loss: 0.068\n",
            "[17,   890] loss: 0.081\n",
            "[17,   900] loss: 0.082\n",
            "[17,   910] loss: 0.094\n",
            "[17,   920] loss: 0.080\n",
            "[17,   930] loss: 0.082\n",
            "[17,   940] loss: 0.085\n",
            "[17,   950] loss: 0.077\n",
            "[17,   960] loss: 0.081\n",
            "[17,   970] loss: 0.084\n",
            "[17,   980] loss: 0.088\n",
            "[17,   990] loss: 0.083\n",
            "[17,  1000] loss: 0.063\n",
            "[17,  1010] loss: 0.089\n",
            "[17,  1020] loss: 0.079\n",
            "[17,  1030] loss: 0.091\n",
            "[17,  1040] loss: 0.078\n",
            "[17,  1050] loss: 0.067\n",
            "[17,  1060] loss: 0.092\n",
            "[17,  1070] loss: 0.097\n",
            "[17,  1080] loss: 0.087\n",
            "[18,    10] loss: 0.056\n",
            "[18,    20] loss: 0.082\n",
            "[18,    30] loss: 0.088\n",
            "[18,    40] loss: 0.062\n",
            "[18,    50] loss: 0.057\n",
            "[18,    60] loss: 0.065\n",
            "[18,    70] loss: 0.099\n",
            "[18,    80] loss: 0.058\n",
            "[18,    90] loss: 0.058\n",
            "[18,   100] loss: 0.071\n",
            "[18,   110] loss: 0.054\n",
            "[18,   120] loss: 0.094\n",
            "[18,   130] loss: 0.079\n",
            "[18,   140] loss: 0.072\n",
            "[18,   150] loss: 0.086\n",
            "[18,   160] loss: 0.072\n",
            "[18,   170] loss: 0.067\n",
            "[18,   180] loss: 0.088\n",
            "[18,   190] loss: 0.076\n",
            "[18,   200] loss: 0.073\n",
            "[18,   210] loss: 0.071\n",
            "[18,   220] loss: 0.107\n",
            "[18,   230] loss: 0.092\n",
            "[18,   240] loss: 0.070\n",
            "[18,   250] loss: 0.088\n",
            "[18,   260] loss: 0.058\n",
            "[18,   270] loss: 0.063\n",
            "[18,   280] loss: 0.069\n",
            "[18,   290] loss: 0.074\n",
            "[18,   300] loss: 0.097\n",
            "[18,   310] loss: 0.061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lost progress at epoch 17 for the model trained above, load from there\n",
        "EPOCHS = 20\n",
        "IMG_SIZE = 256\n",
        "BATCH_SIZE = 32\n",
        "DECAY = 0.00047\n",
        "\n",
        "data = get_birds_data(img_size=IMG_SIZE, batch_size=BATCH_SIZE)\n",
        "net = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
        "net.fc = nn.Linear(net.fc.in_features, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(CK_PATH + '/ck-17.pkl')\n",
        "losses = train(net, data['train'], checkpoint=state, ck_path=CK_PATH, epochs=EPOCHS, decay=DECAY, schedule={0: 0.01, 3: 0.0075, 5: 0.005, 7: 0.0025, 9: 0.001})\n",
        "print(\"Training   accuracy: %f\" % accuracy(net, data['train']))\n",
        "print(\"Validation accuracy: %f\" % accuracy(net, data['valid']))"
      ],
      "metadata": {
        "id": "3kWD_avQNC7H"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "114d25ec56eb4acf9e9cb29c0ffa9189": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27961eeb6f194ef0b78cace46d42b53a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee1ec23bd9cd4e70ac44e809c4fdf993",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a00dfd008e904d6cadf5eefccd4229f9",
            "value": 102530333
          }
        },
        "2ac2b2728a8047b99927c08c2305a08c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "323f9e070bc64acab43ec5c20198a6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a27b33588664815a8ddf67a08892905",
            "placeholder": "​",
            "style": "IPY_MODEL_50800a086d494e90af6a74703b740aaf",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 162MB/s]"
          }
        },
        "325a044a0c33441ebca37a45068c25c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c1591dbe9d344de8b589a28c72335bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a6218a816f5490ab4fa963e67e30a8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e863513a42f4941b9606887966e0937": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_641f973d43d54d569ae6b8df4d54961f",
            "placeholder": "​",
            "style": "IPY_MODEL_c2ec7571cc7e4645a4479e9b56d660b5",
            "value": "100%"
          }
        },
        "50800a086d494e90af6a74703b740aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b78140d4e9d44d8817c3eae820a2de5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ecba45901c643159cc59a40b15ad7f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e863513a42f4941b9606887966e0937",
              "IPY_MODEL_27961eeb6f194ef0b78cace46d42b53a",
              "IPY_MODEL_323f9e070bc64acab43ec5c20198a6d0"
            ],
            "layout": "IPY_MODEL_84b41b749f4f45e5ab0468f95dbbe937"
          }
        },
        "641f973d43d54d569ae6b8df4d54961f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "659b86ae062044fa90985e9e7f846c31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a27b33588664815a8ddf67a08892905": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "804ec67a8d6d4ad5af8774e55f8abe2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "806ff75186ab418384219c4b0d12458f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e85d3686e1a94c57aa256481d56003fb",
            "placeholder": "​",
            "style": "IPY_MODEL_804ec67a8d6d4ad5af8774e55f8abe2b",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 115MB/s]"
          }
        },
        "84b41b749f4f45e5ab0468f95dbbe937": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e59caa21973457fa00ec2a47fd5f24d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91266558fe3942a7b6026e5bfd072de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b78140d4e9d44d8817c3eae820a2de5",
            "placeholder": "​",
            "style": "IPY_MODEL_659b86ae062044fa90985e9e7f846c31",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 212MB/s]"
          }
        },
        "919d85ab996d418990010667416af1d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9290d78dac8a41b2a3834fa884049c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b42aa7e7948742b28da08b8cac236415",
            "placeholder": "​",
            "style": "IPY_MODEL_b50f28647d79476096e318500a274a7d",
            "value": "100%"
          }
        },
        "9733453223654c14a5d294286888a0b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e59caa21973457fa00ec2a47fd5f24d",
            "placeholder": "​",
            "style": "IPY_MODEL_4a6218a816f5490ab4fa963e67e30a8e",
            "value": "100%"
          }
        },
        "a00dfd008e904d6cadf5eefccd4229f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0cddac9856f4f3aab91ea70a210ddce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9290d78dac8a41b2a3834fa884049c46",
              "IPY_MODEL_b4ba8b913b8146f496ff63e18c2077ca",
              "IPY_MODEL_91266558fe3942a7b6026e5bfd072de7"
            ],
            "layout": "IPY_MODEL_325a044a0c33441ebca37a45068c25c4"
          }
        },
        "b42aa7e7948742b28da08b8cac236415": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4ba8b913b8146f496ff63e18c2077ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_114d25ec56eb4acf9e9cb29c0ffa9189",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ac2b2728a8047b99927c08c2305a08c",
            "value": 102530333
          }
        },
        "b50f28647d79476096e318500a274a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b53969318c674eeaa7e0475b56c0e30f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2ec7571cc7e4645a4479e9b56d660b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db35611c78bc43b4956e573e4fc4a67c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c1591dbe9d344de8b589a28c72335bb",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_919d85ab996d418990010667416af1d2",
            "value": 102530333
          }
        },
        "e319e2f21d8f4c788ef5cfc224c3e066": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9733453223654c14a5d294286888a0b9",
              "IPY_MODEL_db35611c78bc43b4956e573e4fc4a67c",
              "IPY_MODEL_806ff75186ab418384219c4b0d12458f"
            ],
            "layout": "IPY_MODEL_b53969318c674eeaa7e0475b56c0e30f"
          }
        },
        "e85d3686e1a94c57aa256481d56003fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee1ec23bd9cd4e70ac44e809c4fdf993": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}